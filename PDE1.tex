%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,ngerman,english]{scrreprt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.6cm,bmargin=3.5cm,lmargin=2.6cm,rmargin=2.6cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{babel}
\usepackage{float}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=false,
 breaklinks=true,pdfborder={0 0 0},backref=page,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Partial Differential Equations 1},
 pdfauthor={Andreas Völklein},
 pdfkeywords={Partial Differential Equations, Mathematics}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
\newcommand{\noun}[1]{\textsc{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{enumitem}		% customizable list environments
\newlength{\lyxlabelwidth}      % auxiliary length 

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tikz,pgfplots}
%\usepackage{tikz-3dplot,cancel,polynom}
\usetikzlibrary{matrix,arrows,calc,decorations,decorations.markings,intersections,shapes}
\usetikzlibrary{external}
\tikzexternalize
\usepackage{latexsym,stmaryrd,stackrel,braket,bbm,subfig,framed,esvect,scrhack,calc,upgreek}
\usepackage [OMLmathrm,OMLmathbf,sfdefault=fav]{isomath}
\usepackage[explicit]{titlesec}
\usepackage[activate]{pdfcprot}

\pgfkeys{/pgf/number format/dec sep={\text{,}}}
\pgfplotsset{compat=newest}

% Inhaltsverzeichnis
\usepackage[subfigure]{tocloft}

\tocloftpagestyle{fancy}

\renewcommand{\cftchapindent}{1 em}
\renewcommand{\cftchapnumwidth}{1.5 em}

\renewcommand{\cftsecindent}{2.7 em}
\renewcommand{\cftsecnumwidth}{2.5em}

\renewcommand{\cftsubsecindent}{5.2 em}
\renewcommand{\cftsubsecnumwidth}{3.8 em}

\renewcommand{\cftsubsubsecindent}{9 em}
\renewcommand{\cftsubsubsecnumwidth}{4.5 em}

% Mathe-Operatoren
\DeclareMathOperator*{\exsop}{\exists}
\DeclareMathOperator*{\exsgop}{\exists!}
\DeclareMathOperator*{\fallop}{\forall}
\DeclareMathOperator*{\bcupdop}{\dot{\bigcup}}
\DeclareMathOperator*{\bcapdop}{\dot{\bigcap}}

%Operatornorm
\newcommand{\opnor}[1]{\abs{\hspace*{-1.1pt}\norm{#1}\hspace*{-1.1pt}}}

% nicht-totales Differential
\newcommand{\dBar}{\mathchar'26\mkern-12mu \textnormal{d}}

% Angström
\newcommand{\ang}{\textup{\AA}}

% schöne Vektorpfeile
\renewcommand{\vec}[1]{\vv{#1}}

% Rotieren
\newcommand{\Rotate}[1]{
\tikzset{external/export next=false}
\begin{tikzpicture}
\node[rotate=90] {\ensuremath{#1}};
\end{tikzpicture}
}

%QED-Zeichen (Box)
\newcommand{\qed}{\ensuremath{\Box}}
\newcommand{\qqed}[1][\arabic{chapter}.\arabic{section}\ifnum\arabic{subsection}>0{.\arabic{subsection}}\fi]{\hspace*{1mm}\hfill\qed\ensuremath{_{\text{#1}}}}

% Mengen Modulo
\newcommand{\moduloT}[2]{
\mbox{\raisebox{0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large /}
\raisebox{-0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Links Modulo
\newcommand{\lmoduloT}[2]{
\mbox{\raisebox{-0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large \ensuremath{\backslash}}
\raisebox{0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Für Z/2Z, um nicht soviel schreiben zu müssen
\newcommand{\modloT}[2]{\moduloT{ \mathbb{#1}}{#2\mathbb{#1}}}

%Laplace-Beltrami-Operator
\newcommand{\LBO}{
\begin{minipage}{6mm}
 \tikzset{external/export next=false}
 \begin{tikzpicture}
   \node at (0,0){$\upDelta$};
   \draw[line width=0.75] (0.25,-0.13) -- (0.1,0.15);
 \end{tikzpicture}
\end{minipage}
}

%Die Modulo-Kommandos in klein, für die Darstellungen unter Quantoren.
\newcommand{\moduloScriptT}[2]{
\mbox{\raisebox{0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize /}
\raisebox{-0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\lmoduloScriptT}[2]{
\mbox{\raisebox{-0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize \ensuremath{\backslash}}
\raisebox{0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\modloScriptT}[2]{\moduloScriptT{ \mathbb{#1}}{#2\mathbb{#1}}}

% stehendes Winkelzeichen
\newcommand{\winkel}{
\tikzset{external/export next=false}
\begin{tikzpicture}[scale=0.25]
\draw ({-2+3^(1/2)},0) -- (0,1) -- ({2-3^(1/2)},0);
\draw ($(0,1) + ({cos(235)*0.7},{sin(315)*0.7})$) arc (235:315:0.7);
\end{tikzpicture}}

% Wurzel mit Häkchen
\newcommand{\hsqrt}[2][{}]{\setbox0=\hbox{$\sqrt[#1]{\phantom{|}\!\! #2\hspace*{1pt}}$}\dimen0=\ht0
  \advance\dimen0-0.2\ht0
  \setbox2=\hbox{\vrule height\ht0 depth -\dimen0}
  {\box0\lower0.4pt\box2}}

% Damit nicht immer "Kapitel 1" etc. über der Kapitelüberschrift steht
\titleformat{\chapter}
  {\huge\bfseries}
  {\textrm{\thechapter} }{0pt}
  {\textrm{#1} \thispagestyle{fancy}
  }

% Neudefinition der Abschnittsmarker für die Kopfzeile
\renewcommand\partmark[1]{\markboth{#1}{}}
\renewcommand\chaptermark[1]{\markright{\arabic{chapter} #1}}
\renewcommand\sectionmark[1]{}
\renewcommand\subsectionmark[1]{}

% Schriften auf Serif umstellen
\addtokomafont{descriptionlabel}{\rmfamily}
\addtokomafont{disposition}{\rmfamily}

% Zeilenumbrüche in Gleichungen
 \allowdisplaybreaks

% Kopf- und Fußzeile
% Höhe der Kopfzeile
\setlength{\headheight}{14pt}
% obere Trennlinie
%\renewcommand{\headrulewidth}{0.4pt}
\fancyhf{} %alle Kopf- und Fußzeilenfelder bereinigen
\fancyhead[L]{\textbf{Partial Differential Equations I}} %Kopfzeile links
%\fancyhead[C]{\leftmark} %zentrierte Kopfzeile
\fancyhead[R]{\rightmark} %Kopfzeile rechts
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END-front}} %Seitenzahl der Front-Matter

\AtBeginDocument{
  \def\labelitemi{\normalfont\bfseries{--}}
  \def\labelitemii{\(\circ\)}
  \def\labelitemiii{\(\triangleright\)}
}

\makeatother

\begin{document}




\selectlanguage{ngerman}%


\selectlanguage{english}%
\global\long\def\norm#1{\left\lVert #1\right\rVert }


\global\long\def\abs#1{\left\lvert #1\right\rvert }


\global\long\def\opnorm#1{\opnor{#1}}


\global\long\def\BRA#1{\Bra{#1}}


\global\long\def\KET#1{\Ket{#1}}


\global\long\def\BraKet#1{\Braket{#1}}


\global\long\def\mins{\textnormal{-}}


\global\long\def\LB{\LBO}


\global\long\def\exs{\exsop}


\global\long\def\exsg{\exsgop}


\global\long\def\fall{\fallop}


\global\long\def\bcupd{\bcupdop}


\global\long\def\bcapd{\bcapdop}


\global\long\def\sr#1#2#3{\underset{#3}{\overset{#2}{#1}}}


\global\long\def\dd{\textnormal{d}}


\global\long\def\DD{\textnormal{D}}


\global\long\def\dbar{\dBar}


\global\long\def\TT{\textnormal{T}}


\global\long\def\ii{\textbf{i}}


\global\long\def\modulo#1#2{\moduloT{#1}{#2}}


\global\long\def\lmodulo#1#2{\lmoduloT{#1}{#2}}


\global\long\def\modlo#1#2{\modloT{#1}{#2}}


\global\long\def\moduloScript#1#2{\moduloScriptT{#1}{#2}}


\global\long\def\lmoduloScript#1#2{\lmoduloScriptT{#1}{#2}}


\global\long\def\modloScript#1#2{\modloScriptT{#1}{#2}}


\global\long\def\vek#1{\vectorsym{#1}}


\global\long\def\mat#1{\matrixsym{#1}}


\global\long\def\ten#1{\tensorsym{#1}}


\global\long\def\msd#1{\mathstrut_{#1}}


\global\long\def\msu#1{\mathstrut^{#1}}


\pagenumbering{roman}


\title{\hspace*{1mm}\vspace*{-15mm}\\
{\Huge Partial Differential Equations I}}


\author{\vspace*{-5mm}\\
\textit{\small lecture by}\\
\textit{\noun{\small Prof. Dr. Felix Finster}}\\
\textit{\small during the summer semester 2013}\\
\textit{\small revision and layout in \LyX{} by}\\
\textit{\noun{\small Andreas Völklein}}\\
\vspace*{5mm}\\
\includegraphics[clip,width=15cm]{unir}\\
\vspace*{3mm}\\
{\normalsize Last changed: \today}\\
\vspace*{-30mm}}

\maketitle
\fancyhead[R]{License}


\subsubsection*{ATTENTION}

This script does \emph{not} replace the lecture.

Therefore it is recommended \emph{strongly} to attend the lecture.

\vfill{}



\subsubsection*{Copyright Notice}

Copyright © 2013 \noun{Andreas Völklein}

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3
or any later version published by the Free Software Foundation;

with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
Texts.

A copy of the license is included in the document entitled “GFDL”.


\subsubsection*{Disclaimer of Warranty}

\noun{Unless otherwise mutually agreed to by the parties in writing
and to the extent not prohibited by applicable law, }\textbf{\noun{the
Copyright Holders and any other party, who may distribute the Document
as permitted above,   provide the Document “as is}}\textbf{”,}\textbf{\noun{
without warranty of any kind}}\noun{, expressed, implied, statutory
or otherwise, including, but not limited to, the implied warranties
of merchantability, fitness for a particular purpose, non-infringement,
the absence of latent or other defects, accuracy, or the absence of
errors, whether or not discoverable.}


\subsubsection*{Limitation of Liability}

\textbf{\noun{In no event}}\noun{ unless required by applicable law
or agreed to in writing }\textbf{\noun{will the Copyright Holders,
or any other party, who may distribute the Document as permitted above,
be liable to you for any damages}}\noun{, including, but not limited
to, any general, special, incidental, consequential, punitive or exemplary
damages, however caused, regardless of the theory of liability, arising
out of or related to this license or any use of or inability to use
the Document, even if they have been advised of the possibility of
such damages.}

\textbf{\noun{In no event will the Copyright Holders'/Distributor's
liability to you}}\noun{, whether in contract, tort (including negligence),
or otherwise, }\textbf{\noun{exceed the amount you paid the Copyright
Holders/Distributor}}\noun{ for the document under this agreement.}


\subsubsection*{Links}

The text of the “GNU Free Documentation License” can also be read
on the following site:
\begin{quote}
\url{https://www.gnu.org/licenses/fdl-1.3.en.html}
\end{quote}
A transparent copy of the recent version of this document can be downloaded
from:
\begin{quote}
\url{https://github.com/andiv/PDE1}
\end{quote}
\newpage{}

\fancyhead[R]{Literature}


\subsection*{Literature}

Elliptic and parabolic partial differential equations:
\begin{itemize}
\item \noun{Jürgen Jost}: \emph{Partial Differential Equations}; Springer,
2007\\
ISBN: 978-0-387-49318-3; \href{http://dx.doi.org/10.1007/978-0-387-49319-0}{doi: 10.1007/978-0-387-49319-0}\\
(good book, but not all details, small errors)
\item \noun{Lawrence C. Evans}: \emph{Partial Differential Equations}; American
Mathematical Society, 2010; ISBN: 978-0-8218-4974-3\\
(part of the lecture follows this book, lots of details)
\item \noun{David Gilborg, Neil S. Trudinger}: \emph{Elliptic Partial Differential
Equations of second order}; Springer, 2001; ISBN: 3-540-41160-7\\
(classic textbook, complete treatment)
\end{itemize}
Hyperbolic partial differential equations (for the lecture ``Partial
Differential Equations II''):
\begin{itemize}
\item \noun{Fritz John}: \emph{Partial Differential Equations}; Springer,
1999\\
ISBN: 0-387-90609-6
\item \noun{Michael E. Taylor}: \emph{Partial Differential Equations I -
III}; Springer, 1997\\
ISBN: 0-387-94653-5, 0-387-94651-9, 0-387-94652-7\\
(nice detailed text books)
\item \noun{Joel Smoller}: \emph{Shock waves and reaction-diffusion equations};
Springer, 1994\\
ISBN: 3-540-94259-9\\
(nicely presented, good motivations, covers most of the material)
\item \noun{Friedrich Sauvigny}: Partial Differential Equations I-II; Springer,
2012\\
ISBN: 978-1-4471-2981-3, 978-1-4471-2984-4;\\
\href{http://dx.doi.org/10.1007/978-1-4471-2981-3}{doi: 10.1007/978-1-4471-2981-3},
\href{http://dx.doi.org/10.1007/3-540-27540-1}{10.1007/3-540-27540-1}
\item and many more $\ldots$
\end{itemize}
{\small \newpage{}}\fancyhead[R]{Table of Contents}
\fancyhead[C]{}

\tableofcontents{}\label{END-front}\newpage{}\pagenumbering{arabic}
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END}} % Seitenzahl des Hauptteils
\fancyhead[R]{\rightmark}
%\fancyhead[C]{\leftmark}%DATE: Mi 17.04.2013


\chapter{A Brief Introduction}

An ordinary differential equation (ODE) can be written as:
\begin{align*}
\frac{\dd}{\dd t}u\left(t\right)=\dot{u}\left(t\right) & =v\left(t,u\right)\\
u:I\subseteq\mathbb{R} & \to\mathbb{R}^{N}
\end{align*}
This equation involves only derivatives with respect to \emph{one}
variable $t$.
\begin{align*}
\frac{\partial}{\partial x}f\left(x,y\right)+\frac{\partial}{\partial y}f\left(x,y\right) & =0
\end{align*}
This is an example for a partial differential equation.


\section{Definition \textmd{(Partial Differential Equation)}}

A \emph{partial differential equation} (PDE) is a (scalar) equation,
which involves partial derivatives of an unknown function $u:\Omega\subseteq\mathbb{R}^{n}\to\mathbb{R}$.
We always assume that $\Omega\subseteq\mathbb{R}^{n}$ is open.\\
More generally, a \emph{system of partial differential equations}
is a system of equations involving partial derivatives of a function
$u:\Omega\subseteq\mathbb{R}^{n}\to\mathbb{R}^{N}$.\\
Similarly one can define partial differential equations on manifolds.

For ordinary differential equations we considered the initial-value
problem:
\begin{align*}
\dot{u}\left(t\right) & =v\left(t,u\right) & u\left(t_{0}\right) & =u_{0}
\end{align*}
For partial differential equations one considers
\begin{itemize}
\item the initial-value problem and
\item the boundary-value problem.
\end{itemize}

\section{Examples}
\begin{enumerate}
\item Cauchy-Riemann equations: Let
\begin{align*}
f:\Omega\stackrel{\text{open}}{\subseteq}\mathbb{C} & \to\mathbb{C}
\end{align*}
be holomorphic.
\begin{align*}
f & =a+\ii b & a & :=\text{Re}\left(f\right) & b & :=\text{Im}\left(f\right)
\end{align*}
\begin{align*}
\frac{\partial a}{\partial x} & =\frac{\partial b}{\partial y} & \frac{\partial b}{\partial x} & =-\frac{\partial a}{\partial y}
\end{align*}
This is a system of two partial differential equations.
\begin{align*}
u & :=\left(\begin{array}{c}
a\\
b
\end{array}\right) & u:\Omega\subseteq\mathbb{C}=\mathbb{R}^{2} & \to\mathbb{R}^{2}
\end{align*}
\begin{align*}
\frac{\partial^{2}a}{\partial x^{2}}+\frac{\partial^{2}a}{\partial y^{2}} & =\frac{\partial b}{\partial x\partial y}-\frac{\partial b}{\partial y\partial x}=0
\end{align*}
\begin{align*}
\Rightarrow\qquad\underbrace{\left(\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}\right)}_{=:\upDelta}a & =0 & \upDelta b & =0
\end{align*}
This is the \emph{Laplace equation} with the \emph{Laplace operator}
$\upDelta$. Solutions of the Laplace equation are called \emph{harmonic
functions}.
\item Let $\left(M,g\right)$ be a Riemannian manifold. Here exists the
Laplace-Beltrami operator $\LBO$.

\begin{itemize}
\item In the special case $M=\mathbb{R}^{n}$ we have:
\begin{align*}
\upDelta & =\frac{\partial^{2}}{\partial x_{1}^{2}}+\ldots+\frac{\partial^{2}}{\partial x_{n}^{2}}\\
\upDelta\varphi & =0
\end{align*}

\item With the Riemannian metric $g_{ij}$ we can define:
\begin{align*}
\LBO\varphi & =g^{ij}\nabla_{i}\nabla_{j}\varphi=\text{div}\left(\text{grad}\left(\varphi\right)\right)=\frac{1}{\sqrt{\det\left(g\right)}}\partial_{j}\left(\sqrt{\det\left(g\right)}g^{jk}\partial_{k}\varphi\right)
\end{align*}

\end{itemize}

This gives an elliptic equation.

\item Newton's gravitational law: Let $\varrho\left(x\right)$ be the mass
density and $\varphi\left(x\right)$ the Newtonian potential.
\begin{align*}
\upDelta\varphi & =\underbrace{-4\pi\varrho}_{\text{inhomogeneity}}
\end{align*}
Such an inhomogeneous Laplace equation is usually referred to as Poisson
equation and it is elliptic.
\item Heat flow equation (\foreignlanguage{ngerman}{Wärmeleitungsgleichung}):
Let $\varphi\left(t,x\right)$ be the temperature at time $t\in\mathbb{R}$
and position $x\in\mathbb{R}^{n}$.
\begin{align*}
\partial_{t}\varphi\left(t,x\right) & =\upDelta\varphi\left(t,x\right)
\end{align*}
This is a parabolic equation.
\item The Schrödinger equation is a parabolic equation:
\begin{align*}
\ii\hbar\partial_{t}\psi\left(t,x\right) & =\left(-\frac{\hbar^{2}}{2m}\upDelta+V\right)\psi\left(t,x\right)
\end{align*}
Additionally to the the heat flow equation there is the potential
$V$, but more important there is a factor of $\ii$ in front of the
partial derivative. The time-independent Schrödinger equation is:
\begin{align*}
E\psi\left(x\right) & =\left(-\frac{\hbar^{2}}{2m}\upDelta+V\right)\psi\left(x\right)
\end{align*}
This is similar to the Poisson equation and also elliptic.
\item The wave equation
\begin{align*}
\left(\partial_{t}^{2}-\upDelta_{x}\right)\psi\left(t,x\right) & =0
\end{align*}
is hyperbolic. We will consider it in the lecture ``Partial Differential
Equations II''.
\item Maxwell's equations: $E\left(t,x\right)$ is the electric field and
$B\left(t,x\right)$ the magnetic field.
\begin{align*}
\text{div}\left(E\right) & =4\pi\varrho &  & \text{Gauss law}\\
\text{rot}\left(E\right) & =-\partial_{t}B &  & \text{Maxwell}\\
\text{div}\left(B\right) & =0\\
\text{rot}\left(B\right) & =4\pi j-\partial_{t}E &  & \text{Faraday}
\end{align*}
This is a system of 8 partial differential equation.
\item Einstein's field equation:
\begin{align*}
R_{ij}-\frac{1}{2}Rg_{ij} & =4\pi\kappa T_{ij}
\end{align*}
This is a geometric partial differential equation. $R_{ij}$ is the
Ricci curvature, $R$ the scalar curvature and $T_{ij}$ the energy-momentum
tensor. It is a system of 10 partial differential equations.
\item Equations of relativistic quantum mechanics:
\begin{align*}
\left(-\partial_{t}^{2}+\upDelta\right)\psi & =m^{2}\psi
\end{align*}
This is the Klein-Gordon equation with the mass $m$.
\begin{align*}
\ii\gamma^{j}\partial_{j}\psi & =m\psi
\end{align*}
This is the Dirac equation, a system of 4 complex-valued or 8 real-valued
partial differential equations for a particle with spin $\frac{1}{2}$.
\item Water waves can be described by the Korteweg-de Vries equation:
\begin{align*}
\partial_{t}u+u\partial_{x}u+\partial_{x}^{3}u & =0
\end{align*}
\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
  \draw (-4,1) -- (4,1) (-4,-1) -- (4,-1);
  \draw[dashed] (-1,0.7) -- (-1,-0.7) (2,0.7) -- (2,-0.7);
  \draw[thick] plot[smooth,tension=.7] coordinates{(-2,-0.4) (-1.6,-0.25) (-1,0.4) (-0.4,-0.25) (0,-0.4)};
  \draw[thick,xshift=3cm] plot[smooth,tension=.7] coordinates{(-2,-0.4) (-1.6,-0.25) (-1,0.4) (-0.4,-0.25) (0,-0.4)};
  \draw[thick,decoration={markings,mark=at position 1 with {\arrow[scale=1.3]{>}};},postaction={decorate}] (0,0.1) -- (1,0.1);
  \draw plot[smooth cycle,tension=.3] coordinates{(-3.5,-0.3) (-2.75,-0.27) (-2.5,-0.2) (-2.25,0) (-2.5,0.2) (-2.75,0.27) (-3.5,0.3)};
\end{tikzpicture}
\par\end{centering}

\caption{Solitons (discovered by John Russel in 1834): When the ship suddenly
stops, the water flows on along the channel. This wave moves with
a constant speed and its shape stays the same.}


\end{figure}

\item Shock waves: Burger's equation
\begin{align*}
\partial_{t}u+u\partial_{x}u & =0
\end{align*}
is hyperbolic.
\item Turbulence can be described by the incompressible Navier-Stokes equations
for the velocity $v:\Omega\subseteq\mathbb{R}^{3}\to\mathbb{R}^{3}$.
\begin{align*}
\text{div}\left(v\right) & =0\\
\rho\partial_{t}v^{j}+\rho v^{i}\partial_{i}v^{j}-\eta\upDelta v^{j} & =-\partial_{j}P
\end{align*}
Here $\varrho$ is the gas density, $P$ the pressure and $\eta$
the viscosity.
\end{enumerate}

\section{Classification}
\begin{enumerate}[label=\Roman*)]
\item The \emph{order} of a partial differential equation is the highest
order of the derivatives in it.
\begin{align*}
\upDelta u & =f &  & \text{second order}\\
\partial_{t}\varphi & =\upDelta\varphi &  & \text{second order}\\
\partial_{t}u+u\partial_{x}u+\partial_{x}^{3}u & =0 &  & \text{third order}
\end{align*}

\item Algebraic classification:

\begin{enumerate}[label=\alph*)]
\item \emph{Linear} equations: The unknown function $u$ and its derivatives
appear only linearly.
\begin{align*}
\partial_{t}u & =u &  & \text{linear}\\
\partial_{t}u+u\partial_{x}u & =0 &  & \text{non-linear}
\end{align*}

\item Linear \emph{homogeneous} equations: If $u$ is a solution, then $\lambda u$
for $\lambda\in\mathbb{R}$ is also a solution.
\begin{align*}
\upDelta u & =0 &  & \text{linear homogeneous}\\
\upDelta u & =\varrho &  & \text{linear inhomogeneous}\\
\LBO u & =0 &  & \text{linear homogeneous}
\end{align*}

\item Linear with \emph{constant coefficients}:
\begin{align*}
\upDelta u & =\rho &  & \text{linear with constant coefficients}\\
\LBO u & =\varrho &  & \text{in general non-constant coefficients}
\end{align*}

\end{enumerate}
\item Classification by type: elliptic, parabolic, hyperbolic\\
Here we only consider scalar second order equations with $x\in\Omega\subseteq\mathbb{R}^{n}$.
\begin{align*}
F\left(x,u,\DD u,\DD^{2}u\right) & =0\\
F:\Omega\times\mathbb{R}\times\mathbb{R}^{n}\times\mathbb{R}^{n\times n} & \to\mathbb{R}
\end{align*}
\begin{align*}
A_{ij} & :=\frac{\partial F\left(x,u,p_{i},p_{ij}\right)}{\partial p_{ij}}
\end{align*}
is a symmetric $n\times n$ matrix.

\begin{itemize}
\item If $A$ is positive definite, the equation is called \emph{elliptic}.
\item If $A$ has $n-1$ positive and one negative eigenvalue, the equation
is called \emph{hyperbolic}.
\item If $A$ has $n-1$ positive eigenvalues and a non-trivial kernel,
the equation is called \emph{parabolic}.
\item If all eigenvalues are negative or $n-1$ are negative, then we replace
$F$ by $-F$.\\
All other case of \emph{mixed type} are difficult and we do not consider
them in this lecture.
\end{itemize}
\end{enumerate}

\section{Examples}

Consider the Poisson equation:
\begin{align*}
\upDelta u & =\varrho\\
F\left(x,u,\DD u,\DD^{2}u\right) & =-\varrho\left(x\right)+\delta^{ij}\partial_{ij}u\\
F\left(x,u,p_{i},p_{ij}\right) & =-\varrho\left(x\right)+\delta^{ij}p_{ij}\\
A_{ij}=\frac{\partial F\left(x,u,p_{i},p_{ij}\right)}{\partial p_{ij}} & =\delta_{ij}
\end{align*}
So we have $A=\mathbbm{1}$ and thus the equation is elliptic.\\
Now consider the inhomogeneous wave equation:
\begin{align*}
\left(\partial_{t}^{2}-\upDelta\right)\phi\left(t,x_{1},x_{2},x_{3}\right) & =\varrho
\end{align*}
\begin{align*}
F\left(x,u,p_{i},p_{ij}\right) & =\varrho\left(x\right)+\eta^{ij}p_{ij} & \eta & =\text{diag}\left(-1,1,1,1\right)
\end{align*}
So $A=\eta$ has one negative and three positive eigenvalues which
means that the equation is hyperbolic.
\begin{align*}
\partial_{t}\phi & =\upDelta\phi
\end{align*}
\begin{align*}
F\left(x,u,\DD\phi,\DD^{2}\phi\right) & =-\partial_{0}\phi+\sum_{i,j=1}^{3}\delta^{ij}\partial_{ij}\phi\\
A_{ij} & =\left(\begin{array}{cccc}
0 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}\right)
\end{align*}
Therefore the equation is parabolic.


\chapter{Distributions and Fourier Transform}


\subsubsection*{Motivation}

We want to solve partial differential equations with constant coefficients
in $\Omega=\mathbb{R}^{n}$, for example:
\begin{align*}
\left(-\partial_{t}^{2}+\upDelta\right)\phi & =0
\end{align*}
Now we make a ``plane wave ansatz'' with $t,\omega\in\mathbb{R}$
and $k,x\in\mathbb{R}^{n-1}$:
\begin{align*}
\phi\left(t,x\right) & =e^{-\ii\omega t+\ii\left\langle k,x\right\rangle }\\
\partial_{t}\phi\left(t,x\right) & =-\ii\omega\phi\left(t,x\right)\\
\partial_{j}\phi\left(t,x\right) & =\ii k_{j}\phi\left(t,x\right)
\end{align*}
This gives an algebraic equation:
\begin{align*}
\left(-\left(-\ii\omega\right)^{2}+\left(\ii k\right)^{2}\right)\phi & =0\\
\Leftrightarrow\qquad\omega^{2} & =k^{2}
\end{align*}
%DATE: Fr 19.4.13\\
We also want to differentiate non-smooth functions, e.g.:
\begin{align*}
\upDelta_{\mathbb{R}^{3}}\frac{1}{\abs x} & =-4\pi\delta\left(x\right)
\end{align*}
$\delta\left(x\right)$ is called Dirac $\delta$-distribution.


\section{The Schwartz Space and Distributions}

Laurent Schwartz was the first to investigate distributions systematically.
He was awarded the fields medal for his research.


\subsection{Definition \textmd{(Multi-Index)}}

For $\mathbb{R}^{n}$ we denote indices by $i,j,k\in\left\{ 1,\ldots,n\right\} $.
We call $\alpha=\left(i_{1},\ldots,i_{k}\right)$ with $i_{l}\in\left\{ 1,\ldots,n\right\} $
a \emph{multi-index}. $\abs{\alpha}:=k$ is called the \emph{order}
or \emph{absolute value} of the multi-index.

With this we can write differentials of order $k$ as
\begin{align}
\DD^{\alpha} & :=\frac{\partial}{\partial x^{i_{1}}}\cdots\frac{\partial}{\partial x^{i_{k}}}
\end{align}
and homogeneous polynomials of degree $k$ in the components of a
vector $x=\left(x^{1},\ldots,x^{n}\right)$ as:
\begin{align}
x^{\alpha} & :=x^{i_{1}}\cdots x^{i_{k}}
\end{align}
For $f\in C^{\infty}\left(\mathbb{R}^{n}\right)$ and $r,s\in\mathbb{N}$
we define the \emph{Schwartz norm}:
\begin{align}
\norm f_{r,s} & :=\sum_{\alpha,\abs{\alpha}\le r}\sum_{\beta,\abs{\beta}\le s}\sup_{x\in\mathbb{R}^{n}}\abs{x^{\alpha}\DD^{\beta}f\left(x\right)}
\end{align}
For example for $r=0=s$ we have:
\begin{align*}
\norm f_{0,0} & =\sup_{x\in\mathbb{R}^{n}}\abs{f\left(x\right)}=\norm f_{C^{0}}
\end{align*}



\subsection{Definition \textmd{(Schwartz Space)}}

The \emph{Schwartz space} $\mathcal{S}\left(\mathbb{R}^{n}\right)$
is the vector space of all $f\in C^{\infty}\left(\mathbb{R}^{n}\right)$
for which all Schwartz norms are finite, i.e. for all $r,s\in\mathbb{N}$
holds:
\begin{align*}
\norm f_{r,s} & <\infty
\end{align*}
This space is an infinite-dimensional vector space.\\
On a normed space $\left(E,\norm .\right)$, the topology is given
by the open sets.

$\Omega\subseteq E$ is defined as \emph{open} if holds:
\begin{align*}
\fall_{x\in\Omega}\ \exs_{\varepsilon>0}\ :\ B_{\varepsilon}\left(x\right) & \subseteq\Omega
\end{align*}
A subset $\Omega\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$
is called \emph{open} if for every $f\in\Omega$ there is a $\varepsilon>0$
and $r,s\in\mathbb{N}$ such that holds:
\begin{align}
\left\{ g\in\mathcal{S}\Big|\norm{g-f}_{r,s}<\varepsilon\right\}  & \subseteq\Omega
\end{align}

\begin{description}
\item [{Note:}] This topology is fine, because it involves many open sets,
since the condition for open only involves the statement ``there
are $r,s\in\mathbb{N}$''.\\
Convergence $f_{n}\to f$ in $\mathcal{S}$ means that \emph{every}
open neighborhood $U$ of $f$ contains almost all $f_{n}$. For a
finer topology, the condition for a sequence to converge is stronger.
\end{description}

\subsection{Theorem \textmd{(Criterion for Convergence)}}

Convergence $f_{n}\to f$ in $\mathcal{S}$ is equivalent to the convergence
$\norm{f_{n}-f}_{r,s}\to0$ for all $r,s\in\mathbb{N}$.


\subsubsection*{Proof}

``$\Rightarrow$'': Suppose that $f_{n}\to f$ converges. By definition
of the convergence, every open neighborhood of $f$ contains almost
all $f_{n}$. For all $r,s\in\mathbb{N}$ the sets $U_{\varepsilon}^{r,s}:=\big\{ g\big|\norm{g-f}_{r,s}<\varepsilon\big\}$
are open by definition. So the inequality
\begin{align*}
\norm{f_{n}-f}_{r,s} & <\varepsilon
\end{align*}
holds for almost all $f_{n}$ and thus converges $\norm{f_{n}-f}_{r,s}\to0$.

``$\Leftarrow$'': Assume that $\norm{f_{n}-f}_{r,s}\to0$ converges
for all $r,s\in\mathbb{N}$. Let $A$ be an open neighborhood of $f$.
This means by definition that there exist $r,s\in\mathbb{N}$ and
$\varepsilon\in\mathbb{R}_{>0}$ with $U_{\varepsilon}^{r,s}\subseteq A$.
For this $\left(r,s\right)$ we know that $\norm{f_{n}-f}_{r,s}\to0$
converges. Hence there exists a $N\in\mathbb{N}$ such that $\norm{f_{n}-f}_{r,s}<\varepsilon$
holds for all $n\in\mathbb{N}_{>N}$, in other words $f_{n}\in U_{\varepsilon}^{r,s}\subseteq A$.
So $f_{n}\to f$ converges in $\mathcal{S}$.\qqed

A vector space with a topology generated by a family of norms or semi-norms
is a \emph{uniform space} and is called \emph{topological vector space}.


\subsection{Definition \textmd{(Tempered Distribution)}}

Let $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ be the dual space
of $\mathcal{S}\left(\mathbb{R}^{n}\right)$. It is called the space
of \emph{tempered distributions} (\foreignlanguage{ngerman}{temperierte
Distributionen}).

In linear algebra for a finite-dimensional vector space $V$, the
dual space $V^{*}=L\left(V,\mathbb{R}\right)$ is the space of linear
functionals. $V^{*}$ is again a vector space with $\dim\left(V^{*}\right)=\dim\left(V\right)$.\\
Here $\mathcal{S}\left(\mathbb{R}^{n}\right)$ is an infinite-dimensional
vector space with a topology. $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
is the space of all \emph{continuous} linear functionals.

In a Banach space $\left(E,\norm .\right)$ holds: A linear functional
$A:E\to\mathbb{R}$ is continuous if and only if $A$ is bounded,
i.e. $\abs{Au}\le c\norm U$ for all $u\in E$.


\subsection{Lemma \textmd{(Criterion for Continuity)}\label{sub:Lem-continuous_functional}}

A linear functional $T:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathbb{R}$
is continuous if and only if there are $r,s\in\mathbb{N}$ and a $c\in\mathbb{R}_{>0}$
such that holds:
\begin{align}
\abs{Tf} & \le c\norm f_{r,s}\label{eq:T_bounded}
\end{align}



\subsubsection*{Proof}

``$\Leftarrow$'': Assume that (\ref{eq:T_bounded}) holds for some
$r,s\in\mathbb{N}$. We want to show that $T$ is continuous. To this
end, let $f_{n}\to f$ be a convergent series in $\mathcal{S}$. Our
task is to show that $Tf_{n}\to Tf$ converges.\\
The convergence $f_{n}\to f$ implies $\norm{f_{n}-f}_{r',s'}\to0$
for all $r',s'\in\mathbb{N}$ and thus in particular for $r,s$ satisfying
the inequality (\ref{eq:T_bounded}). By linearity follows:
\begin{align*}
\abs{Tf_{n}-Tf} & =\abs{T\left(f_{n}-f\right)}\le c\norm{f_{n}-f}_{r,s}\xrightarrow{n\to\infty}0
\end{align*}
So $T$ maps convergent sequences to convergent sequences and is thus
continuous.

``$\Rightarrow$'': Assume that $T$ is continuous. Then the preimage
of open sets is open, in particular $T^{-1}\left(B_{1}\left(0\right)\right)\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$
is open. So there exist $r,s\in\mathbb{N}$ and a $\varepsilon\in\mathbb{R}_{>0}$
such that holds:
\begin{align*}
T^{-1}\left(B_{1}\left(0\right)\right) & \supseteq U_{\varepsilon}^{r,s}:=\big\{ g\big|\norm g_{r,s}<\varepsilon\big\}
\end{align*}
This implies:
\begin{align*}
\norm g_{r,s}<\varepsilon & \quad\Rightarrow\quad g\in T^{-1}\left(B_{1}\left(0\right)\right)
\end{align*}
Now $g\in T^{-1}\left(B_{1}\left(0\right)\right)$ means $\abs{Tg}<1$.
For any $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ apply this to
$g=\frac{f}{\lambda}$ with $\lambda\in\mathbb{R}_{>0}$.
\begin{align*}
\frac{1}{\lambda}\norm f_{r,s}<\varepsilon & \quad\Rightarrow\quad\frac{1}{\lambda}\abs{Tf}<1\qquad/\cdot\lambda\\
\norm f_{r,s}<\lambda\varepsilon & \quad\Rightarrow\quad\abs{Tf}<\lambda
\end{align*}
Now choose $\lambda=\frac{2}{\varepsilon}\norm f_{r,s}$, so the left
side holds, which implies:
\begin{align*}
\abs{Tf} & <\frac{2}{\varepsilon}\norm f_{r,s}\qquad\fall_{f\in\mathcal{S}\left(\mathbb{R}^{n}\right)}
\end{align*}
\qqed


\subsection{Example \textmd{(\texorpdfstring{$\delta$}{Delta}-Distribution)}}
\begin{enumerate}[label=\alph*)]
\item Consider the following functional:
\begin{align}
\delta:\mathcal{S}\left(\mathbb{R}\right) & \to\mathbb{R}\\
f & \mapsto f\left(0\right)\nonumber 
\end{align}
This is obviously linear.
\begin{align*}
\abs{\delta\left(f\right)} & =\abs{f\left(0\right)}\le\sup_{\mathbb{R}}\abs f=\norm f_{0,0}
\end{align*}
Hence $\delta$ is continuous, which means that $\delta\in\mathcal{S}^{*}\left(\mathbb{R}\right)$
is a tempered distribution.\\
A convenient \emph{notation} with $f\in\mathcal{S}\left(\mathbb{R}\right)$
is:
\begin{align*}
\delta\left(f\right) & =\int_{\mathbb{R}}f\left(x\right)\delta\left(x\right)\dd x
\end{align*}

\item In higher dimension $n\in\mathbb{N}$ we define:
\begin{align*}
\delta:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathbb{R}\\
f & \mapsto f\left(0\right)
\end{align*}
Again holds $\abs{\delta\left(f\right)}\le\norm f_{0,0}$. The physicists'
notation for this is:
\begin{align*}
\delta\left(f\right) & =\int_{\mathbb{R}^{n}}f\left(x\right)\delta^{\left(n\right)}\left(x\right)\dd^{n}x\\
\delta^{\left(n\right)}\left(x\right) & =\delta\left(x^{1}\right)\cdots\delta\left(x^{n}\right)
\end{align*}

\end{enumerate}

\subsubsection*{Remark}

$\delta$ can also be introduced as a \emph{measure} on $\mathbb{R}^{n}$,
the \emph{Dirac measure}. For $A\subseteq\mathbb{R}^{n}$ define:
\begin{align}
\delta\left(x\right) & =\begin{cases}
1 & \text{if }0\in A\\
0 & \text{otherwise}
\end{cases}
\end{align}
Then for $f\in C^{0}\left(\mathbb{R}^{n}\right)$ the expression 
\begin{align*}
\int_{\mathbb{R}^{n}}f\left(x\right)\dd\delta\left(x\right) & =f\left(0\right)
\end{align*}
makes mathematical sense as an integral.

This is useful because convergence theorems and so on from measure
theory are available. The problem is, that this does not work for
every distribution and thus is not general enough for most purposes,
e.g. the derivative $\delta'\left(x\right)$ is a distribution, but
cannot be written as a measure.


\subsection{Example \textmd{(Integral Operator)}}
\begin{enumerate}[label=\alph*)]
\item Consider $g\in C^{\infty}\left(\mathbb{R}^{n}\right)$ with at most
polynomial growth, i.e. there are $c\in\mathbb{R}_{>0}$ and $r\in\mathbb{N}$
such that holds:
\begin{align*}
\abs{g\left(x\right)} & \le c\left(1+\abs x^{r}\right)
\end{align*}
Now define:
\begin{align*}
T_{g}:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathbb{R}\\
f & \mapsto\int_{\mathbb{R}^{n}}g\left(x\right)f\left(x\right)\dd^{n}x
\end{align*}
The integral here is just the Lebesgue integral and it exists:\\
For $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds $\norm f_{r,s}<\infty$
for all $r,s\in\mathbb{N}$.
\begin{align*}
\sup_{\mathbb{R}}\abs f+\sup_{x\in\mathbb{R}}\left(\abs x^{\tilde{r}}\cdot\abs{f\left(x\right)}\right) & \le\norm f_{\tilde{r},0}<\infty\\
\Rightarrow\qquad\sup_{x\in\mathbb{R}}\left(\left(1+\abs x^{\tilde{r}}\right)\abs{f\left(x\right)}\right) & \le\norm f_{\tilde{r},0}\\
\Rightarrow\qquad\abs{f\left(x\right)} & \le\frac{\norm f_{\tilde{r},0}}{1+\abs x^{\tilde{r}}}\qquad\fall_{\tilde{r}\in\mathbb{N}}
\end{align*}
So we get:
\begin{align*}
T_{g}f & =\int g\left(x\right)f\left(x\right)\dd^{n}x\le\int c\left(1+\abs x^{r}\right)\frac{\norm f_{\tilde{r},0}}{\left(1+\abs x^{\tilde{r}}\right)}\dd^{n}x=\\
 & \sr ={\text{polar coordinates}}{\rho:=\abs x}c\norm f_{\tilde{r},0}\underbrace{\mu\left(S^{n-1}\right)}_{\text{volume of unit sphere}}\int_{0}^{\infty}\rho^{n-1}\frac{1+\rho^{r}}{1+\rho^{\tilde{r}}}\dd\rho\stackrel{\tilde{r}>r+n}{<}\infty
\end{align*}
This is finite if and only if the integrand decays faster than $\rho^{-1}$,
i.e. $n-1+r-\tilde{r}<-1$ and thus $\tilde{r}>n+r$. Since $\tilde{r}\in\mathbb{N}$
is arbitrary, the integral exists.\\
Continuity: The previous estimate implies with $\tilde{r}=n+r+1$:
\begin{align*}
\abs{T_{g}f} & \le C\left(g,n\right)\norm f_{\tilde{r},0}
\end{align*}
Thus $T_{g}\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ is a tempered
distribution.
\item Chose $g\left(x\right)=e^{x}$ and define:
\begin{align*}
T_{g}f & :=\int_{-\infty}^{\infty}f\left(x\right)e^{x}\dd x
\end{align*}
This is \emph{not} a well-defined tempered distribution. Namely, choose:
\begin{align*}
f\left(x\right) & =\frac{1}{\cosh\left(\frac{x}{2}\right)}
\end{align*}
\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
 \begin{axis}[width=16cm, axis equal image, axis x line=middle, axis y line=middle, xlabel=$x$, domain=-4:4, ymin=0, ymax=1.2, samples=300]
  \addplot[mark=none] {1/cosh(x/2)};
  \addlegendentry{$f(x)$}
 \end{axis}
\end{tikzpicture} 
\par\end{centering}

\caption{$f\left(x\right)$ decays rapidly.}
\end{figure}
$f\left(x\right)$ and all its derivatives decay rapidly (exponentially
fast $\sim e^{-\frac{x}{2}}$) at $\pm\infty$, so $f\in\mathcal{S}$
is a Schwartz function. But $T_{g}f$ diverges:
\begin{align*}
T_{g}f & =\int_{-\infty}^{\infty}\frac{e^{x}}{\cosh\left(\frac{x}{2}\right)}\dd x=+\infty
\end{align*}

\end{enumerate}
%DATE: Mi 24.4.13


\subsection{Remark \textmd{(Schwartz Functions as Distributions)}}

The mapping
\begin{align*}
T:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
f & \mapsto T_{f}
\end{align*}
is injective.


\subsubsection*{Proof}

If $T$ was injective, there were $f_{1},f_{2}\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
with $T_{f_{1}}=T_{f_{2}}$ and $f_{1}\not=f_{2}$. By linearity this
would imply $T_{g}=0$ with $g=f_{1}-f_{2}\not=0$ and we could choose
a $y\in\mathbb{R}^{n}$ with $g\left(y\right)\not=0$. By continuity
follows $g>0$ or $g<0$ in a neighborhood $U$ of $y$. Now choose
a test function $h$ with $\text{supp}\left(h\right)\subseteq U$
and $h\ge0$. Then follows the contradiction:
\begin{align*}
0=T_{g}\left(h\right) & =\int_{\mathbb{R}^{n}}g\left(x\right)h\left(x\right)\dd^{n}x\not=0
\end{align*}
\qqed

Thus we can regard distributions as ``generalized functions''. Namely
we identify a function $g$ with $T_{g}$. (Later on many people often
do not distinguish between $g$ and $T_{g}$.)


\subsubsection*{Operations on Schwartz Functions and Distributions}
\begin{itemize}
\item $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ is a vector space with
addition $T+S$ and scalar multiplication $\alpha\cdot f$ for distributions
$T,S\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ and $\alpha\in\mathbb{R}$.
\item Multiplication of a distribution by a Schwartz function is defined
for $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ and $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
as:
\begin{align}
\left(fT\right)\left(g\right) & :=T\left(f\cdot g\right)
\end{align}
This is well defined, because $f\cdot g$ is again a Schwartz function
and for $h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds:
\begin{align*}
\left(fT_{h}\right)\left(g\right) & \stackrel{\text{definition of }fT_{h}}{=}T_{h}\left(f\cdot g\right)\stackrel{\text{definition of }T_{h}}{=}\int_{\mathbb{R}^{n}}h\left(x\right)\left(f\cdot g\right)\left(x\right)\dd^{n}x=\\
 & =\int_{\mathbb{R}^{n}}\left(f\cdot h\right)\left(x\right)g\left(x\right)\dd^{n}x=T_{fh}\left(g\right)
\end{align*}
So this definition is extends the multiplication of Schwartz functions
to distributions. But we still have to show, that this operation gives
a continuous functional.
\end{itemize}

\subsection{Definition \textmd{(regular/singular distribution)}}

A tempered distribution $T$ is called \emph{regular} distribution
if there is a $g\in L_{\text{loc}}^{1}\left(\mathbb{R}^{n}\right)$
(locally integrable, i.e. integrable on every compact interval) with
$T=T_{g}$. Otherwise, $T$ is called \emph{singular}.

For example $\delta\left(x\right)$ is singular.


\subsection{Lemma \textmd{(Multiplication of a Distribution by a Schwartz Function)}}

Let $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ be a Schwartz function
and $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ a distribution.
Then $fT$ is a \emph{continuous} linear functional on $\mathcal{S}\left(\mathbb{R}^{n}\right)$,
in other words $fT\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
is also a distribution.


\subsubsection*{Proof}

According to Lemma \ref{sub:Lem-continuous_functional}, our task
is to show that there are $r,s\in\mathbb{N}$ and a $C\in\mathbb{R}_{>0}$
with:
\begin{align*}
\abs{\left(fT\right)\left(g\right)} & \le C\norm g_{r,s}
\end{align*}
Since $T$ is continuous, there exist $r,s\in\mathbb{N}$ and a $\tilde{C}\in\mathbb{R}_{>0}$
with:
\begin{align*}
\abs{T\left(fg\right)} & \le\tilde{C}\norm{fg}_{r,s}
\end{align*}
Thus it remains to show that there is a $c\left(r,s\right)\in\mathbb{R}_{>0}$
such that for all $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align*}
\norm{fg}_{r,s} & \le c\left(r,s\right)\norm f_{r,s}\cdot\norm g_{r,s}
\end{align*}
This inequality can be proven by induction in $s$.

Induction basis $s=0$:
\begin{align*}
\norm{fg}_{r,0} & =\sum_{\abs{\alpha}\le r}\sup_{x\in\mathbb{R}^{n}}\left(\abs{x^{\alpha}f\left(x\right)g\left(x\right)}\right)\le\\
 & \le\sup_{y\in\mathbb{R}^{n}}\abs{g\left(y\right)}\sum_{\abs{\alpha}\le r}\sup_{x\in\mathbb{R}^{n}}\left(\abs{x^{\alpha}f\left(x\right)}\right)=\\
 & =\norm g_{0,0}\cdot\norm f_{r,0}\le\norm g_{r,0}\cdot\norm f_{r,0}
\end{align*}
Induction step $s\leadsto s+1$: Assume that the statement holds for
a $s\in\mathbb{N}$ for all $r\in\mathbb{N}$. Let $\beta$ be a multi-index
with $\abs{\beta}=s+1$, i.e. $\beta=\left(i_{1},\ldots,i_{s+1}\right)$.
Now set:
\begin{align*}
\hat{\beta} & :=\left(i_{1},\ldots,i_{s}\right) & j & :=i_{s+1} & \DD^{\beta} & =\DD^{\hat{\beta}}\frac{\partial}{\partial x^{j}}
\end{align*}
It holds:
\begin{align*}
\DD^{\beta}\left(fg\right) & =\DD^{\hat{\beta}}\frac{\partial}{\partial x^{j}}\left(fg\right)=\DD^{\hat{\beta}}\left(\left(\frac{\partial}{\partial x^{j}}f\right)g+f\left(\frac{\partial}{\partial x^{j}}g\right)\right)
\end{align*}
\begin{align*}
\norm{fg}_{r,s+1} & =\norm{f\cdot g}_{r,s}+\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\beta}=s+1}}\sup_{x\in\mathbb{R}}\abs{x^{\alpha}\DD^{\beta}\left(f\cdot g\right)\left(x\right)}=\\
 & =\norm{fg}_{r,s}+\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\hat{\beta}}=s}}\sum_{j=1}^{n}\sup_{x\in\mathbb{R}}\abs{x^{\alpha}\DD^{\hat{\beta}}\left(\left(\frac{\partial}{\partial x^{j}}f\left(x\right)\right)g\left(x\right)+f\left(x\right)\left(\frac{\partial}{\partial x^{j}}g\left(x\right)\right)\right)}\le\\
 & \sr{\le}{\text{induction}}{\text{hypothesis}}c\left(r,s\right)\norm f_{r,s}\norm g_{r,s}+\sum_{j=1}^{n}c\left(r,s\right)\left(\norm{\frac{\partial}{\partial x^{j}}f}_{r,s}\norm g_{r,s}+\norm f_{r,s}\norm{\frac{\partial}{\partial x^{j}}g}_{r,s}\right)\le\\
 & \le c\left(r,s\right)\norm f_{r,s}\norm g_{r,s}+n\cdot c\left(r,s\right)\left(\norm f_{r,s+1}\norm g_{r,s}+\norm f_{r,s}\norm g_{r,s+1}\right)\le\\
 & \le\underbrace{\left(2n+1\right)c\left(r,s\right)}_{=c\left(r,s+1\right)}\norm f_{r,s+1}\norm g_{r,s+1}
\end{align*}


\qqed


\subsection{Example \textmd{(Derivative of the \texorpdfstring{$\delta$}{Delta}-Distribution)}}

We make a formal computation:
\begin{align*}
\int_{\mathbb{R}}\delta'\left(x\right)f\left(x\right)\dd x & =\int_{\mathbb{R}}\left(\frac{\dd}{\dd x}\delta\left(x\right)\right)f\left(x\right)\dd x\sr ={\text{integration}}{\text{by parts}}-\int_{\mathbb{R}}\delta\left(x\right)f'\left(x\right)\dd x=-f'\left(0\right)
\end{align*}
This motivates us to \emph{define}:
\begin{align}
\delta':\mathcal{S}\left(\mathbb{R}\right) & \to\mathbb{R}\\
f & \mapsto-f'\left(0\right)\nonumber 
\end{align}
This is obviously linear and it is continuous, because for all $f\in\mathcal{S}\left(\mathbb{R}\right)$
holds:
\begin{align*}
\abs{\delta'\left(f\right)} & =\abs{f'\left(0\right)}\le\norm f_{0,1}
\end{align*}
Hence we have $\delta'\in\mathcal{S}^{*}\left(\mathbb{R}\right)$.


\subsubsection*{Remark}

In contrast to $\delta$, the distribution $\delta'$ cannot be introduced
as a measure:
\begin{align*}
\delta\left(\Omega\right) & =\begin{cases}
1 & \text{if }0\in\Omega\\
0 & \text{otherwise}
\end{cases}\\
\delta'\left(\Omega\right) & =?
\end{align*}



\subsection{Definition \textmd{(Distributional Derivative, Convolution)}}
\begin{itemize}
\item For a tempered distribution $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
we define the \emph{distributional derivative} $\DD^{\alpha}T$ by:
\begin{align}
\left(\DD^{\alpha}T\right)\left(f\right) & :=\left(-1\right)^{\abs{\alpha}}T\left(\DD^{\alpha}f\right)
\end{align}
$\DD^{\alpha}T$ is a distribution, since it is a continuous functional:
\begin{align*}
\abs{\left(\DD^{\alpha}T\right)\left(f\right)} & =\abs{T\left(\DD^{\alpha}f\right)}\stackrel{T\text{ continuous}}{\le}C\norm{\DD^{\alpha}f}_{r,s}\le C\norm f_{r,s+\abs{\alpha}}
\end{align*}
So we have a mapping $\DD^{\alpha}:\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
\item The convolution (\foreignlanguage{ngerman}{Faltung}) for $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
is defined as:
\begin{align}
\left(f*g\right)\left(x\right) & :=\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align}

\end{itemize}

\subsection{Lemma \textmd{(Commutativity and Associativity of the Convolution)}}

The convolution is commutative and associative, i.e. for $f,g,h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align}
f*g & =g*f & f*\left(g*h\right) & =\left(f*g\right)*h
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(f*g\right)\left(x\right) & =\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y\sr ={z:=x-y}{\dd^{n}z=\dd^{n}y}\int_{\mathbb{R}^{n}}f\left(z\right)g\left(x-z\right)\dd^{n}z=\left(g*f\right)\left(x\right)
\end{align*}
Associativity follows analogously using Fubini's theorem, which can
be applied, since the function $\left(y,z\right)\mapsto f\left(x-y\right)g\left(y-z\right)h\left(z\right)$
is an element of $\mathcal{S}\left(\mathbb{R}^{2n}\right)\subseteq L^{1}\left(\mathbb{R}^{2n}\right)$:
\begin{align*}
f*\left(g*h\right)\left(x\right) & =\int_{\mathbb{R}^{n}}f\left(x-y\right)\left(g*h\right)\left(y\right)\dd^{n}y=\\
 & =\int_{\mathbb{R}^{n}}f\left(x-y\right)\left(\int_{\mathbb{R}^{n}}g\left(y-z\right)h\left(z\right)\dd^{n}z\right)\dd^{n}y=\\
 & \sr ={\tilde{y}:=y-z}{\dd^{n}\tilde{y}=\dd y}\int_{\mathbb{R}^{n}}\int_{\mathbb{R}^{n}}f\left(x-\tilde{y}-z\right)g\left(\tilde{y}\right)h\left(z\right)\dd^{n}\tilde{y}\dd^{n}z=\\
 & =\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}f\left(x-z-\tilde{y}\right)g\left(\tilde{y}\right)\dd^{n}\tilde{y}\right)h\left(z\right)\dd^{n}z=\\
 & =\int_{\mathbb{R}^{n}}\left(f*g\right)\left(x-z\right)h\left(z\right)\dd^{n}z=\\
 & =\left(f*g\right)*h\left(x\right)
\end{align*}
\qqed


\subsection{Proposition \textmd{(Convolution is Continuous)}}

The convolution $*:\mathcal{S}\times\mathcal{S}\to\mathcal{S}$ is
continuous.


\subsubsection*{Proof}

\begin{align*}
\norm{f*g}_{r,s} & =\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\beta}\le s}}\sup_{x\in\mathbb{R}^{n}}\abs{x^{\alpha}\DD_{x}^{\beta}\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y}
\end{align*}
The derivative may be commuted with the integral:
\begin{align*}
\frac{\partial}{\partial x_{j}}\left(f*g\right)\left(x\right) & =\lim_{\varepsilon\searrow0}\frac{1}{\varepsilon}\left(\left(f*g\right)\left(x+\varepsilon e_{j}\right)-\left(f*g\right)\left(x\right)\right)=\\
 & =\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}g\left(y\right)\dd^{n}y
\end{align*}
Using the estimate
\begin{align*}
\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon} & =\frac{1}{\varepsilon}\int_{0}^{1}\frac{\dd}{\dd\tau}\left(f\left(x+\varepsilon\tau e_{j}-y\right)\right)\dd\tau=\\
 & =\frac{1}{\varepsilon}\int_{0}^{1}\left(\partial_{j}f\right)\left(x+\varepsilon\tau e_{j}-y\right)\varepsilon\dd\tau\\
\Rightarrow\qquad\abs{\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}} & \le\sup_{\mathbb{R}^{n}}\abs{\partial_{j}f}\le\norm f_{0,1}
\end{align*}
we get:
\begin{align*}
\abs{\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}g\left(y\right)} & \le\norm f_{0,1}\cdot\abs{g\left(y\right)}\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
Thus the dominated convergence theorem implies:
\begin{align*}
\frac{\partial}{\partial x_{j}}\left(f*g\right)\left(x\right) & =\int_{\mathbb{R}^{n}}\frac{\partial}{\partial x^{j}}f\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align*}
By induction follows:
\begin{align*}
x^{\alpha}\DD^{\beta}\int_{\mathbb{R}}f\left(x-y\right)g\left(y\right)\dd^{n}y & =x^{\alpha}\int_{\mathbb{R}^{n}}\left(\DD^{\beta}f\right)\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align*}
Now we treat the $x^{\alpha}$:
\begin{align*}
x^{\alpha} & =\left(\left(x-y\right)+y\right)^{\alpha}=\sum_{\gamma,\delta\text{ with }\alpha=\gamma+\delta}c_{\gamma\delta}\left(x-y\right)^{\gamma}\cdot y^{\delta}
\end{align*}
Here holds $\abs{\gamma},\abs{\delta}\le\abs{\alpha}$. Now we can
estimate:
\begin{align*}
\abs{\left(x-y\right)^{\gamma}\DD^{\beta}f\left(x\right)} & \le\norm f_{r,s}
\end{align*}
Hence we get:
\begin{align*}
\norm{f*g}_{r,s} & \le c\left(r,s\right)\norm f_{r,s}\sum_{\delta}\int_{\mathbb{R}^{n}}\abs{y^{\delta}g\left(y\right)}\cdot\frac{\left(1+\abs y\right)^{n+1}}{\left(1+\abs y\right)^{n+1}}\dd^{n}y\le\\
 & \le c\left(r,s\right)\norm f_{r,s}\norm g_{n+1+r,0}\underbrace{\int_{\mathbb{R}^{n}}\frac{\dd^{n}y}{\left(1+\abs y\right)^{n+1}}}_{<\infty}
\end{align*}
\qqed


\subsection{Definition \textmd{(Convolution with Distribution)}}

How can we define the convolution of $T\in S^{*}\left(\mathbb{R}^{n}\right)$
with $f\in S\left(\mathbb{R}^{n}\right)$? $f*T_{g}$ should be equal
to $T_{f*g}$. For $h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds:
\begin{align*}
T_{f*g}\left(h\right) & =\int_{\mathbb{R}^{n}}\left(f*g\right)\left(x\right)\cdot h\left(x\right)\dd^{n}x=\\
 & =\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y\right)\cdot h\left(x\right)\dd^{n}x
\end{align*}
By Fubini's theorem we may interchange the order of integration to
get:
\begin{align*}
T_{f*g}\left(h\right) & =\int_{\mathbb{R}^{n}}g\left(y\right)\left(\int_{\mathbb{R}^{n}}f\left(x-y\right)\cdot h\left(x\right)\dd^{n}x\right)\dd^{n}y=\\
 & \sr ={\tilde{f}\left(z\right):=f\left(-z\right)}{}\int_{\mathbb{R}^{n}}g\left(y\right)\left(\int_{\mathbb{R}^{n}}\tilde{f}\left(y-x\right)\cdot h\left(x\right)\dd^{n}x\right)\dd^{n}y=\\
 & =\int_{\mathbb{R}^{n}}g\left(y\right)\left(\tilde{f}*h\right)\left(y\right)\dd^{n}y=T_{g}\left(\tilde{f}*h\right)
\end{align*}
So for a distribution $T\in S^{*}\left(\mathbb{R}^{n}\right)$ we
define the \emph{convolution} as:
\begin{align}
*:\mathcal{S}\left(\mathbb{R}^{n}\right)\times\mathcal{S}^{*}\left(\mathbb{R}^{n}\right) & \to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
\left(f*T\right)\left(h\right) & :=T\left(\tilde{f}*h\right)\nonumber 
\end{align}


For $S,T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$, $S*T$ and
$S\cdot T$ are ill-defined in general. For example $\delta\left(x\right)\cdot\delta\left(x\right)$
makes no sense, as well as $T_{f}*T_{f}$ for $f=1$.


\section{The Fourier Transform}

First consider the Fourier transform on $\mathcal{S}\left(\mathbb{R}^{n}\right)$
and later on $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.


\subsection{Definition \textmd{(Fourier Transform)}}

Define linear functionals $\mathcal{F}$ and $\overline{\mathcal{F}}$
on $\mathcal{S}$:
\begin{align}
\left(\mathcal{F}f\right)\left(p\right) & :=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\\
\left(\overline{\mathcal{F}}f\right)\left(x\right) & :=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{\ii px}f\left(p\right)\dd^{n}p
\end{align}
The integrals are well-defined and finite, because $f$ has suitable
decay properties at infinity.

An alternative convention, which is not convenient here, because it
has less symmetry, is:
\begin{align*}
\left(\mathcal{F}f\right)\left(p\right) & :=\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\\
\left(\overline{\mathcal{F}}f\right)\left(x\right) & :=\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}e^{\ii px}f\left(p\right)\dd^{n}p
\end{align*}


%DATE: Fr 26.4.13


\subsection{Proposition \textmd{(Fourier Transform)}}

$\mathcal{F}$ and $\overline{\mathcal{F}}$ are well-defined linear
operators from $\mathcal{S}\left(\mathbb{R}^{n}\right)$ to $\mathcal{S}\left(\mathbb{R}^{n}\right)$.


\subsubsection*{Proof}

The linearity is clear. We still have to show, that all norms $\norm{\mathcal{F}f}_{r,s}$
are finite. First consider the norm $\norm ._{0,0}$:
\begin{align*}
\abs{\left(\mathcal{F}f\right)\left(p\right)} & \le\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\abs{f\left(x\right)}\cdot\frac{\left(1+\abs x\right)^{n+1}}{\left(1+\abs x\right)^{n+1}}\dd^{n}x\le\\
 & \le\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\norm f_{n+1,0}\underbrace{\int_{\mathbb{R}^{n}}\frac{\dd^{n}x}{\left(1+\abs x\right)^{n+1}}}_{<\infty}\le c\norm f_{n+1,0}
\end{align*}
Now we consider $\abs{p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right)}$.
\begin{align*}
\frac{\partial}{\partial p^{j}}\left(\mathcal{F}f\right)\left(p\right) & =\frac{\partial}{\partial p^{j}}\int e^{-\ii px}f\left(x\right)\dd^{n}x=\ldots=\int\left(\frac{\partial}{\partial p^{j}}e^{-\ii px}\right)f\left(x\right)\dd^{n}x=\\
 & =\int\left(-\ii x^{j}\right)e^{-\ii px}f\left(x\right)\dd^{n}x
\end{align*}
That the derivative and the integral can be interchanged is shown
as follows:
\begin{align*}
\frac{\partial}{\partial p^{j}}\int e^{-\ii px}f\left(x\right)\dd^{n}x & =\lim_{\varepsilon\searrow0}\int\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}f\left(x\right)\dd^{n}x\\
\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon} & =\frac{1}{\varepsilon}\int_{0}^{1}\frac{\dd}{\dd\tau}e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}\dd\tau=-\ii e_{j}x\int_{0}^{1}e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}\dd\tau\\
\Rightarrow\qquad\abs{\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}} & \le\norm x\cdot\int_{0}^{1}\underbrace{\abs{e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}}}_{=1}\dd\tau=\norm x\\
\abs{\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}f\left(x\right)} & \le\norm x\cdot\abs{f\left(x\right)}\le\frac{\norm x}{1+\norm x^{n+2}}\norm f_{n+2,0}=:h\left(x\right)\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
This allows us to apply the dominated convergence theorem to take
the limit $\varepsilon\to0$ inside the integral. Iteration of this
process gives:
\begin{align*}
\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}}\left(-\ii\right)^{\abs{\beta}}x^{\beta}f\left(x\right)e^{-\ii px}\dd^{n}x\\
p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}}\left(-\ii\right)^{\abs{\beta}}x^{\beta}f\left(x\right)p^{\alpha}e^{-\ii px}\dd^{n}x\\
p^{j}e^{-\ii px} & =\ii\frac{\partial}{\partial x^{j}}e^{-\ii px}\\
\Rightarrow\qquad p^{\alpha}e^{-\ii px} & =\ii^{\abs{\alpha}}\DD_{x}^{\alpha}e^{-\ii px}\\
p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{\left(-\ii\right)^{\abs{\beta}}\ii^{\abs{\alpha}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\underbrace{\left(x^{\beta}f\left(x\right)\right)}_{\text{rapid decay}}\left(\DD_{x}^{\alpha}e^{-\ii px}\right)\dd^{n}x=\\
 & \sr ={\text{integration}}{\text{by parts}}\frac{\left(-\ii\right)^{\abs{\beta}}\ii^{\abs{\alpha}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(-1\right)^{\abs{\alpha}}\DD_{x}^{\alpha}\left(x^{\beta}f\left(x\right)\right)e^{-\ii px}\dd^{n}x=\\
 & =\frac{\left(-\ii\right)^{\abs{\alpha}+\abs{\beta}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\DD_{x}^{\alpha}\left(x^{\beta}f\left(x\right)\right)e^{-\ii px}\dd^{n}x
\end{align*}
From the computation we did earlier in the proof we know:
\begin{align*}
\abs{\DD_{x}^{\alpha}\left(\mathcal{F}f\right)\left(p\right)} & \le C\norm{\DD_{x}^{\alpha}\left(x^{\beta}f\right)}_{n+1,0}\le\tilde{C}\left(\alpha,\beta\right)\norm f_{\abs{\beta}+n+1,\abs{\alpha}}
\end{align*}
\begin{align*}
\norm{\mathcal{F}f}_{r,s} & \le\tilde{c}\left(s,r,n\right)\norm f_{s+n+1,r}
\end{align*}
Therefore $\mathcal{F}:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathcal{S}\left(\mathbb{R}^{n}\right)$
is well-defined. The same follows analogously for $\overline{\mathcal{F}}$.\qqed

So we have the following correspondence:
\begin{align}
-\ii x^{j} & \leftrightarrow\frac{\partial}{\partial p^{j}}\\
-\ii\frac{\partial}{\partial x^{j}} & \leftrightarrow p^{j}
\end{align}
Here the derivatives always act on $f$ or $\mathcal{F}f$ and not
on $e^{-\ii px}$.
\begin{align*}
x^{\alpha}\DD^{\beta}f & \leftrightarrow\ii^{\abs{\alpha}+\abs{\beta}}\DD_{p}^{\alpha}p^{\beta}\left(\mathcal{F}f\right)\left(p\right)=\ii^{\abs{\alpha}+\abs{\beta}}p^{\beta}\DD^{\alpha}\left(\mathcal{F}f\right)\left(p\right)+\text{lower order terms}
\end{align*}
Suppose we had worked with $\norm f_{0,k}=\abs f_{C^{k}}$ as family
of norms. Then the norms of the Fourier transform of a function with
finite norms would not necessarily be finite.


\subsection{Theorem \textmd{(Plancherel, Convergence Generating Factor)\label{sub:Thm-Plancherel}}}

$\mathcal{F}$ and $\overline{\mathcal{F}}$ are inverse to each other:
\begin{align}
\overline{\mathcal{F}}\mathcal{F} & =\mathcal{F}\overline{\mathcal{F}}=\mathbbm{1}:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathcal{S}\left(\mathbb{R}^{n}\right)
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}e^{-\ii px}\underbrace{\left(\int_{\mathbb{R}^{n}}e^{\ii qx}f\left(q\right)\dd^{n}q\right)}_{\left(\overline{\mathcal{F}}f\right)\left(x\right)}\dd^{n}x\stackrel{?}{=}f\left(p\right)\\
 & \stackrel{?}{=}\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\int_{\mathbb{R}^{n}}e^{-\ii\left(p-q\right)x}\dd^{n}x\right)\dd^{n}q
\end{align*}
The problem here is, that $e^{-\ii\left(p-q\right)x}$ does not decay
at infinity, so the integral is not well-defined. Instead we have
to introduce a \emph{convergence generating factor} $e^{-\varepsilon x^{2}}$
and, after integrating, calculate the limes $\varepsilon\to0$.
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}e^{-\ii px}e^{-\varepsilon x^{2}}\left(\int_{\mathbb{R}^{n}}e^{\ii qx}f\left(q\right)\dd^{n}q\right)\dd^{n}x=\\
 & \stackrel{\text{Fubini}}{=}\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\int_{\mathbb{R}^{n}}e^{-\ii\left(p-q\right)x}e^{-\varepsilon x^{2}}\dd^{n}x\right)\dd^{n}q
\end{align*}
The resulting Gaussian integral can be computed in closed form. In
one dimension it is:
\begin{align*}
\int_{\mathbb{R}}e^{-\ii\lambda x}e^{-\varepsilon x^{2}}\dd x & =\int_{\mathbb{R}}e^{-\varepsilon\left(x+\frac{\ii\lambda}{2\varepsilon}\right)^{2}-\frac{\lambda^{2}}{4\varepsilon}}\dd x=e^{-\frac{\lambda^{2}}{4\varepsilon}}\int_{\mathbb{R}}e^{-\varepsilon\left(x+\frac{\ii\lambda}{2\varepsilon}\right)^{2}}\dd x=\\
 & \sr ={z=\sqrt{\varepsilon}\left(x+\frac{\ii\lambda}{2\varepsilon}\right)}{\dd z=\sqrt{\varepsilon}\dd x}e^{-\frac{\lambda^{2}}{4\varepsilon}}\int_{\mathbb{R}+\frac{\ii\lambda}{2\sqrt{\varepsilon}}}e^{-z^{2}}\frac{\dd z}{\sqrt{\varepsilon}}=\\
 & \sr ={\text{contour}}{\text{deformation}}\frac{e^{-\frac{\lambda^{2}}{4\varepsilon}}}{\sqrt{\varepsilon}}\underbrace{\int_{\mathbb{R}}e^{-z^{2}}\dd z}_{=\sqrt{\pi}}=\sqrt{\frac{\pi}{\varepsilon}}e^{-\frac{\lambda^{2}}{4\varepsilon}}
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\frac{\pi}{\varepsilon}\right)^{\frac{n}{2}}e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q
\end{align*}


\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
 \begin{axis}[width=9cm, axis x line=middle, axis y line=middle, xtick={0}, ytick={0}, xlabel=$q$,domain=-6:6,samples=300, ymin=-0.5]
  \addplot[mark=none] {exp(-(1-x)^2/4)};
  \addlegendentry{$\varepsilon = 1$}
  \addplot[blue,dashed,mark=none] {exp(-(1-x)^2/0.4)/sqrt(0.5)};
  \addlegendentry{$\varepsilon = 0.5$}
  \addplot[red!50!black,dotted,mark=none] {exp(-(1-x)^2/0.03)/sqrt(0.1)};
  \addlegendentry{$\varepsilon = 0.1$}
  \draw (axis cs: 1,-0.05) -- (axis cs: 1,0.05) node[above]{$p$};
 \end{axis}
\end{tikzpicture} \hfill{}\begin{tikzpicture}
 \begin{axis}[width=9cm, axis equal image, axis x line=middle, axis y line=middle, xtick={0}, ytick={0}, xlabel=$q^i$, ylabel=$q^j$, xmin=-1, xmax=3, ymin=-0.45, ymax=3]
  \draw (axis cs: 2.05,0.95) -- (axis cs: 1.95,1.05) (axis cs: 2.05,1.05) -- (axis cs: 1.95,0.95) (axis cs:2,1) node[below]{$p$};
  \draw (axis cs: 2,1) circle (10.8mm);
  \draw (axis cs: 2,1) -- node[above]{$\varepsilon$} (axis cs: 1.4,1);
 \end{axis}
\end{tikzpicture} \caption{The Gaussian gets very narrow and very high as $\varepsilon$ decreases.}

\par\end{centering}

\end{figure}


Estimate the integral as follows:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\varepsilon\right)^{\frac{n}{2}}}\left(\int_{\mathbb{R}^{n}}f\left(p\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q+\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q\right)
\end{align*}
The first integral gives:
\begin{align*}
\int_{\mathbb{R}^{n}}e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q & \sr ={z=\frac{p-q}{2\sqrt{\varepsilon}}}{\dd^{n}z=\frac{\dd^{n}q}{\left(4\varepsilon\right)^{\frac{n}{2}}}}\left(4\varepsilon\right)^{\frac{n}{2}}\underbrace{\int_{\mathbb{R}^{n}}e^{-z^{2}}\dd^{n}q}_{=\pi^{\frac{n}{2}}}=\left(4\pi\varepsilon\right)^{\frac{n}{2}}
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =f\left(p\right)+\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\varepsilon\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q
\end{align*}
It remains to show that the second summand goes to zero for $\varepsilon\to0$.
We use the following scaling argument:
\begin{align*}
\frac{1}{\varepsilon^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{4}q & \sr ={u=\frac{p-q}{\sqrt{\varepsilon}}}{\dd^{n}q=\varepsilon^{\frac{n}{2}}\dd^{n}u}\frac{1}{\varepsilon^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)e^{-\frac{u^{2}}{4}}\varepsilon^{\frac{n}{2}}\dd^{n}u=\\
 & =\int_{\mathbb{R}^{n}}\underbrace{\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{\xrightarrow{\varepsilon\searrow0}0\ \text{pointwise}}e^{-\frac{u^{2}}{4}}\dd^{n}u
\end{align*}
For the integrand holds:
\begin{align*}
\underbrace{\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{\xrightarrow{\varepsilon\searrow0}0\ \text{pointwise}}e^{-\frac{u^{2}}{4}} & \le\norm f_{0,0}e^{-\frac{u^{2}}{4}}\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
So the dominated convergence theorem can be applied to get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =f\left(p\right)+\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\underbrace{\lim_{\varepsilon\searrow0}\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{=0}e^{-\frac{u^{2}}{4}}\dd^{n}u=f\left(p\right)
\end{align*}


$\overline{\mathcal{F}}\mathcal{F}=\mathbbm{1}$ follows analogously.\qqed

We want to generalize the Fourier transform to $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
We begin with the case $T_{g}$ with $g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$.
We want:
\begin{align*}
\mathcal{F}\left(T_{g}\right) & =T_{\mathcal{F}g}
\end{align*}
\begin{align*}
T_{\mathcal{F}g}\left(f\right) & =\int_{\mathbb{R}^{n}}\left(\mathcal{F}g\right)\left(p\right)f\left(p\right)\dd^{n}p=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}e^{-\ii px}g\left(x\right)\dd^{n}x\right)f\left(p\right)\dd^{n}p
\end{align*}
Fubini's theorem allows us to interchange the order of integration:
\begin{align*}
T_{\mathcal{F}g}\left(f\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}g\left(x\right)\underbrace{\left(\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(p\right)\dd^{n}p\right)}_{=\mathcal{F}f\left(x\right)}\dd^{n}x=\int_{\mathbb{R}^{n}}g\left(x\right)\left(\mathcal{F}f\right)\left(x\right)\dd^{n}x=\TT_{g}\left(\mathcal{F}f\right)
\end{align*}
Since we want $\left(\mathcal{F}T_{g}\right)\left(f\right)=T_{\mathcal{F}g}=T_{g}\left(\mathcal{F}f\right)$,
this motivates the following general definition:


\subsection{Definition \textmd{(Fourier Transform of Distributions)\label{sub:Def-Fourier_distribution}}}

$\mathcal{F},\overline{\mathcal{F}}:\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
are defined by their action on a test function $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$:
\begin{align}
\left(\mathcal{F}T\right)\left(f\right) & :=T\left(\mathcal{F}f\right)\\
\left(\overline{\mathcal{F}}T\right)\left(f\right) & :=T\left(\overline{\mathcal{F}}f\right)
\end{align}
It holds:
\begin{align*}
\abs{\left(\mathcal{F}T\right)\left(f\right)} & =\abs{T\left(\mathcal{F}f\right)}\sr{\le}{T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}{\Rightarrow\exs r,s\in\mathbb{N},c\in\mathbb{R}_{>0}}c\norm{\mathcal{F}f}_{r,s}\le\tilde{c}\norm f_{s+n+1,r}
\end{align*}
Thus $\mathcal{F}T$ is indeed a tempered distribution.


\subsection{Theorem \textmd{(Plancherel for Distributions)}}

Plancherel's theorem holds on $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
as well:
\begin{align}
\mathcal{F}\overline{\mathcal{F}} & =\overline{\mathcal{F}}\mathcal{F}=\mathbbm{1}_{\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}T\right)\left(f\right) & \stackrel{\text{Definition }\ref{sub:Def-Fourier_distribution}}{=}\left(\overline{\mathcal{F}}T\right)\left(\mathcal{F}f\right)=T\left(\overline{\mathcal{F}}\mathcal{F}f\right)\stackrel{\text{Plancherel }\ref{sub:Thm-Plancherel}}{=}T\left(f\right)
\end{align*}
Since this holds for all $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
and all $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ it follows:
\begin{align*}
\mathcal{F}\overline{\mathcal{F}} & =\mathbbm{1}_{\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}
\end{align*}
The same follows for $\overline{\mathcal{F}}\mathcal{F}$.\qqed


\subsection{Examples}
\begin{enumerate}
\item The Fourier transform of the $\delta$-Distribution can be calculated
as follows:
\begin{align*}
\left(\mathcal{F}\delta\right)\left(f\right) & =\delta\left(\mathcal{F}f\right)=\left(\mathcal{F}f\right)\left(0\right)=\\
 & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\bigg|_{p=0}=\int_{\mathbb{R}^{n}}\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}f\left(x\right)\dd^{n}x=T_{\left(2\pi\right)^{-\frac{n}{2}}}\left(f\right)
\end{align*}
This means:
\begin{align*}
\mathcal{F}\delta & =T_{\left(2\pi\right)^{-\frac{n}{2}}}
\end{align*}
Or, in a more computational manner, one can write this as:
\begin{align*}
\mathcal{F}\delta & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}\delta\left(x\right)\dd^{n}x=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}
\end{align*}
This is not satisfying from a mathematical point of view, because
one does not know, that the usual formula for the Fourier transform
also works for distributions.
\item Consider $T_{f}$ with $g\left(p\right)=e^{\ii py}$ for a given $y\in\mathbb{R}^{n}$.
\begin{align*}
\left(\mathcal{F}T_{f}\right)\left(h\right) & =T_{f}\left(\mathcal{F}h\right)=T_{f}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int e^{-\ii px}h\left(x\right)\dd^{n}x\right)=\\
 & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int e^{\ii py}\left(\int e^{-\ii px}h\left(x\right)\dd^{n}x\right)\dd^{n}p=\\
 & =\left(2\pi\right)^{\frac{n}{2}}\left(\overline{\mathcal{F}}\mathcal{F}\right)h\left(y\right)=\left(2\pi\right)^{\frac{n}{2}}h\left(y\right)
\end{align*}
So we get:
\begin{align*}
\mathcal{F}T_{f}h & =\left(2\pi\right)^{\frac{n}{2}}h\left(y\right)\\
\left(\mathcal{F}T_{f}\right)\left(x\right) & =\left(2\pi\right)^{\frac{n}{2}}\delta^{\left(n\right)}\left(x-y\right)
\end{align*}
Formally one can write:
\begin{align*}
\left(\mathcal{F}f\right)\left(x\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}e^{\ii py}\dd^{n}p=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii p\left(x-y\right)}\dd^{n}p
\end{align*}
This is ill-defined, but physicists use the formal relation:
\begin{align*}
\int_{\mathbb{R}^{n}}e^{-\ii p\left(x-y\right)}\dd^{n}p & =\left(2\pi\right)^{n}\delta^{\left(n\right)}\left(x-y\right)
\end{align*}
%DATE: Fr 3.5.13
\item Consider $T=T_{g}$ with $g\left(p\right)=p^{2}e^{\ii py}$ for a
given $y\in\mathbb{R}$. 
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =T_{g}\left(\mathcal{F}f\right)=\int_{-\infty}^{\infty}g\left(p\right)\left(\mathcal{F}f\right)\left(p\right)\dd p=\\
 & =\int g\left(p\right)\left(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}f\left(x\right)e^{-\ii px}\dd x\right)\dd p
\end{align*}
One cannot interchange the integrals, because the integral
\begin{align*}
\int_{-\infty}^{\infty}\underbrace{g\left(p\right)e^{-\ii p\alpha}}_{\not\in L^{1}}\dd p
\end{align*}
does not exist. Therefore we work again with a convergence generating
factor, which we can due to the dominated convergence theorem:
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}g\left(p\right)e^{-\varepsilon\abs p}\left(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}f\left(x\right)e^{-\ii px}\dd x\right)\dd p=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}g\left(p\right)e^{-\varepsilon\abs p}e^{-\ii px}\dd p\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}p^{2}e^{\ii py}e^{-\varepsilon\abs p}e^{-\ii px}\dd p\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}\left(\ii\partial_{x}\right)^{2}e^{-\ii p\left(x-y\right)-\varepsilon\abs p}\dd p\right)\dd x=\\
 & \stackrel{\text{Lebesgue theorem}}{=}\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\ii\partial_{x}\right)^{2}\left(\int_{-\infty}^{\infty}e^{-\ii p\left(x-y\right)-\varepsilon\abs p}\dd p\right)\dd x
\end{align*}
Now one can decompose the integral into integrals from $-\infty$
to 0 and from $0$ to $\infty$ and calculate the result.
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\ii\partial_{x}\right)^{2}\left(\int_{-\infty}^{0}e^{-\ii p\left(x-y\right)+\varepsilon p}\dd p+\int_{0}^{\infty}e^{-\ii p\left(x-y\right)-\varepsilon p}\dd p\right)\dd x=\\
 & =\frac{-1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{1}{-\ii\left(x-y\right)+\varepsilon}-\frac{1}{-\ii\left(x-y\right)-\varepsilon}\right)\dd x=\\
 & =\frac{-1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{-\ii\left(x-y\right)-\varepsilon-\left(-\ii\left(x-y\right)+\varepsilon\right)}{-\left(x-y\right)^{2}-\varepsilon^{2}}\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{2\varepsilon}{\left(x-y\right)^{2}+\varepsilon^{2}}\right)\dd x=\\
 & \sr ={\text{integration}}{\text{by parts}}\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(x\right)\cdot\frac{\varepsilon}{\left(x-y\right)^{2}+\varepsilon^{2}}\dd x=\\
 & \sr ={z:=\frac{x-y}{\varepsilon}}{\dd z=\frac{\dd x}{\varepsilon}}\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(\varepsilon z+y\right)\cdot\frac{\varepsilon}{\varepsilon^{2}z^{2}+\varepsilon^{2}}\varepsilon\dd z=\\
 & =\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(\varepsilon z+y\right)\cdot\frac{1}{z^{2}+1}\dd z=\\
 & =\sqrt{\frac{2}{\pi}}f''\left(y\right)\underbrace{\int_{-\infty}^{\infty}\frac{1}{z^{2}+1}\dd z}_{=\pi}=\sqrt{2\pi}f''\left(y\right)
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(x\right) & =\sqrt{2\pi}\delta''\left(x-y\right)
\end{align*}

\item Consider the following Hilbert space:
\begin{align*}
L^{2}\left(\mathbb{R}^{n}\right) & =\left\{ f:\mathbb{R}^{n}\to\mathbb{R}\bigg|f\text{ measurable with }\int\abs f^{2}\dd^{n}x<\infty\right\} 
\end{align*}
For $f\in L^{2}\left(\mathbb{R}^{n}\right)$ define:
\begin{align*}
T_{f}\left(g\right) & :=\int_{\mathbb{R}^{n}}f\left(x\right)g\left(x\right)\dd^{n}x\\
\abs{T_{f}\left(g\right)} & \stackrel{\text{Schwarz}}{\le}\norm f_{L^{2}\left(\mathbb{R}^{n}\right)}\norm g_{L^{2}\left(\mathbb{R}^{n}\right)}\le\norm f_{L^{2}\left(\mathbb{R}^{n}\right)}\cdot c\left(n\right)\norm g_{n+1,0}
\end{align*}
Here we used:
\begin{align*}
\abs{g\left(x\right)} & \le\tilde{c}\left(n\right)\frac{\norm g_{n+1,0}}{\left(1+\abs x\right)^{n+1}}
\end{align*}
So we have $T_{f}\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
\begin{align*}
L^{2}\left(\mathbb{R}^{n}\right) & \hookrightarrow\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\xrightarrow{\mathcal{F}}\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
f & \mapsto\ \ \ T_{f}\quad\mapsto\mathcal{F}T_{f}
\end{align*}

\end{enumerate}

\subsection{Theorem}

The mappings $\mathcal{F},\overline{\mathcal{F}}:L^{2}\left(\mathbb{R}^{n}\right)\to L^{2}\left(\mathbb{R}^{n}\right)$
are isometries, i.e.:
\begin{align}
\norm f_{L^{2}\left(\mathbb{R}^{n}\right)} & =\norm{\mathcal{F}f}_{L^{2}\left(\mathbb{R}^{n}\right)}
\end{align}
Due to $\mathcal{F}\overline{\mathcal{F}}=1$ they are even unitary
transformations.


\subsubsection*{Proof}

Consider first $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)\subseteq L^{2}\left(\mathbb{R}^{n}\right)$.
\begin{align*}
\left\langle \mathcal{F}f,\mathcal{F}g\right\rangle _{L^{2}\left(\mathbb{R}^{n}\right)} & =\int_{\mathbb{R}^{n}}\overline{\left(\mathcal{F}f\right)\left(x\right)}\left(\mathcal{F}g\right)\left(x\right)\dd^{n}x\stackrel{?}{=}\int\overline{f}\left(x\right)g\left(x\right)\dd^{n}x\\
 & =T_{\overline{\mathcal{F}}\,\overline{f}}\left(\mathcal{F}g\right)=\left(\overline{\mathcal{F}}T_{\overline{f}}\right)\left(\mathcal{F}g\right)=T_{\overline{f}}\left(\overline{\mathcal{F}}\mathcal{F}g\right)=\\
 & \stackrel{\overline{\mathcal{F}}\mathcal{F}=1}{=}T_{\overline{f}}\left(g\right)=\int\overline{f}\left(x\right)g\left(x\right)\dd^{n}x
\end{align*}
$\mathcal{S}\left(\mathbb{R}^{n}\right)$ is dense in $L^{2}\left(\mathbb{R}^{n}\right)$.
Because $\mathcal{F}$ is continuous, $\mathcal{F}$ is also isometric
on $L^{2}\left(\mathbb{R}^{n}\right)$.\\
For $f\in L^{2}\left(\mathbb{R}^{n}\right)$ choose $f_{n}\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
with $f_{n}\to f$ converging in $L^{2}\left(\mathbb{R}^{n}\right)$.
Then holds for all $n\in\mathbb{N}$:
\begin{align*}
\norm{f_{n}}_{L^{2}} & =\norm{\mathcal{F}f_{n}}
\end{align*}
In the limes $n\to\infty$ we get, since $\mathcal{F}$ is continuous:
\begin{align*}
\norm f & =\norm{\mathcal{F}f}
\end{align*}
\qqed


\section{Applications to Partial Differential Equations with Constant Coefficients}

Consider as example the Poisson equation
\begin{align*}
\upDelta u & =f
\end{align*}
 in $\mathbb{R}^{n}$ with a given $f$ and assume for simplicity
$f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$. After a Fourier transform
and defining $\hat{u}:=\mathcal{F}u$ and $\hat{f}=\mathcal{F}f$
we get:
\begin{align*}
\left(-\norm p^{2}\right)\hat{u}\left(p\right) & =\hat{f}\left(p\right)\\
\Rightarrow\qquad\hat{u}\left(p\right) & =-\frac{\hat{f}\left(p\right)}{\norm p^{2}}
\end{align*}
Then $\overline{\mathcal{F}}\hat{u}$ is a solution of the Poisson
equation.
\begin{itemize}
\item For $\norm p^{-2}\hat{f}\left(p\right)\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
the method works directly and one gets a $u\in\mathcal{S}\left(\mathbb{R}^{n}\right)$.
\item In the case of $n\ge3$, $\hat{u}=-\norm p^{-2}\hat{f}\left(p\right)$
is a regular distribution. (If $n<3$ the integral does not necessarily
converge.)
\begin{align*}
\left(T_{\hat{u}}\right)\left(g\right) & :=\int\left(-\frac{\hat{f}\left(p\right)}{\norm p^{2}}\right)g\left(p\right)\dd^{n}p
\end{align*}
Therefore $u:=\overline{\mathcal{F}}T_{\hat{u}}$ is a distributional
solution of the Poisson equation, so we get $\upDelta u=T_{f}$.

\begin{description}
\item [{Problem:}] The distributional solution is not unique, because e.g.
\begin{align*}
\hat{u}\left(p\right) & =-\frac{\hat{f}\left(p\right)}{\norm p^{2}}+c\delta\left(p\right)
\end{align*}
is also a solution. Therefore we have to specify the behavior of $u\left(x\right)$
in the limit $\norm x\to\infty$.
\end{description}
\end{itemize}

\chapter{The Laplace equation\texorpdfstring{ in $\Omega\subseteq\mathbb{R}^{n}$}{}}

In this chapter we always consider an open subset $\Omega\subseteq\mathbb{R}^{n}$
with boundary $\partial\Omega$. With the Laplacian
\begin{align}
\upDelta & =\frac{\partial^{2}}{\partial x_{1}^{2}}+\ldots+\frac{\partial^{2}}{\partial x_{n}^{2}}
\end{align}
the Laplace equation can be written as:
\begin{align*}
\upDelta u & =0
\end{align*}
The inhomogeneous Laplace equation is called Poisson equation:
\begin{align*}
\upDelta u & =f
\end{align*}
For both one needs to specify boundary conditions on $\partial\Omega$
to get a unique solution.

\setcounter{section}{-1}


\section{Reminder}


\subsection{Theorem \textmd{(Gauss's Theorem)}}

If $Y$ is a smooth vector field on the closure $\overline{\Omega}$
and $\partial\Omega$ is smooth with outer normal $\nu$, then holds:
\begin{align}
\int_{\Omega}\text{div}\left(Y\right)\underbrace{\dd^{n}x}_{=\dd\mu} & =\int_{\partial\Omega}\left\langle Y,\nu\right\rangle \dd\mu_{\partial\Omega}
\end{align}



\subsubsection*{(Proof omitted)}


\subsection{Theorem \textmd{(Green's Identities)}}

For $u,w\in C^{\infty}\left(\overline{\Omega}\right)$ holds:
\begin{align}
\int_{\Omega}w\upDelta u\dd\mu_{\Omega} & =\int_{\partial\Omega}w\left(\nabla_{\nu}u\right)\dd\mu_{\partial\Omega}-\int_{\Omega}\left\langle \nabla w,\nabla u\right\rangle \dd\mu_{\Omega}\\
\int_{\Omega}\left(w\left(\upDelta u\right)-\left(\upDelta w\right)u\right)\dd\mu_{\Omega} & =\int_{\partial\Omega}\left(w\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}w\right)u\right)\dd\mu_{\partial\Omega}
\end{align}



\subsubsection*{Proof}

We use $\upDelta=\text{div}\,\text{grad}$ and integrate by parts:
\begin{align*}
\int_{\Omega}w\upDelta u\dd\mu_{\Omega} & =\int_{\Omega}w\cdot\text{div}\left(\nabla u\right)\dd\mu_{\Omega}=\int_{\Omega}\text{div}\left(w\nabla u\right)-\left\langle \nabla w,\nabla u\right\rangle \dd\mu_{\Omega}
\end{align*}
Then one can use Gauss's theorem to get the first identity. Now one
subtracts the identity with $w$ and $u$ commuted:
\begin{align*}
w\upDelta u-u\upDelta w & =\text{div}\left(w\nabla u\right)-\left\langle \nabla w,\nabla u\right\rangle -\left(\text{div}\left(u\nabla w\right)-\left\langle \nabla u,\nabla w\right\rangle \right)=\\
 & \stackrel{\left\langle .,.\right\rangle \text{ symmetric}}{=}\text{div}\left(w\nabla u\right)-\text{div}\left(u\nabla w\right)
\end{align*}
Using Gauss's theorem the second identity follows.\qqed


\section{Representation Formulas for Harmonic Functions}


\subsection{Definition \textmd{(Harmonic Functions)}}

A function $u\in C^{2}\left(\overline{\Omega}\right)$ is called \emph{harmonic},
if the Laplacian vanishes:
\begin{align*}
\upDelta u & =0
\end{align*}
The harmonic functions form a vector space.


\subsubsection*{Examples}
\begin{itemize}
\item Constant or linear functions
\item $u\left(x_{1},x_{2}\right)=x_{1}^{2}-x_{2}^{2}$ is harmonic on $\mathbb{R}^{2}$.
\item Holomorphic functions on $\Omega\subseteq\mathbb{C}\stackrel{\sim}{=}\mathbb{R}^{2}$
\end{itemize}
Consider now \emph{spherically symmetric harmonic functions}. For
this we choose polar coordinates $\left(r,\vartheta,\varphi\right)$
in $\mathbb{R}^{3}$:
\begin{align*}
x & =r\cos\left(\vartheta\right)\\
y & =r\sin\left(\vartheta\right)\cos\left(\varphi\right)\\
z & =r\sin\left(\vartheta\right)\sin\left(\varphi\right)
\end{align*}
More general in $\mathbb{R}^{n}$ with $n\in\mathbb{N}_{\ge2}$ we
choose $r=\norm x$ and $\omega\in S^{n-1}$. Regard $\mathbb{R}^{n}$
with the Euclidian metric as a Riemannian manifold $\left(M,g\right)$.
Polar coordinates give a special chart on $\Omega\subseteq M$ with
$0\not\in\Omega$. The we can calculate $\upDelta=\LBO$ as Laplace-Beltrami
operator in polar coordinates. The metric is:
\begin{align*}
g & =\left(\begin{array}{cc}
1 & 0\\
0 & r^{2}g_{S^{n-1}}
\end{array}\right) & g^{-1} & =\left(\begin{array}{cc}
1 & 0\\
0 & r^{-2}g_{S^{n-1}}^{-1}
\end{array}\right)
\end{align*}
\begin{align*}
\det\left(g\right) & =r^{2\left(n-1\right)}g_{S^{n-1}}\\
\sqrt{\det\left(g\right)} & =r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}
\end{align*}
Now the Laplace-Beltrami operator can be calculated with the \emph{Koszul
formula}:
\begin{align}
\LBO u & =\nabla_{j}\nabla^{j}u=\frac{1}{\sqrt{\det\left(g\right)}}\frac{\partial}{\partial x^{j}}\left(\sqrt{\det\left(g\right)}g^{jk}\frac{\partial}{\partial x^{k}}u\right)=\\
 & =\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial x^{j}}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}g^{jk}\frac{\partial}{\partial x^{k}}u\right)=\nonumber \\
 & =\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial r}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}\frac{\partial}{\partial r}u\right)+\nonumber \\
 & \qquad+\sum_{j,k=2}^{n}\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial x^{j}}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}\frac{1}{r^{2}}\left(g_{S^{n-1}}\right)^{jk}\frac{\partial}{\partial x^{k}}u\right)=\nonumber \\
 & =\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}u\right)+\frac{1}{r^{2}}\LBO_{S^{n-1}}u\nonumber 
\end{align}
The important formula is:
\begin{align}
\LBO & =\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}\,.\,\right)+\frac{1}{r^{2}}\LBO_{S^{n-1}}
\end{align}
For spherically symmetric solutions $\Gamma\in C^{\infty}\left(\mathbb{R}^{n}\setminus\left\{ 0\right\} \right)$,
the Laplace equation reads:
\begin{align*}
\LB\Gamma=\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}\Gamma\left(r\right)\right) & =0
\end{align*}


%DATE: Mi 8.5.13

This gives:
\begin{align*}
r^{n-1}\frac{\partial}{\partial r}\Gamma\left(r\right) & =c\\
\frac{\partial}{\partial r}\Gamma\left(r\right) & =cr^{1-n}
\end{align*}
\begin{align*}
\Gamma\left(r\right) & =a+C\int^{r}\tau^{1-n}\dd\tau=\begin{cases}
a+\tilde{c}\ln\left(r\right) & \text{if }n=2\\
a+\frac{c}{r^{n+2}} & \text{if }n>2
\end{cases}
\end{align*}
Now we choose specific values for $a$ and $c$ or $\tilde{c}$.


\subsection{Definition \textmd{(Fundamental Solution of Laplace Equation)}}

The \emph{fundamental solution} $\Gamma$ of the Laplace equation
in $\mathbb{R}^{n}$ is defined by:
\begin{align}
\Gamma\left(x,y\right) & =\Gamma\left(\norm{x-y}\right):=\begin{cases}
\frac{1}{2\pi}\ln\left(\norm{x-y}\right) & \text{if }n=2\\
\frac{1}{n\left(2-n\right)\omega_{n}}\norm{x-y}^{2-n} & \text{if }n>2
\end{cases}
\end{align}
Here $\omega_{n}:=\mu\left(B_{1}\left(0\right)\right)$ is the Lebesgue
measure of the unit ball.

For example for $n=3$ we have $\omega_{3}=\frac{4\pi}{3}$ and thus:
\begin{align}
\Gamma\left(x,y\right) & =\frac{1}{3\left(-1\right)\frac{4\pi}{3}}\cdot\frac{1}{\norm{x-y}}=-\frac{1}{4\pi}\frac{1}{\norm{x-y}}
\end{align}



\subsection{Theorem \textmd{(Green's representation)}}

Let $\Omega\subseteq\mathbb{R}^{n}$ be open with smooth boundary
and $u\in C^{2}\left(\overline{\Omega}\right)$. Then for any $y\in\Omega$
holds:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align}
For harmonic functions with $\upDelta u=0$, this simplifies to:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align}
Thus $u$ has an explicit representation in terms of its boundary
values on $\partial\Omega$.


\subsubsection*{Proof}

Choose $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(y\right)\subseteq\Omega$.
\begin{align*}
\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}\underbrace{\Gamma\left(x,y\right)}_{\text{smooth}}\underbrace{\left(\upDelta u\right)\left(x\right)}_{\text{continuous}}\dd\mu\left(x\right)
\end{align*}


\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[scale=2]{>}};},postaction={decorate}},scale=0.8]
  \draw (-0.1,-0.1) -- (0.1,0.1);
  \draw (-0.1,0.1) -- (0.1,-0.1);
  \node[right=0pt] at (0,0) {$y$};
  \draw (0,0) circle(1);
  \draw[dashed] (0,0) -- node[above left=-2pt]{$\varepsilon$} ({cos(100)},{sin(100)});
  \draw plot[smooth cycle,tension=.7,scale=2] coordinates{(0,-2) (1,-0.95) (2,0.2) (1.5,1.4) (0,2) (-2,-0.5)};
  \node at (0.5,4.5) {$\Omega$};
  \foreach \x in {20,80,...,360} {
    \draw[arr, orange] ({cos(\x)},{sin(\x)}) -- ({1.5*cos(\x)},{1.5*sin(\x)});
    \draw[arr] ({cos(\x)},{sin(\x)}) -- ({0.5*cos(\x)},{0.5*sin(\x)});
	}
  \node[orange] at (1.5,0.3) {$\nu$};
  \draw[arr] (0,4) -- (-0.3,4.45);
  \draw[arr] (4.05,1) -- (4.55,1);
  \draw[arr] (2,-1.9) -- (2.3,-2.2);
  \draw[arr] (-2,-3.27) -- node[below right=2pt]{$\nu$} (-2.25,-3.74);
  \draw[arr] (-3,1.2) -- (-3.4,1.5);
\end{tikzpicture}
\par\end{centering}

\caption{Outer normal $\nu$ of $\Omega\setminus B_{\varepsilon}\left(y\right)$
(black) and of $B_{\varepsilon}\left(y\right)$ (orange) }
\end{figure}


We apply the second Green's identity to obtain with $v\left(x\right):=\Gamma\left(x,y\right)$:
\begin{align*}
\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}\big(v\cdot\upDelta u-\underbrace{\left(\upDelta v\right)}_{=0}u\big)\dd\mu & =\int_{\partial\left(\Omega\setminus B_{\varepsilon}\left(y\right)\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial\Omega}=\\
 & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}+\\
 & \qquad-\int_{\partial B_{\varepsilon}\left(y\right)}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\nabla_{\nu}\Gamma\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)}
\end{align*}
The minus in front of $\int_{\partial B_{\varepsilon}\left(y\right)}$
comes from the fact, that the outer normal of $\partial\left(\Omega\setminus B_{\varepsilon}\left(y\right)\right)$
shows in the opposite direction of the outer normal of $\partial B_{\varepsilon}\left(y\right)$.
The left side of the integral gives in the limit $\varepsilon\searrow0$:
\begin{align*}
\lim_{\varepsilon\searrow0}\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}v\cdot\upDelta u\dd\mu & =\int_{\Omega}v\cdot\upDelta u\dd\mu=\int_{\Omega}\Gamma\left(x,y\right)\cdot\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
We estimate the integral over $\partial B_{\varepsilon}\left(y\right)$
in the limit $\varepsilon\searrow0$:
\begin{align*}
\abs{\int_{\partial B_{\varepsilon}\left(y\right)}\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)}} & \le\Gamma\left(\varepsilon\right)\sup_{B_{\varepsilon}\left(y\right)}\norm{\nabla u}\cdot\underbrace{n\omega_{n}}_{\sr{}{\text{surface area of}}{\text{the unit sphere}}}\varepsilon^{n-1}\sim\\
 & \sim\begin{cases}
\varepsilon & \text{if }n>2\\
\varepsilon\ln\left(\varepsilon\right) & \text{if }n=2
\end{cases}\xrightarrow{\varepsilon\searrow0}0
\end{align*}
Now we expand the second part around $\varepsilon=0$:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(y\right)}\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)} & =\underbrace{\frac{\partial}{\partial\varepsilon}\Gamma\left(\varepsilon\right)}_{=\frac{1}{n\omega_{n}}\varepsilon^{1-n}}\underbrace{\int_{\partial B_{\varepsilon}\left(y\right)}u\left(x\right)\dd\mu_{B_{\varepsilon}\left(y\right)}}_{=u\left(y\right)n\omega_{n}\varepsilon^{n-1}+o_{0}\left(\varepsilon^{n-1}\right)}=\\
 & =u\left(y\right)+o_{0}\left(\varepsilon^{0}\right)\xrightarrow{\varepsilon\searrow0}u\left(y\right)
\end{align*}
This gives:
\begin{align*}
\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}+u\left(y\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
\qqed


\subsection{Corollary \textmd{(Laplacian of Fundamental Solution is Delta Distribution)}}

For any $\varphi\in C_{0}^{\infty}\left(\Omega\right)$ holds:
\begin{align}
\varphi\left(y\right) & =\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)\label{eq:phi-as-integral}
\end{align}
This can also be expressed in terms of distributions as:
\begin{align}
\upDelta_{x}\Gamma\left(x,y\right) & =\delta^{\left(n\right)}\left(x-y\right)
\end{align}
More correctly, for fixed $y\in\mathbb{R}^{n}$, $T\left(x\right):=T_{\Gamma\left(x,y\right)}$
defines a regular distribution. Equation (\ref{eq:phi-as-integral})
means, that for all $\varphi\in C_{0}^{\infty}\left(\Omega\right)\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$:
\begin{align*}
\left(\upDelta T\right)\left(\varphi\right) & =\varphi\left(y\right)\\
\Leftrightarrow\qquad\upDelta T & =\delta_{y}
\end{align*}



\subsubsection*{Proof}

Since the support of $\varphi$ lies inside of $\Omega$, the first
term in Green's representation vanishes:
\begin{align*}
\varphi\left(y\right) & =\int_{\partial\Omega}\left(\varphi\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}\varphi\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)=\\
 & =\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
\qqed

Next we investigate the existence of solutions.
\begin{align}
\upDelta u & =0 & u\big|_{\partial\Omega} & =u_{0} &  & \text{Dirichlet problem}\\
\upDelta u & =0 & \nabla_{\nu}u\big|_{\partial\Omega} & =u_{1} &  & \text{Neumann problem}
\end{align}
The problem is, that the representation
\begin{align*}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align*}
needs booth $u$ and $\nabla_{\nu}u$ on the boundary. Suppose we
want to solve the Dirichlet problem. Then $u_{0}=u\big|_{\partial\Omega}$
is given, but $\nabla_{\nu}u\big|_{\partial\Omega}$ is unknown.


\section{The Green's Function}

Consider the Dirichlet problem for the Poisson equation:
\begin{align}
\upDelta u\left(x\right) & =f\left(x\right)\qquad\fall_{x\in\Omega} & u\big|_{\partial\Omega} & =\varphi
\end{align}
Assume $u\in C^{2}\left(\overline{\Omega}\right)$, $f\in C^{0}\left(\overline{\Omega}\right)$
and $\varphi\in C^{2}\left(\partial\Omega\right)$.


\subsection{Definition \textmd{(Green's function)}}

A function $G\left(x,y\right)$ defined for $x,y\in\overline{\Omega}$
with $x\not=y$ is called \emph{Green's function} for the domain $\Omega$
if the following conditions are satisfied:
\begin{enumerate}[label=\roman*)]
\item For all $x\in\partial\Omega$ holds ${\displaystyle G\left(x,y\right)=0}$.
\item $h\left(x,y\right):=G\left(x,y\right)-\Gamma\left(x,y\right)$ is
in $C^{2}\left(\Omega\right)$, even for $x=y$, and harmonic in $x\in\Omega$.
\end{enumerate}

\subsection{Proposition \textmd{(Solution of Dirichlet Problem)}}

For a solution $u$ of the Dirichlet problem for the Poisson equation
holds:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}f\left(x\right)G\left(x,y\right)\dd\mu\left(x\right)
\end{align}



\subsubsection*{Proof}

\begin{align*}
\int_{\Omega}h\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right) & =\int_{\Omega}h\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)=\\
 & \sr ={\text{2. Green's}}{\text{identity}}\int_{\partial\Omega}\left(h\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}h\left(x,y\right)\right)\cdot u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align*}
Now we add the Green's representation
\begin{align*}
\int_{\Omega}\Gamma\left(x,y\right)f\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}\Gamma\left(x,y\right)\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+u\left(y\right)
\end{align*}
to get:
\begin{align*}
\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(G\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}G\left(x,y\right)\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+u\left(y\right)
\end{align*}
Since $G\left(x,y\right)=0$ on $\partial\Omega$, the proposition
follows.\qqed


\subsection{Theorem \textmd{(Symmetry of the Green's Function)}}

For all $x,y\in\Omega$ with $x\not=y$ holds $G\left(x,y\right)=G\left(y,x\right)$.


\subsubsection*{Proof}

\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[scale=0.7]
  \node at (0.5,4.5) {$\Omega$};
  \draw[clip] plot[smooth cycle,tension=.7,scale=2] coordinates{(0,-2) (1,-0.95) (2,0.2) (1.5,1.4) (0,2) (-2,-0.5)};
  \foreach \x in {-4.5,-3,...,2}     \draw (\x,-5) -- ({\x + 3},5);
  \draw[fill=white] (1,0) circle(1);
  \draw (1,0) +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \node[right=0pt] at (1,0) {$y$};
  \draw[dashed] (1,0) -- node[above left=-2pt]{$\varepsilon$} +({cos(90)},{sin(90)});
  \draw[fill=white] (-2.5,-1) circle(1);
  \draw (-2.5,-1) +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \node[right=0pt] at (-2.5,-1) {$x$};
  \draw[dashed] (-2.5,-1) -- node[above left=-2pt]{$\varepsilon$} +({cos(90)},{sin(90)});
\end{tikzpicture}
\par\end{centering}

\caption{$B_{\varepsilon}\left(x\right)\subseteq\Omega$, $B_{\varepsilon}\left(y\right)\subseteq\Omega$,
$B_{\varepsilon}\left(x\right)\cap B_{\varepsilon}\left(y\right)=\emptyset$}
\end{figure}


Choose $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(x\right)$
and $B_{\varepsilon}\left(y\right)$ are disjoint subsets of $\Omega$.
\begin{align*}
u\left(z\right) & :=G\left(z,x\right) & v\left(z\right) & :=G\left(z,y\right)
\end{align*}
It holds $u,v\in C^{2}\left(\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)\right)$
and $u,v$ are harmonic. Moreover for $z\in\partial\Omega$ holds:
\begin{align*}
u\left(z\right) & =G\left(z,x\right)=0 & v\left(z\right) & =G\left(z,y\right)=0
\end{align*}
Apply again the second Green's identity:
\begin{align*}
0 & =\int_{\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}\big(v\underbrace{\left(\upDelta u\right)}_{=0}-\underbrace{\left(\upDelta v\right)}_{=0}u\big)\dd\mu=\\
 & =\int_{\partial\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}
\end{align*}
Moreover, the boundary values on $\partial\Omega$ vanish. We conclude:
\begin{align*}
0 & =\int_{\partial B_{\varepsilon}\left(x\right)\cup\partial B_{\varepsilon}\left(y\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)\cup\partial B_{\varepsilon}\left(y\right)}
\end{align*}
Consider the integral over $\partial B_{\varepsilon}\left(x\right)$
first. Since $G=\Gamma+h$ and $h\in C^{2}$ is bounded, we know for
all $z\in\partial B_{\varepsilon}\left(x\right)$:
\begin{align*}
u\left(z\right) & =G\left(z,x\right)\sim\Gamma\left(z,x\right)\sim\begin{cases}
\ln\left(\varepsilon\right) & \text{if }n=2\\
\varepsilon^{2-n} & \text{if }n>2
\end{cases}
\end{align*}
Since $\nabla_{\nu}v$ is also bounded due to $v\in C^{2}\left(B_{\varepsilon}\left(x\right)\right)$,
we get:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}\left(\nabla_{\nu}v\right)u\dd_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}0
\end{align*}
The other term gives:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}v\left(\nabla_{\nu}u\right)\dd_{\partial B_{\varepsilon}\left(x\right)} & \sr ={\nabla_{\nu}u=\frac{\partial}{\partial\varepsilon}\Gamma\left(\varepsilon\right)+o_{0}\left(\varepsilon^{0}\right)=}{=\tilde{c}\varepsilon^{1-n}+o_{0}\left(\varepsilon^{0}\right)}cv\left(x\right)\varepsilon^{1-n}\underbrace{\int_{\partial B_{\varepsilon}\left(x\right)}1\dd\mu_{\partial B_{\varepsilon}\left(x\right)}}_{=n\omega_{n}\varepsilon^{n-1}}+o_{0}\left(\varepsilon\right)\xrightarrow{\varepsilon\searrow0}cv\left(x\right)
\end{align*}
Here the constant $c\not=0$ does not vanish. Now follows:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}\left(\left(\nabla_{\nu}v\right)u-v\left(\nabla_{\nu}u\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}cv\left(x\right)\\
\int_{\partial B_{\varepsilon}\left(y\right)}\left(\left(\nabla_{\nu}v\right)u-v\left(\nabla_{\nu}u\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}cu\left(y\right)
\end{align*}
Adding these two integrals gives:
\begin{align*}
0 & =c\left(v\left(x\right)-u\left(y\right)\right)\\
\Rightarrow\qquad G\left(x,y\right) & =v\left(x\right)=u\left(y\right)=G\left(y,x\right)
\end{align*}
\qqed

Any solution $u$ of the Dirichlet problem
\begin{align*}
\upDelta u & =f & u\big|_{\partial\Omega} & =\varphi
\end{align*}
has the representation:
\begin{align*}
u\left(y\right) & =\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
We define:
\begin{align*}
u\left(y\right) & :=\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
Since $G$ is symmetric, $G\left(x,y\right)=G\left(y,x\right)$, the
equation $\upDelta_{x}G\left(x,y\right)=\delta^{\left(n\right)}\left(x-y\right)$
implies $\upDelta_{y}G\left(x,y\right)=\delta^{\left(n\right)}\left(x-y\right)$
as well. As a consequence, a formal computation gives:
\begin{align*}
\upDelta_{y}u\left(y\right) & =\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}\delta^{\left(n\right)}\left(x-y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\delta^{\left(n\right)}\left(x-y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
For $y\in\Omega$ the first term vanishes, so we get:
\begin{align*}
\upDelta_{y}u\left(y\right) & =f\left(y\right)
\end{align*}
This formal calculation can be made rigorous, once an explicit Green's
function is given.


\part*{Appendix\thispagestyle{empty}}

\addcontentsline{toc}{part}{Appendix}

\fancyhead[R]{}
\fancyhead[C]{Appendix}


\chapter*{Acknowledgements}

\addcontentsline{toc}{section}{\hspace*{2.7em}Acknowledgements}

\fancyhead[R]{Acknowledgements}

My special thanks goes to Professor Finster, who gave this lecture
and allowed me to publish this script of the lecture.

I would also like to thank all those, who found errors by careful
reading and told me of them.

\vspace{1cm}


\hfill{}Andreas Völklein

\label{END}
\end{document}
