%% LyX 2.0.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,ngerman,english]{scrreprt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.6cm,bmargin=3.5cm,lmargin=2.6cm,rmargin=2.6cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{color}
\usepackage{babel}
\usepackage{float}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=false,
 breaklinks=true,pdfborder={0 0 0},backref=page,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Partial Differential Equations 1},
 pdfauthor={Andreas Völklein},
 pdfkeywords={Partial Differential Equations, Mathematics}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
\newcommand{\noun}[1]{\textsc{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{enumitem}		% customizable list environments
\newlength{\lyxlabelwidth}      % auxiliary length 

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tikz,pgfplots}
%\usepackage{tikz-3dplot,cancel,polynom}
\usetikzlibrary{matrix,arrows,calc,decorations,decorations.markings,intersections,shapes}
\usetikzlibrary{external}
\tikzexternalize
\usepackage{latexsym,stmaryrd,stackrel,braket,bbm,subfig,framed,esvect,scrhack,calc,upgreek}
\usepackage [OMLmathrm,OMLmathbf,sfdefault=fav]{isomath}
\usepackage[explicit]{titlesec}
\usepackage[activate]{pdfcprot}

\pgfkeys{/pgf/number format/dec sep={\text{,}}}
\pgfplotsset{compat=newest}

% Inhaltsverzeichnis
\usepackage[subfigure]{tocloft}

\tocloftpagestyle{fancy}

\renewcommand{\cftchapindent}{1 em}
\renewcommand{\cftchapnumwidth}{1.5 em}

\renewcommand{\cftsecindent}{2.7 em}
\renewcommand{\cftsecnumwidth}{2.5em}

\renewcommand{\cftsubsecindent}{5.2 em}
\renewcommand{\cftsubsecnumwidth}{3.8 em}

\renewcommand{\cftsubsubsecindent}{9 em}
\renewcommand{\cftsubsubsecnumwidth}{4.5 em}

% Mathe-Operatoren
\DeclareMathOperator*{\exsop}{\exists}
\DeclareMathOperator*{\exsgop}{\exists!}
\DeclareMathOperator*{\fallop}{\forall}
\DeclareMathOperator*{\bcupdop}{\dot{\bigcup}}
\DeclareMathOperator*{\bcapdop}{\dot{\bigcap}}

%Operatornorm
\newcommand{\opnor}[1]{\abs{\hspace*{-1.1pt}\norm{#1}\hspace*{-1.1pt}}}

% nicht-totales Differential
\newcommand{\dBar}{\mathchar'26\mkern-12mu \textnormal{d}}

% Angström
\newcommand{\ang}{\textup{\AA}}

% schöne Vektorpfeile
\renewcommand{\vec}[1]{\vv{#1}}

% Rotieren
\newcommand{\Rotate}[1]{
\tikzset{external/export next=false}
\begin{tikzpicture}
\node[rotate=90] {\ensuremath{#1}};
\end{tikzpicture}
}

%QED-Zeichen (Box)
\newcommand{\qed}{\ensuremath{\Box}}
\newcommand{\qqed}[1][\arabic{chapter}.\arabic{section}\ifnum\arabic{subsection}>0{.\arabic{subsection}}\fi]{\hspace*{1mm}\hfill\qed\ensuremath{_{\text{#1}}}}

% Mengen Modulo
\newcommand{\moduloT}[2]{
\mbox{\raisebox{0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large /}
\raisebox{-0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Links Modulo
\newcommand{\lmoduloT}[2]{
\mbox{\raisebox{-0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large \ensuremath{\backslash}}
\raisebox{0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Für Z/2Z, um nicht soviel schreiben zu müssen
\newcommand{\modloT}[2]{\moduloT{ \mathbb{#1}}{#2\mathbb{#1}}}

%Laplace-Beltrami-Operator
\newcommand{\LBO}{
\begin{minipage}{6mm}
 \tikzset{external/export next=false}
 \begin{tikzpicture}
   \node at (0,0){$\upDelta$};
   \draw[line width=0.75] (0.25,-0.13) -- (0.1,0.15);
 \end{tikzpicture}
\end{minipage}
}

%Die Modulo-Kommandos in klein, für die Darstellungen unter Quantoren.
\newcommand{\moduloScriptT}[2]{
\mbox{\raisebox{0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize /}
\raisebox{-0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\lmoduloScriptT}[2]{
\mbox{\raisebox{-0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize \ensuremath{\backslash}}
\raisebox{0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\modloScriptT}[2]{\moduloScriptT{ \mathbb{#1}}{#2\mathbb{#1}}}

% stehendes Winkelzeichen
\newcommand{\winkel}{
\tikzset{external/export next=false}
\begin{tikzpicture}[scale=0.25]
\draw ({-2+3^(1/2)},0) -- (0,1) -- ({2-3^(1/2)},0);
\draw ($(0,1) + ({cos(235)*0.7},{sin(315)*0.7})$) arc (235:315:0.7);
\end{tikzpicture}}

% Wurzel mit Häkchen
\newcommand{\hsqrt}[2][{}]{\setbox0=\hbox{$\sqrt[#1]{\phantom{|}\!\! #2\hspace*{1pt}}$}\dimen0=\ht0
  \advance\dimen0-0.2\ht0
  \setbox2=\hbox{\vrule height\ht0 depth -\dimen0}
  {\box0\lower0.4pt\box2}}

% Damit nicht immer "Kapitel 1" etc. über der Kapitelüberschrift steht
\titleformat{\chapter}
  {\huge\bfseries}
  {\textrm{\thechapter} }{0pt}
  {\textrm{#1} \thispagestyle{fancy}
  }

% Neudefinition der Abschnittsmarker für die Kopfzeile
\renewcommand\partmark[1]{\markboth{#1}{}}
\renewcommand\chaptermark[1]{\markright{\arabic{chapter} #1}}
\renewcommand\sectionmark[1]{}
\renewcommand\subsectionmark[1]{}

% Schriften auf Serif umstellen
\addtokomafont{descriptionlabel}{\rmfamily}
\addtokomafont{disposition}{\rmfamily}

% Zeilenumbrüche in Gleichungen
 \allowdisplaybreaks

% Kopf- und Fußzeile
% Höhe der Kopfzeile
\setlength{\headheight}{14pt}
% obere Trennlinie
%\renewcommand{\headrulewidth}{0.4pt}
\fancyhf{} %alle Kopf- und Fußzeilenfelder bereinigen
\fancyhead[L]{\textbf{Partial Differential Equations I}} %Kopfzeile links
%\fancyhead[C]{\leftmark} %zentrierte Kopfzeile
\fancyhead[R]{\rightmark} %Kopfzeile rechts
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END-front}} %Seitenzahl der Front-Matter

\AtBeginDocument{
  \def\labelitemi{\normalfont\bfseries{--}}
  \def\labelitemii{\(\circ\)}
  \def\labelitemiii{\(\triangleright\)}
}

\makeatother

\begin{document}




\selectlanguage{ngerman}%


\selectlanguage{english}%
\global\long\def\norm#1{\left\lVert #1\right\rVert }


\global\long\def\abs#1{\left\lvert #1\right\rvert }


\global\long\def\opnorm#1{\opnor{#1}}


\global\long\def\BRA#1{\Bra{#1}}


\global\long\def\KET#1{\Ket{#1}}


\global\long\def\BraKet#1{\Braket{#1}}


\global\long\def\mins{\textnormal{-}}


\global\long\def\LB{\LBO}


\global\long\def\exs{\exsop}


\global\long\def\exsg{\exsgop}


\global\long\def\fall{\fallop}


\global\long\def\bcupd{\bcupdop}


\global\long\def\bcapd{\bcapdop}


\global\long\def\sr#1#2#3{\underset{#3}{\overset{#2}{#1}}}


\global\long\def\dd{\textnormal{d}}


\global\long\def\DD{\textnormal{D}}


\global\long\def\dbar{\dBar}


\global\long\def\TT{\textnormal{T}}


\global\long\def\ii{\textbf{i}}


\global\long\def\modulo#1#2{\moduloT{#1}{#2}}


\global\long\def\lmodulo#1#2{\lmoduloT{#1}{#2}}


\global\long\def\modlo#1#2{\modloT{#1}{#2}}


\global\long\def\moduloScript#1#2{\moduloScriptT{#1}{#2}}


\global\long\def\lmoduloScript#1#2{\lmoduloScriptT{#1}{#2}}


\global\long\def\modloScript#1#2{\modloScriptT{#1}{#2}}


\global\long\def\vek#1{\vectorsym{#1}}


\global\long\def\mat#1{\matrixsym{#1}}


\global\long\def\ten#1{\tensorsym{#1}}


\global\long\def\msd#1{\mathstrut_{#1}}


\global\long\def\msu#1{\mathstrut^{#1}}


\pagenumbering{roman}


\title{\hspace*{1mm}\vspace*{-15mm}\\
{\Huge{Partial Differential Equations I}}}


\author{\vspace*{-5mm}\\
\textit{\small{lecture by}}\\
\textit{\noun{\small{Prof. Dr. Felix Finster}}}\\
\textit{\small{during the summer semester 2013}}\\
\textit{\small{revision and layout in \LyX{} by}}\\
\textit{\noun{\small{Andreas Völklein}}}\\
\vspace*{5mm}\\
\includegraphics[clip,width=15cm]{unir}\\
\vspace*{3mm}\\
{\normalsize{Last changed: \today}}\\
\vspace*{-30mm}}

\maketitle
\fancyhead[R]{License}


\subsubsection*{ATTENTION}

This script does \emph{not} replace the lecture.

Therefore it is recommended \emph{strongly} to attend the lecture.

\vfill{}



\subsubsection*{Copyright Notice}

Copyright © 2013 \noun{Andreas Völklein}

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3
or any later version published by the Free Software Foundation;

with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
Texts.

A copy of the license is included in the document entitled “GFDL”.


\subsubsection*{Disclaimer of Warranty}

\noun{Unless otherwise mutually agreed to by the parties in writing
and to the extent not prohibited by applicable law, }\textbf{\noun{the
Copyright Holders and any other party, who may distribute the Document
as permitted above,   provide the Document “as is}}\textbf{”,}\textbf{\noun{
without warranty of any kind}}\noun{, expressed, implied, statutory
or otherwise, including, but not limited to, the implied warranties
of merchantability, fitness for a particular purpose, non-infringement,
the absence of latent or other defects, accuracy, or the absence of
errors, whether or not discoverable.}


\subsubsection*{Limitation of Liability}

\textbf{\noun{In no event}}\noun{ unless required by applicable law
or agreed to in writing }\textbf{\noun{will the Copyright Holders,
or any other party, who may distribute the Document as permitted above,
be liable to you for any damages}}\noun{, including, but not limited
to, any general, special, incidental, consequential, punitive or exemplary
damages, however caused, regardless of the theory of liability, arising
out of or related to this license or any use of or inability to use
the Document, even if they have been advised of the possibility of
such damages.}

\textbf{\noun{In no event will the Copyright Holders'/Distributor's
liability to you}}\noun{, whether in contract, tort (including negligence),
or otherwise, }\textbf{\noun{exceed the amount you paid the Copyright
Holders/Distributor}}\noun{ for the document under this agreement.}


\subsubsection*{Links}

The text of the “GNU Free Documentation License” can also be read
on the following site:
\begin{quote}
\url{https://www.gnu.org/licenses/fdl-1.3.en.html}
\end{quote}
A transparent copy of the recent version of this document can be downloaded
from:
\begin{quote}
\url{https://github.com/andiv/PDE1}
\end{quote}
\newpage{}

\fancyhead[R]{Literature}


\subsection*{Literature}

Elliptic and parabolic partial differential equations:
\begin{itemize}
\item \noun{Jürgen Jost}: \emph{Partial Differential Equations}; Springer,
2007\\
ISBN: 978-0-387-49318-3; \href{http://dx.doi.org/10.1007/978-0-387-49319-0}{doi: 10.1007/978-0-387-49319-0}\\
(good book, but not all details, small errors)
\item \noun{Lawrence C. Evans}: \emph{Partial Differential Equations}; American
Mathematical Society, 2010; ISBN: 978-0-8218-4974-3\\
(part of the lecture follows this book, lots of details)
\item \noun{David Gilborg, Neil S. Trudinger}: \emph{Elliptic Partial Differential
Equations of second order}; Springer, 2001; ISBN: 3-540-41160-7\\
(classic textbook, complete treatment)
\end{itemize}
Hyperbolic partial differential equations (for the lecture ``Partial
Differential Equations II''):
\begin{itemize}
\item \noun{Fritz John}: \emph{Partial Differential Equations}; Springer,
1999\\
ISBN: 0-387-90609-6
\item \noun{Michael E. Taylor}: \emph{Partial Differential Equations I -
III}; Springer, 1997\\
ISBN: 0-387-94653-5, 0-387-94651-9, 0-387-94652-7\\
(nice detailed text books)
\item \noun{Joel Smoller}: \emph{Shock waves and reaction-diffusion equations};
Springer, 1994\\
ISBN: 3-540-94259-9\\
(nicely presented, good motivations, covers most of the material)
\item \noun{Friedrich Sauvigny}: Partial Differential Equations I-II; Springer,
2012\\
ISBN: 978-1-4471-2981-3, 978-1-4471-2984-4;\\
\href{http://dx.doi.org/10.1007/978-1-4471-2981-3}{doi: 10.1007/978-1-4471-2981-3},
\href{http://dx.doi.org/10.1007/3-540-27540-1}{10.1007/3-540-27540-1}
\item and many more $\ldots$
\end{itemize}
{\small{\newpage{}}}\fancyhead[R]{Table of Contents}
\fancyhead[C]{}

\tableofcontents{}\label{END-front}\newpage{}\pagenumbering{arabic}
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END}} % Seitenzahl des Hauptteils
\fancyhead[R]{\rightmark}
%\fancyhead[C]{\leftmark}%DATE: Mi 17.04.2013


\chapter{A Brief Introduction}

An ordinary differential equation (ODE) can be written as:
\begin{align*}
\frac{\dd}{\dd t}u\left(t\right)=\dot{u}\left(t\right) & =v\left(t,u\right)\\
u:I\subseteq\mathbb{R} & \to\mathbb{R}^{N}
\end{align*}
This equation involves only derivatives with respect to \emph{one}
variable $t$.
\begin{align*}
\frac{\partial}{\partial x}f\left(x,y\right)+\frac{\partial}{\partial y}f\left(x,y\right) & =0
\end{align*}
This is an example for a partial differential equation.


\section{Definition \textmd{(Partial Differential Equation)}}

A \emph{partial differential equation} (PDE) is a (scalar) equation,
which involves partial derivatives of an unknown function $u:\Omega\subseteq\mathbb{R}^{n}\to\mathbb{R}$.
We always assume that $\Omega\subseteq\mathbb{R}^{n}$ is open.\\
More generally, a \emph{system of partial differential equations}
is a system of equations involving partial derivatives of a function
$u:\Omega\subseteq\mathbb{R}^{n}\to\mathbb{R}^{N}$.\\
Similarly one can define partial differential equations on manifolds.

For ordinary differential equations we considered the initial-value
problem:
\begin{align*}
\dot{u}\left(t\right) & =v\left(t,u\right) & u\left(t_{0}\right) & =u_{0}
\end{align*}
For partial differential equations one considers
\begin{itemize}
\item the initial-value problem and
\item the boundary-value problem.
\end{itemize}

\section{Examples}
\begin{enumerate}
\item Cauchy-Riemann equations: Let
\begin{align*}
f:\Omega\stackrel{\text{open}}{\subseteq}\mathbb{C} & \to\mathbb{C}
\end{align*}
be holomorphic.
\begin{align*}
f & =a+\ii b & a & :=\text{Re}\left(f\right) & b & :=\text{Im}\left(f\right)
\end{align*}
\begin{align*}
\frac{\partial a}{\partial x} & =\frac{\partial b}{\partial y} & \frac{\partial b}{\partial x} & =-\frac{\partial a}{\partial y}
\end{align*}
This is a system of two partial differential equations.
\begin{align*}
u & :=\left(\begin{array}{c}
a\\
b
\end{array}\right) & u:\Omega\subseteq\mathbb{C}=\mathbb{R}^{2} & \to\mathbb{R}^{2}
\end{align*}
\begin{align*}
\frac{\partial^{2}a}{\partial x^{2}}+\frac{\partial^{2}a}{\partial y^{2}} & =\frac{\partial b}{\partial x\partial y}-\frac{\partial b}{\partial y\partial x}=0
\end{align*}
\begin{align*}
\Rightarrow\qquad\underbrace{\left(\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}\right)}_{=:\upDelta}a & =0 & \upDelta b & =0
\end{align*}
This is the \emph{Laplace equation} with the \emph{Laplace operator
}(or\emph{ Laplacian}) $\upDelta$. Solutions of the Laplace equation
are called \emph{harmonic functions}.
\item Let $\left(M,g\right)$ be a Riemannian manifold. Here exists the
Laplace-Beltrami operator $\LBO$.

\begin{itemize}
\item In the special case $M=\mathbb{R}^{n}$ we have:
\begin{align*}
\upDelta & =\frac{\partial^{2}}{\partial x_{1}^{2}}+\ldots+\frac{\partial^{2}}{\partial x_{n}^{2}}\\
\upDelta\varphi & =0
\end{align*}

\item With the Riemannian metric $g_{ij}$ we can define:
\begin{align*}
\LBO\varphi & =g^{ij}\nabla_{i}\nabla_{j}\varphi=\text{div}\left(\text{grad}\left(\varphi\right)\right)=\frac{1}{\sqrt{\det\left(g\right)}}\partial_{j}\left(\sqrt{\det\left(g\right)}g^{jk}\partial_{k}\varphi\right)
\end{align*}

\end{itemize}

This gives an elliptic equation.

\item Newton's gravitational law: Let $\varrho\left(x\right)$ be the mass
density and $\varphi\left(x\right)$ the Newtonian potential.
\begin{align*}
\upDelta\varphi & =\underbrace{-4\pi\varrho}_{\text{inhomogeneity}}
\end{align*}
Such an inhomogeneous Laplace equation is usually referred to as Poisson
equation and it is elliptic.
\item Heat flow equation (\foreignlanguage{ngerman}{Wärmeleitungsgleichung}):
Let $\varphi\left(t,x\right)$ be the temperature at time $t\in\mathbb{R}$
and position $x\in\mathbb{R}^{n}$.
\begin{align*}
\partial_{t}\varphi\left(t,x\right) & =\upDelta\varphi\left(t,x\right)
\end{align*}
This is a parabolic equation.
\item The Schrödinger equation is a parabolic equation:
\begin{align*}
\ii\hbar\partial_{t}\psi\left(t,x\right) & =\left(-\frac{\hbar^{2}}{2m}\upDelta+V\right)\psi\left(t,x\right)
\end{align*}
Additionally to the the heat flow equation there is the potential
$V$, but more important there is a factor of $\ii$ in front of the
partial derivative. The time-independent Schrödinger equation is:
\begin{align*}
E\psi\left(x\right) & =\left(-\frac{\hbar^{2}}{2m}\upDelta+V\right)\psi\left(x\right)
\end{align*}
This is similar to the Poisson equation and also elliptic.
\item The wave equation
\begin{align*}
\left(\partial_{t}^{2}-\upDelta_{x}\right)\psi\left(t,x\right) & =0
\end{align*}
is hyperbolic. We will consider it in the lecture ``Partial Differential
Equations II''.
\item Maxwell's equations: $E\left(t,x\right)$ is the electric field and
$B\left(t,x\right)$ the magnetic field.
\begin{align*}
\text{div}\left(E\right) & =4\pi\varrho &  & \text{Gauss law}\\
\text{rot}\left(E\right) & =-\partial_{t}B &  & \text{Maxwell}\\
\text{div}\left(B\right) & =0\\
\text{rot}\left(B\right) & =4\pi j-\partial_{t}E &  & \text{Faraday}
\end{align*}
This is a system of 8 partial differential equation.
\item Einstein's field equation:
\begin{align*}
R_{ij}-\frac{1}{2}Rg_{ij} & =4\pi\kappa T_{ij}
\end{align*}
This is a geometric partial differential equation. $R_{ij}$ is the
Ricci curvature, $R$ the scalar curvature and $T_{ij}$ the energy-momentum
tensor. It is a system of 10 partial differential equations.
\item Equations of relativistic quantum mechanics:
\begin{align*}
\left(-\partial_{t}^{2}+\upDelta\right)\psi & =m^{2}\psi
\end{align*}
This is the Klein-Gordon equation with the mass $m$.
\begin{align*}
\ii\gamma^{j}\partial_{j}\psi & =m\psi
\end{align*}
This is the Dirac equation, a system of 4 complex-valued or 8 real-valued
partial differential equations for a particle with spin $\frac{1}{2}$.
\item Water waves can be described by the Korteweg-de Vries equation:
\begin{align*}
\partial_{t}u+u\partial_{x}u+\partial_{x}^{3}u & =0
\end{align*}
\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
  \draw (-4,1) -- (4,1) (-4,-1) -- (4,-1);
  \draw[dashed] (-1,0.7) -- (-1,-0.7) (2,0.7) -- (2,-0.7);
  \draw[thick] plot[smooth,tension=.7] coordinates{(-2,-0.4) (-1.6,-0.25) (-1,0.4) (-0.4,-0.25) (0,-0.4)};
  \draw[thick,xshift=3cm] plot[smooth,tension=.7] coordinates{(-2,-0.4) (-1.6,-0.25) (-1,0.4) (-0.4,-0.25) (0,-0.4)};
  \draw[thick,decoration={markings,mark=at position 1 with {\arrow[scale=1.3]{>}};},postaction={decorate}] (0,0.1) -- (1,0.1);
  \draw plot[smooth cycle,tension=.3] coordinates{(-3.5,-0.3) (-2.75,-0.27) (-2.5,-0.2) (-2.25,0) (-2.5,0.2) (-2.75,0.27) (-3.5,0.3)};
\end{tikzpicture}
\par\end{centering}

\caption{Solitons (discovered by John Russel in 1834): When the ship suddenly
stops, the water flows on along the channel. This wave moves with
a constant speed and its shape stays the same.}


\end{figure}

\item Shock waves: Burger's equation
\begin{align*}
\partial_{t}u+u\partial_{x}u & =0
\end{align*}
is hyperbolic.
\item Turbulence can be described by the incompressible Navier-Stokes equations
for the velocity $v:\Omega\subseteq\mathbb{R}^{3}\to\mathbb{R}^{3}$.
\begin{align*}
\text{div}\left(v\right) & =0\\
\rho\partial_{t}v^{j}+\rho v^{i}\partial_{i}v^{j}-\eta\upDelta v^{j} & =-\partial_{j}P
\end{align*}
Here $\varrho$ is the gas density, $P$ the pressure and $\eta$
the viscosity.
\end{enumerate}

\section{Classification}
\begin{enumerate}[label=\Roman*)]
\item The \emph{order} of a partial differential equation is the highest
order of the derivatives in it.
\begin{align*}
\upDelta u & =f &  & \text{second order}\\
\partial_{t}\varphi & =\upDelta\varphi &  & \text{second order}\\
\partial_{t}u+u\partial_{x}u+\partial_{x}^{3}u & =0 &  & \text{third order}
\end{align*}

\item Algebraic classification:

\begin{enumerate}[label=\alph*)]
\item \emph{Linear} equations: The unknown function $u$ and its derivatives
appear only linearly.
\begin{align*}
\partial_{t}u & =u &  & \text{linear}\\
\partial_{t}u+u\partial_{x}u & =0 &  & \text{non-linear}
\end{align*}

\item Linear \emph{homogeneous} equations: If $u$ is a solution, then $\lambda u$
for $\lambda\in\mathbb{R}$ is also a solution.
\begin{align*}
\upDelta u & =0 &  & \text{linear homogeneous}\\
\upDelta u & =\varrho &  & \text{linear inhomogeneous}\\
\LBO u & =0 &  & \text{linear homogeneous}
\end{align*}

\item Linear with \emph{constant coefficients}:
\begin{align*}
\upDelta u & =\rho &  & \text{linear with constant coefficients}\\
\LBO u & =\varrho &  & \text{in general non-constant coefficients}
\end{align*}

\end{enumerate}
\item Classification by type: elliptic, parabolic, hyperbolic\\
Here we only consider scalar second order equations with $x\in\Omega\subseteq\mathbb{R}^{n}$.
\begin{align*}
F\left(x,u,\DD u,\DD^{2}u\right) & =0\\
F:\Omega\times\mathbb{R}\times\mathbb{R}^{n}\times\mathbb{R}^{n\times n} & \to\mathbb{R}
\end{align*}
\begin{align*}
A_{ij} & :=\frac{\partial F\left(x,u,p_{i},p_{ij}\right)}{\partial p_{ij}}
\end{align*}
is a symmetric $n\times n$ matrix.

\begin{itemize}
\item If $A$ is positive definite, the equation is called \emph{elliptic}.
\item If $A$ has $n-1$ positive and one negative eigenvalue, the equation
is called \emph{hyperbolic}.
\item If $A$ has $n-1$ positive eigenvalues and a non-trivial kernel,
the equation is called \emph{parabolic}.
\item If all eigenvalues are negative or $n-1$ are negative, then we replace
$F$ by $-F$.\\
All other case of \emph{mixed type} are difficult and we do not consider
them in this lecture.
\end{itemize}
\end{enumerate}

\section{Examples}

Consider the Poisson equation:
\begin{align*}
\upDelta u & =\varrho\\
F\left(x,u,\DD u,\DD^{2}u\right) & =-\varrho\left(x\right)+\delta^{ij}\partial_{ij}u\\
F\left(x,u,p_{i},p_{ij}\right) & =-\varrho\left(x\right)+\delta^{ij}p_{ij}\\
A_{ij}=\frac{\partial F\left(x,u,p_{i},p_{ij}\right)}{\partial p_{ij}} & =\delta_{ij}
\end{align*}
So we have $A=\mathbbm{1}$ and thus the equation is elliptic.\\
Now consider the inhomogeneous wave equation:
\begin{align*}
\left(\partial_{t}^{2}-\upDelta\right)\phi\left(t,x_{1},x_{2},x_{3}\right) & =\varrho
\end{align*}
\begin{align*}
F\left(x,u,p_{i},p_{ij}\right) & =\varrho\left(x\right)+\eta^{ij}p_{ij} & \eta & =\text{diag}\left(-1,1,1,1\right)
\end{align*}
So $A=\eta$ has one negative and three positive eigenvalues which
means that the equation is hyperbolic.
\begin{align*}
\partial_{t}\phi & =\upDelta\phi
\end{align*}
\begin{align*}
F\left(x,u,\DD\phi,\DD^{2}\phi\right) & =-\partial_{0}\phi+\sum_{i,j=1}^{3}\delta^{ij}\partial_{ij}\phi\\
A_{ij} & =\left(\begin{array}{cccc}
0 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}\right)
\end{align*}
Therefore the equation is parabolic.


\chapter{Distributions and Fourier Transform}


\subsubsection*{Motivation}

We want to solve partial differential equations with constant coefficients
in $\Omega=\mathbb{R}^{n}$, for example:
\begin{align*}
\left(-\partial_{t}^{2}+\upDelta\right)\phi & =0
\end{align*}
Now we make a ``plane wave ansatz'' with $t,\omega\in\mathbb{R}$
and $k,x\in\mathbb{R}^{n-1}$:
\begin{align*}
\phi\left(t,x\right) & =e^{-\ii\omega t+\ii\left\langle k,x\right\rangle }\\
\partial_{t}\phi\left(t,x\right) & =-\ii\omega\phi\left(t,x\right)\\
\partial_{j}\phi\left(t,x\right) & =\ii k_{j}\phi\left(t,x\right)
\end{align*}
This gives an algebraic equation:
\begin{align*}
\left(-\left(-\ii\omega\right)^{2}+\left(\ii k\right)^{2}\right)\phi & =0\\
\Leftrightarrow\qquad\omega^{2} & =k^{2}
\end{align*}
%DATE: Fr 19.4.13\\
We also want to differentiate non-smooth functions, e.g.:
\begin{align*}
\upDelta_{\mathbb{R}^{3}}\frac{1}{\abs x} & =-4\pi\delta\left(x\right)
\end{align*}
$\delta\left(x\right)$ is called Dirac $\delta$-distribution.


\section{The Schwartz Space and Distributions}

Laurent Schwartz was the first to investigate distributions systematically.
He was awarded the fields medal for his research.


\subsection{Definition \textmd{(Multi-Index)}}

For $\mathbb{R}^{n}$ we denote indices by $i,j,k\in\left\{ 1,\ldots,n\right\} $.
We call $\alpha=\left(i_{1},\ldots,i_{k}\right)$ with $i_{l}\in\left\{ 1,\ldots,n\right\} $
a \emph{multi-index}. $\abs{\alpha}:=k$ is called the \emph{order}
or \emph{absolute value} of the multi-index.

With this we can write differentials of order $k$ as
\begin{align}
\DD^{\alpha} & :=\frac{\partial}{\partial x^{i_{1}}}\cdots\frac{\partial}{\partial x^{i_{k}}}
\end{align}
and homogeneous polynomials of degree $k$ in the components of a
vector $x=\left(x^{1},\ldots,x^{n}\right)$ as:
\begin{align}
x^{\alpha} & :=x^{i_{1}}\cdots x^{i_{k}}
\end{align}
For $f\in C^{\infty}\left(\mathbb{R}^{n}\right)$ and $r,s\in\mathbb{N}$
we define the \emph{Schwartz norm}:
\begin{align}
\norm f_{r,s} & :=\sum_{\alpha,\abs{\alpha}\le r}\sum_{\beta,\abs{\beta}\le s}\sup_{x\in\mathbb{R}^{n}}\abs{x^{\alpha}\DD^{\beta}f\left(x\right)}
\end{align}
For example for $r=0=s$ we have:
\begin{align*}
\norm f_{0,0} & =\sup_{x\in\mathbb{R}^{n}}\abs{f\left(x\right)}=\norm f_{C^{0}}
\end{align*}



\subsection{Definition \textmd{(Schwartz Space)}}

The \emph{Schwartz space} $\mathcal{S}\left(\mathbb{R}^{n}\right)$
is the vector space of all $f\in C^{\infty}\left(\mathbb{R}^{n}\right)$
for which all Schwartz norms are finite, i.e. for all $r,s\in\mathbb{N}$
holds:
\begin{align*}
\norm f_{r,s} & <\infty
\end{align*}
This space is an infinite-dimensional vector space.\\
On a normed space $\left(E,\norm .\right)$, the topology is given
by the open sets.

$\Omega\subseteq E$ is defined as \emph{open} if holds:
\begin{align*}
\fall_{x\in\Omega}\ \exs_{\varepsilon>0}\ :\ B_{\varepsilon}\left(x\right) & \subseteq\Omega
\end{align*}
A subset $\Omega\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$
is called \emph{open} if for every $f\in\Omega$ there is a $\varepsilon>0$
and $r,s\in\mathbb{N}$ such that holds:
\begin{align}
\left\{ g\in\mathcal{S}\Big|\norm{g-f}_{r,s}<\varepsilon\right\}  & \subseteq\Omega
\end{align}

\begin{description}
\item [{Note:}] This topology is fine, because it involves many open sets,
since the condition for open only involves the statement ``there
are $r,s\in\mathbb{N}$''.\\
Convergence $f_{n}\to f$ in $\mathcal{S}$ means that \emph{every}
open neighborhood $U$ of $f$ contains almost all $f_{n}$. For a
finer topology, the condition for a sequence to converge is stronger.
\end{description}

\subsection{Theorem \textmd{(Criterion for Convergence)}}

Convergence $f_{n}\to f$ in $\mathcal{S}$ is equivalent to the convergence
$\norm{f_{n}-f}_{r,s}\to0$ for all $r,s\in\mathbb{N}$.


\subsubsection*{Proof}

``$\Rightarrow$'': Suppose that $f_{n}\to f$ converges. By definition
of the convergence, every open neighborhood of $f$ contains almost
all $f_{n}$. For all $r,s\in\mathbb{N}$ the sets $U_{\varepsilon}^{r,s}:=\big\{ g\big|\norm{g-f}_{r,s}<\varepsilon\big\}$
are open by definition. So the inequality
\begin{align*}
\norm{f_{n}-f}_{r,s} & <\varepsilon
\end{align*}
holds for almost all $f_{n}$ and thus converges $\norm{f_{n}-f}_{r,s}\to0$.

``$\Leftarrow$'': Assume that $\norm{f_{n}-f}_{r,s}\to0$ converges
for all $r,s\in\mathbb{N}$. Let $A$ be an open neighborhood of $f$.
This means by definition that there exist $r,s\in\mathbb{N}$ and
$\varepsilon\in\mathbb{R}_{>0}$ with $U_{\varepsilon}^{r,s}\subseteq A$.
For this $\left(r,s\right)$ we know that $\norm{f_{n}-f}_{r,s}\to0$
converges. Hence there exists a $N\in\mathbb{N}$ such that $\norm{f_{n}-f}_{r,s}<\varepsilon$
holds for all $n\in\mathbb{N}_{>N}$, in other words $f_{n}\in U_{\varepsilon}^{r,s}\subseteq A$.
So $f_{n}\to f$ converges in $\mathcal{S}$.\qqed

A vector space with a topology generated by a family of norms or semi-norms
is a \emph{uniform space} and is called \emph{topological vector space}.


\subsection{Definition \textmd{(Tempered Distribution)}}

Let $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ be the dual space
of $\mathcal{S}\left(\mathbb{R}^{n}\right)$. It is called the space
of \emph{tempered distributions} (\foreignlanguage{ngerman}{temperierte
Distributionen}).

In linear algebra for a finite-dimensional vector space $V$, the
dual space $V^{*}=L\left(V,\mathbb{R}\right)$ is the space of linear
functionals. $V^{*}$ is again a vector space with $\dim\left(V^{*}\right)=\dim\left(V\right)$.\\
Here $\mathcal{S}\left(\mathbb{R}^{n}\right)$ is an infinite-dimensional
vector space with a topology. $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
is the space of all \emph{continuous} linear functionals.

In a Banach space $\left(E,\norm .\right)$ holds: A linear functional
$A:E\to\mathbb{R}$ is continuous if and only if $A$ is bounded,
i.e. $\abs{Au}\le c\norm U$ for all $u\in E$.


\subsection{Lemma \textmd{(Criterion for Continuity)}\label{sub:Lem-continuous_functional}}

A linear functional $T:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathbb{R}$
is continuous if and only if there are $r,s\in\mathbb{N}$ and a $c\in\mathbb{R}_{>0}$
such that holds:
\begin{align}
\abs{Tf} & \le c\norm f_{r,s}\label{eq:T_bounded}
\end{align}



\subsubsection*{Proof}

``$\Leftarrow$'': Assume that (\ref{eq:T_bounded}) holds for some
$r,s\in\mathbb{N}$. We want to show that $T$ is continuous. To this
end, let $f_{n}\to f$ be a convergent series in $\mathcal{S}$. Our
task is to show that $Tf_{n}\to Tf$ converges.\\
The convergence $f_{n}\to f$ implies $\norm{f_{n}-f}_{r',s'}\to0$
for all $r',s'\in\mathbb{N}$ and thus in particular for $r,s$ satisfying
the inequality (\ref{eq:T_bounded}). By linearity follows:
\begin{align*}
\abs{Tf_{n}-Tf} & =\abs{T\left(f_{n}-f\right)}\le c\norm{f_{n}-f}_{r,s}\xrightarrow{n\to\infty}0
\end{align*}
So $T$ maps convergent sequences to convergent sequences and is thus
continuous.

``$\Rightarrow$'': Assume that $T$ is continuous. Then the preimage
of open sets is open, in particular $T^{-1}\left(B_{1}\left(0\right)\right)\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$
is open. So there exist $r,s\in\mathbb{N}$ and a $\varepsilon\in\mathbb{R}_{>0}$
such that holds:
\begin{align*}
T^{-1}\left(B_{1}\left(0\right)\right) & \supseteq U_{\varepsilon}^{r,s}:=\big\{ g\big|\norm g_{r,s}<\varepsilon\big\}
\end{align*}
This implies:
\begin{align*}
\norm g_{r,s}<\varepsilon & \quad\Rightarrow\quad g\in T^{-1}\left(B_{1}\left(0\right)\right)
\end{align*}
Now $g\in T^{-1}\left(B_{1}\left(0\right)\right)$ means $\abs{Tg}<1$.
For any $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ apply this to
$g=\frac{f}{\lambda}$ with $\lambda\in\mathbb{R}_{>0}$.
\begin{align*}
\frac{1}{\lambda}\norm f_{r,s}<\varepsilon & \quad\Rightarrow\quad\frac{1}{\lambda}\abs{Tf}<1\qquad/\cdot\lambda\\
\norm f_{r,s}<\lambda\varepsilon & \quad\Rightarrow\quad\abs{Tf}<\lambda
\end{align*}
Now choose $\lambda=\frac{2}{\varepsilon}\norm f_{r,s}$, so the left
side holds, which implies:
\begin{align*}
\abs{Tf} & <\frac{2}{\varepsilon}\norm f_{r,s}\qquad\fall_{f\in\mathcal{S}\left(\mathbb{R}^{n}\right)}
\end{align*}
\qqed


\subsection{Example \textmd{(\texorpdfstring{$\delta$}{Delta}-Distribution)}}
\begin{enumerate}[label=\alph*)]
\item Consider the following functional:
\begin{align}
\delta:\mathcal{S}\left(\mathbb{R}\right) & \to\mathbb{R}\\
f & \mapsto f\left(0\right)\nonumber 
\end{align}
This is obviously linear.
\begin{align*}
\abs{\delta\left(f\right)} & =\abs{f\left(0\right)}\le\sup_{\mathbb{R}}\abs f=\norm f_{0,0}
\end{align*}
Hence $\delta$ is continuous, which means that $\delta\in\mathcal{S}^{*}\left(\mathbb{R}\right)$
is a tempered distribution.\\
A convenient \emph{notation} with $f\in\mathcal{S}\left(\mathbb{R}\right)$
is:
\begin{align*}
\delta\left(f\right) & =\int_{\mathbb{R}}f\left(x\right)\delta\left(x\right)\dd x
\end{align*}

\item In higher dimension $n\in\mathbb{N}$ we define:
\begin{align*}
\delta:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathbb{R}\\
f & \mapsto f\left(0\right)
\end{align*}
Again holds $\abs{\delta\left(f\right)}\le\norm f_{0,0}$. The physicists'
notation for this is:
\begin{align*}
\delta\left(f\right) & =\int_{\mathbb{R}^{n}}f\left(x\right)\delta^{\left(n\right)}\left(x\right)\dd^{n}x\\
\delta^{\left(n\right)}\left(x\right) & =\delta\left(x^{1}\right)\cdots\delta\left(x^{n}\right)
\end{align*}

\end{enumerate}

\subsubsection*{Remark}

$\delta$ can also be introduced as a \emph{measure} on $\mathbb{R}^{n}$,
the \emph{Dirac measure}. For $A\subseteq\mathbb{R}^{n}$ define:
\begin{align}
\delta\left(x\right) & =\begin{cases}
1 & \text{if }0\in A\\
0 & \text{otherwise}
\end{cases}
\end{align}
Then for $f\in C^{0}\left(\mathbb{R}^{n}\right)$ the expression 
\begin{align*}
\int_{\mathbb{R}^{n}}f\left(x\right)\dd\delta\left(x\right) & =f\left(0\right)
\end{align*}
makes mathematical sense as an integral.

This is useful because convergence theorems and so on from measure
theory are available. The problem is, that this does not work for
every distribution and thus is not general enough for most purposes,
e.g. the derivative $\delta'\left(x\right)$ is a distribution, but
cannot be written as a measure.


\subsection{Example \textmd{(Integral Operator)}}
\begin{enumerate}[label=\alph*)]
\item Consider $g\in C^{\infty}\left(\mathbb{R}^{n}\right)$ with at most
polynomial growth, i.e. there are $c\in\mathbb{R}_{>0}$ and $r\in\mathbb{N}$
such that holds:
\begin{align*}
\abs{g\left(x\right)} & \le c\left(1+\abs x^{r}\right)
\end{align*}
Now define:
\begin{align*}
T_{g}:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathbb{R}\\
f & \mapsto\int_{\mathbb{R}^{n}}g\left(x\right)f\left(x\right)\dd^{n}x
\end{align*}
The integral here is just the Lebesgue integral and it exists:\\
For $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds $\norm f_{r,s}<\infty$
for all $r,s\in\mathbb{N}$.
\begin{align*}
\sup_{\mathbb{R}}\abs f+\sup_{x\in\mathbb{R}}\left(\abs x^{\tilde{r}}\cdot\abs{f\left(x\right)}\right) & \le\norm f_{\tilde{r},0}<\infty\\
\Rightarrow\qquad\sup_{x\in\mathbb{R}}\left(\left(1+\abs x^{\tilde{r}}\right)\abs{f\left(x\right)}\right) & \le\norm f_{\tilde{r},0}\\
\Rightarrow\qquad\abs{f\left(x\right)} & \le\frac{\norm f_{\tilde{r},0}}{1+\abs x^{\tilde{r}}}\qquad\fall_{\tilde{r}\in\mathbb{N}}
\end{align*}
So we get:
\begin{align*}
T_{g}f & =\int g\left(x\right)f\left(x\right)\dd^{n}x\le\int c\left(1+\abs x^{r}\right)\frac{\norm f_{\tilde{r},0}}{\left(1+\abs x^{\tilde{r}}\right)}\dd^{n}x=\\
 & \sr ={\text{polar coordinates}}{\rho:=\abs x}c\norm f_{\tilde{r},0}\underbrace{\mu\left(S^{n-1}\right)}_{\text{volume of unit sphere}}\int_{0}^{\infty}\rho^{n-1}\frac{1+\rho^{r}}{1+\rho^{\tilde{r}}}\dd\rho\stackrel{\tilde{r}>r+n}{<}\infty
\end{align*}
This is finite if and only if the integrand decays faster than $\rho^{-1}$,
i.e. $n-1+r-\tilde{r}<-1$ and thus $\tilde{r}>n+r$. Since $\tilde{r}\in\mathbb{N}$
is arbitrary, the integral exists.\\
Continuity: The previous estimate implies with $\tilde{r}=n+r+1$:
\begin{align*}
\abs{T_{g}f} & \le C\left(g,n\right)\norm f_{\tilde{r},0}
\end{align*}
Thus $T_{g}\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ is a tempered
distribution.
\item Chose $g\left(x\right)=e^{x}$ and define:
\begin{align*}
T_{g}f & :=\int_{-\infty}^{\infty}f\left(x\right)e^{x}\dd x
\end{align*}
This is \emph{not} a well-defined tempered distribution. Namely, choose:
\begin{align*}
f\left(x\right) & =\frac{1}{\cosh\left(\frac{x}{2}\right)}
\end{align*}
\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
 \begin{axis}[width=16cm, axis equal image, axis x line=middle, axis y line=middle, xlabel=$x$, domain=-4:4, ymin=0, ymax=1.2, samples=300]
  \addplot[mark=none] {1/cosh(x/2)};
  \addlegendentry{$f(x)$}
 \end{axis}
\end{tikzpicture} 
\par\end{centering}

\caption{$f\left(x\right)$ decays rapidly.}
\end{figure}
$f\left(x\right)$ and all its derivatives decay rapidly (exponentially
fast $\sim e^{-\frac{x}{2}}$) at $\pm\infty$, so $f\in\mathcal{S}$
is a Schwartz function. But $T_{g}f$ diverges:
\begin{align*}
T_{g}f & =\int_{-\infty}^{\infty}\frac{e^{x}}{\cosh\left(\frac{x}{2}\right)}\dd x=+\infty
\end{align*}

\end{enumerate}
%DATE: Mi 24.4.13


\subsection{Remark \textmd{(Schwartz Functions as Distributions)}}

The mapping
\begin{align*}
T:\mathcal{S}\left(\mathbb{R}^{n}\right) & \to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
f & \mapsto T_{f}
\end{align*}
is injective.


\subsubsection*{Proof}

If $T$ was injective, there were $f_{1},f_{2}\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
with $T_{f_{1}}=T_{f_{2}}$ and $f_{1}\not=f_{2}$. By linearity this
would imply $T_{g}=0$ with $g=f_{1}-f_{2}\not=0$ and we could choose
a $y\in\mathbb{R}^{n}$ with $g\left(y\right)\not=0$. By continuity
follows $g>0$ or $g<0$ in a neighborhood $U$ of $y$. Now choose
a test function $h$ with $\text{supp}\left(h\right)\subseteq U$
and $h\ge0$. Then follows the contradiction:
\begin{align*}
0=T_{g}\left(h\right) & =\int_{\mathbb{R}^{n}}g\left(x\right)h\left(x\right)\dd^{n}x\not=0
\end{align*}
\qqed

Thus we can regard distributions as ``generalized functions''. Namely
we identify a function $g$ with $T_{g}$. (Later on many people often
do not distinguish between $g$ and $T_{g}$.)


\subsubsection*{Operations on Schwartz Functions and Distributions}
\begin{itemize}
\item $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ is a vector space with
addition $T+S$ and scalar multiplication $\alpha\cdot f$ for distributions
$T,S\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ and $\alpha\in\mathbb{R}$.
\item Multiplication of a distribution by a Schwartz function is defined
for $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ and $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
as:
\begin{align}
\left(fT\right)\left(g\right) & :=T\left(f\cdot g\right)
\end{align}
This is well defined, because $f\cdot g$ is again a Schwartz function
and for $h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds:
\begin{align*}
\left(fT_{h}\right)\left(g\right) & \stackrel{\text{definition of }fT_{h}}{=}T_{h}\left(f\cdot g\right)\stackrel{\text{definition of }T_{h}}{=}\int_{\mathbb{R}^{n}}h\left(x\right)\left(f\cdot g\right)\left(x\right)\dd^{n}x=\\
 & =\int_{\mathbb{R}^{n}}\left(f\cdot h\right)\left(x\right)g\left(x\right)\dd^{n}x=T_{fh}\left(g\right)
\end{align*}
So this definition is extends the multiplication of Schwartz functions
to distributions. But we still have to show, that this operation gives
a continuous functional.
\end{itemize}

\subsection{Definition \textmd{(regular/singular distribution)}}

A tempered distribution $T$ is called \emph{regular} distribution
if there is a $g\in L_{\text{loc}}^{1}\left(\mathbb{R}^{n}\right)$
(locally integrable, i.e. integrable on every compact interval) with
$T=T_{g}$. Otherwise, $T$ is called \emph{singular}.

For example $\delta\left(x\right)$ is singular.


\subsection{Lemma \textmd{(Multiplication of a Distribution by a Schwartz Function)}}

Let $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ be a Schwartz function
and $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ a distribution.
Then $fT$ is a \emph{continuous} linear functional on $\mathcal{S}\left(\mathbb{R}^{n}\right)$,
in other words $fT\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
is also a distribution.


\subsubsection*{Proof}

According to Lemma \ref{sub:Lem-continuous_functional}, our task
is to show that there are $r,s\in\mathbb{N}$ and a $C\in\mathbb{R}_{>0}$
with:
\begin{align*}
\abs{\left(fT\right)\left(g\right)} & \le C\norm g_{r,s}
\end{align*}
Since $T$ is continuous, there exist $r,s\in\mathbb{N}$ and a $\tilde{C}\in\mathbb{R}_{>0}$
with:
\begin{align*}
\abs{T\left(fg\right)} & \le\tilde{C}\norm{fg}_{r,s}
\end{align*}
Thus it remains to show that there is a $c\left(r,s\right)\in\mathbb{R}_{>0}$
such that for all $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align*}
\norm{fg}_{r,s} & \le c\left(r,s\right)\norm f_{r,s}\cdot\norm g_{r,s}
\end{align*}
This inequality can be proven by induction in $s$.

Induction basis $s=0$:
\begin{align*}
\norm{fg}_{r,0} & =\sum_{\abs{\alpha}\le r}\sup_{x\in\mathbb{R}^{n}}\left(\abs{x^{\alpha}f\left(x\right)g\left(x\right)}\right)\le\\
 & \le\sup_{y\in\mathbb{R}^{n}}\abs{g\left(y\right)}\sum_{\abs{\alpha}\le r}\sup_{x\in\mathbb{R}^{n}}\left(\abs{x^{\alpha}f\left(x\right)}\right)=\\
 & =\norm g_{0,0}\cdot\norm f_{r,0}\le\norm g_{r,0}\cdot\norm f_{r,0}
\end{align*}
Induction step $s\leadsto s+1$: Assume that the statement holds for
a $s\in\mathbb{N}$ for all $r\in\mathbb{N}$. Let $\beta$ be a multi-index
with $\abs{\beta}=s+1$, i.e. $\beta=\left(i_{1},\ldots,i_{s+1}\right)$.
Now set:
\begin{align*}
\hat{\beta} & :=\left(i_{1},\ldots,i_{s}\right) & j & :=i_{s+1} & \DD^{\beta} & =\DD^{\hat{\beta}}\frac{\partial}{\partial x^{j}}
\end{align*}
It holds:
\begin{align*}
\DD^{\beta}\left(fg\right) & =\DD^{\hat{\beta}}\frac{\partial}{\partial x^{j}}\left(fg\right)=\DD^{\hat{\beta}}\left(\left(\frac{\partial}{\partial x^{j}}f\right)g+f\left(\frac{\partial}{\partial x^{j}}g\right)\right)
\end{align*}
\begin{align*}
\norm{fg}_{r,s+1} & =\norm{f\cdot g}_{r,s}+\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\beta}=s+1}}\sup_{x\in\mathbb{R}}\abs{x^{\alpha}\DD^{\beta}\left(f\cdot g\right)\left(x\right)}=\\
 & =\norm{fg}_{r,s}+\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\hat{\beta}}=s}}\sum_{j=1}^{n}\sup_{x\in\mathbb{R}}\abs{x^{\alpha}\DD^{\hat{\beta}}\left(\left(\frac{\partial}{\partial x^{j}}f\left(x\right)\right)g\left(x\right)+f\left(x\right)\left(\frac{\partial}{\partial x^{j}}g\left(x\right)\right)\right)}\le\\
 & \sr{\le}{\text{induction}}{\text{hypothesis}}c\left(r,s\right)\norm f_{r,s}\norm g_{r,s}+\sum_{j=1}^{n}c\left(r,s\right)\left(\norm{\frac{\partial}{\partial x^{j}}f}_{r,s}\norm g_{r,s}+\norm f_{r,s}\norm{\frac{\partial}{\partial x^{j}}g}_{r,s}\right)\le\\
 & \le c\left(r,s\right)\norm f_{r,s}\norm g_{r,s}+n\cdot c\left(r,s\right)\left(\norm f_{r,s+1}\norm g_{r,s}+\norm f_{r,s}\norm g_{r,s+1}\right)\le\\
 & \le\underbrace{\left(2n+1\right)c\left(r,s\right)}_{=c\left(r,s+1\right)}\norm f_{r,s+1}\norm g_{r,s+1}
\end{align*}


\qqed


\subsection{Example \textmd{(Derivative of the \texorpdfstring{$\delta$}{Delta}-Distribution)}}

We make a formal computation:
\begin{align*}
\int_{\mathbb{R}}\delta'\left(x\right)f\left(x\right)\dd x & =\int_{\mathbb{R}}\left(\frac{\dd}{\dd x}\delta\left(x\right)\right)f\left(x\right)\dd x\sr ={\text{integration}}{\text{by parts}}-\int_{\mathbb{R}}\delta\left(x\right)f'\left(x\right)\dd x=-f'\left(0\right)
\end{align*}
This motivates us to \emph{define}:
\begin{align}
\delta':\mathcal{S}\left(\mathbb{R}\right) & \to\mathbb{R}\\
f & \mapsto-f'\left(0\right)\nonumber 
\end{align}
This is obviously linear and it is continuous, because for all $f\in\mathcal{S}\left(\mathbb{R}\right)$
holds:
\begin{align*}
\abs{\delta'\left(f\right)} & =\abs{f'\left(0\right)}\le\norm f_{0,1}
\end{align*}
Hence we have $\delta'\in\mathcal{S}^{*}\left(\mathbb{R}\right)$.


\subsubsection*{Remark}

In contrast to $\delta$, the distribution $\delta'$ cannot be introduced
as a measure:
\begin{align*}
\delta\left(\Omega\right) & =\begin{cases}
1 & \text{if }0\in\Omega\\
0 & \text{otherwise}
\end{cases}\\
\delta'\left(\Omega\right) & =?
\end{align*}



\subsection{Definition \textmd{(Distributional Derivative, Convolution)}}
\begin{itemize}
\item For a tempered distribution $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
we define the \emph{distributional derivative} $\DD^{\alpha}T$ by:
\begin{align}
\left(\DD^{\alpha}T\right)\left(f\right) & :=\left(-1\right)^{\abs{\alpha}}T\left(\DD^{\alpha}f\right)
\end{align}
$\DD^{\alpha}T$ is a distribution, since it is a continuous functional:
\begin{align*}
\abs{\left(\DD^{\alpha}T\right)\left(f\right)} & =\abs{T\left(\DD^{\alpha}f\right)}\stackrel{T\text{ continuous}}{\le}C\norm{\DD^{\alpha}f}_{r,s}\le C\norm f_{r,s+\abs{\alpha}}
\end{align*}
So we have a mapping $\DD^{\alpha}:\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
\item The convolution (\foreignlanguage{ngerman}{Faltung}) for $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
is defined as:
\begin{align}
\left(f*g\right)\left(x\right) & :=\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align}

\end{itemize}

\subsection{Lemma \textmd{(Commutativity and Associativity of the Convolution)}}

The convolution is commutative and associative, i.e. for $f,g,h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align}
f*g & =g*f & f*\left(g*h\right) & =\left(f*g\right)*h
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(f*g\right)\left(x\right) & =\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y\sr ={z:=x-y}{\dd^{n}z=\dd^{n}y}\int_{\mathbb{R}^{n}}f\left(z\right)g\left(x-z\right)\dd^{n}z=\left(g*f\right)\left(x\right)
\end{align*}
Associativity follows analogously using Fubini's theorem, which can
be applied, since the function $\left(y,z\right)\mapsto f\left(x-y\right)g\left(y-z\right)h\left(z\right)$
is an element of $\mathcal{S}\left(\mathbb{R}^{2n}\right)\subseteq L^{1}\left(\mathbb{R}^{2n}\right)$:
\begin{align*}
f*\left(g*h\right)\left(x\right) & =\int_{\mathbb{R}^{n}}f\left(x-y\right)\left(g*h\right)\left(y\right)\dd^{n}y=\\
 & =\int_{\mathbb{R}^{n}}f\left(x-y\right)\left(\int_{\mathbb{R}^{n}}g\left(y-z\right)h\left(z\right)\dd^{n}z\right)\dd^{n}y=\\
 & \sr ={\tilde{y}:=y-z}{\dd^{n}\tilde{y}=\dd y}\int_{\mathbb{R}^{n}}\int_{\mathbb{R}^{n}}f\left(x-\tilde{y}-z\right)g\left(\tilde{y}\right)h\left(z\right)\dd^{n}\tilde{y}\dd^{n}z=\\
 & =\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}f\left(x-z-\tilde{y}\right)g\left(\tilde{y}\right)\dd^{n}\tilde{y}\right)h\left(z\right)\dd^{n}z=\\
 & =\int_{\mathbb{R}^{n}}\left(f*g\right)\left(x-z\right)h\left(z\right)\dd^{n}z=\\
 & =\left(f*g\right)*h\left(x\right)
\end{align*}
\qqed


\subsection{Proposition \textmd{(Convolution is Continuous)}}

The convolution $*:\mathcal{S}\times\mathcal{S}\to\mathcal{S}$ is
continuous.


\subsubsection*{Proof}

\begin{align*}
\norm{f*g}_{r,s} & =\sum_{\sr{}{\abs{\alpha}\le r}{\abs{\beta}\le s}}\sup_{x\in\mathbb{R}^{n}}\abs{x^{\alpha}\DD_{x}^{\beta}\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y}
\end{align*}
The derivative may be commuted with the integral:
\begin{align*}
\frac{\partial}{\partial x_{j}}\left(f*g\right)\left(x\right) & =\lim_{\varepsilon\searrow0}\frac{1}{\varepsilon}\left(\left(f*g\right)\left(x+\varepsilon e_{j}\right)-\left(f*g\right)\left(x\right)\right)=\\
 & =\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}g\left(y\right)\dd^{n}y
\end{align*}
Using the estimate
\begin{align*}
\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon} & =\frac{1}{\varepsilon}\int_{0}^{1}\frac{\dd}{\dd\tau}\left(f\left(x+\varepsilon\tau e_{j}-y\right)\right)\dd\tau=\\
 & =\frac{1}{\varepsilon}\int_{0}^{1}\left(\partial_{j}f\right)\left(x+\varepsilon\tau e_{j}-y\right)\varepsilon\dd\tau\\
\Rightarrow\qquad\abs{\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}} & \le\sup_{\mathbb{R}^{n}}\abs{\partial_{j}f}\le\norm f_{0,1}
\end{align*}
we get:
\begin{align*}
\abs{\frac{f\left(x+\varepsilon e_{j}-y\right)-f\left(x-y\right)}{\varepsilon}g\left(y\right)} & \le\norm f_{0,1}\cdot\abs{g\left(y\right)}\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
Thus the dominated convergence theorem implies:
\begin{align*}
\frac{\partial}{\partial x_{j}}\left(f*g\right)\left(x\right) & =\int_{\mathbb{R}^{n}}\frac{\partial}{\partial x^{j}}f\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align*}
By induction follows:
\begin{align*}
x^{\alpha}\DD^{\beta}\int_{\mathbb{R}}f\left(x-y\right)g\left(y\right)\dd^{n}y & =x^{\alpha}\int_{\mathbb{R}^{n}}\left(\DD^{\beta}f\right)\left(x-y\right)g\left(y\right)\dd^{n}y
\end{align*}
Now we treat the $x^{\alpha}$:
\begin{align*}
x^{\alpha} & =\left(\left(x-y\right)+y\right)^{\alpha}=\sum_{\gamma,\delta\text{ with }\alpha=\gamma+\delta}c_{\gamma\delta}\left(x-y\right)^{\gamma}\cdot y^{\delta}
\end{align*}
Here holds $\abs{\gamma},\abs{\delta}\le\abs{\alpha}$. Now we can
estimate:
\begin{align*}
\abs{\left(x-y\right)^{\gamma}\DD^{\beta}f\left(x\right)} & \le\norm f_{r,s}
\end{align*}
Hence we get:
\begin{align*}
\norm{f*g}_{r,s} & \le c\left(r,s\right)\norm f_{r,s}\sum_{\delta}\int_{\mathbb{R}^{n}}\abs{y^{\delta}g\left(y\right)}\cdot\frac{\left(1+\abs y\right)^{n+1}}{\left(1+\abs y\right)^{n+1}}\dd^{n}y\le\\
 & \le c\left(r,s\right)\norm f_{r,s}\norm g_{n+1+r,0}\underbrace{\int_{\mathbb{R}^{n}}\frac{\dd^{n}y}{\left(1+\abs y\right)^{n+1}}}_{<\infty}
\end{align*}
\qqed


\subsection{Definition \textmd{(Convolution with Distribution)}}

How can we define the convolution of $T\in S^{*}\left(\mathbb{R}^{n}\right)$
with $f\in S\left(\mathbb{R}^{n}\right)$? $f*T_{g}$ should be equal
to $T_{f*g}$. For $h\in\mathcal{S}\left(\mathbb{R}^{n}\right)$ holds:
\begin{align*}
T_{f*g}\left(h\right) & =\int_{\mathbb{R}^{n}}\left(f*g\right)\left(x\right)\cdot h\left(x\right)\dd^{n}x=\\
 & =\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}f\left(x-y\right)g\left(y\right)\dd^{n}y\right)\cdot h\left(x\right)\dd^{n}x
\end{align*}
By Fubini's theorem we may interchange the order of integration to
get:
\begin{align*}
T_{f*g}\left(h\right) & =\int_{\mathbb{R}^{n}}g\left(y\right)\left(\int_{\mathbb{R}^{n}}f\left(x-y\right)\cdot h\left(x\right)\dd^{n}x\right)\dd^{n}y=\\
 & \sr ={\tilde{f}\left(z\right):=f\left(-z\right)}{}\int_{\mathbb{R}^{n}}g\left(y\right)\left(\int_{\mathbb{R}^{n}}\tilde{f}\left(y-x\right)\cdot h\left(x\right)\dd^{n}x\right)\dd^{n}y=\\
 & =\int_{\mathbb{R}^{n}}g\left(y\right)\left(\tilde{f}*h\right)\left(y\right)\dd^{n}y=T_{g}\left(\tilde{f}*h\right)
\end{align*}
So for a distribution $T\in S^{*}\left(\mathbb{R}^{n}\right)$ we
define the \emph{convolution} as:
\begin{align}
*:\mathcal{S}\left(\mathbb{R}^{n}\right)\times\mathcal{S}^{*}\left(\mathbb{R}^{n}\right) & \to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
\left(f*T\right)\left(h\right) & :=T\left(\tilde{f}*h\right)\nonumber 
\end{align}


For $S,T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$, $S*T$ and
$S\cdot T$ are ill-defined in general. For example $\delta\left(x\right)\cdot\delta\left(x\right)$
makes no sense, as well as $T_{f}*T_{f}$ for $f=1$.


\section{The Fourier Transform}

First consider the Fourier transform on $\mathcal{S}\left(\mathbb{R}^{n}\right)$
and later on $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.


\subsection{Definition \textmd{(Fourier Transform)}}

Define linear functionals $\mathcal{F}$ and $\overline{\mathcal{F}}$
on $\mathcal{S}$:
\begin{align}
\left(\mathcal{F}f\right)\left(p\right) & :=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\\
\left(\overline{\mathcal{F}}f\right)\left(x\right) & :=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{\ii px}f\left(p\right)\dd^{n}p
\end{align}
The integrals are well-defined and finite, because $f$ has suitable
decay properties at infinity.

An alternative convention, which is not convenient here, because it
has less symmetry, is:
\begin{align*}
\left(\mathcal{F}f\right)\left(p\right) & :=\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\\
\left(\overline{\mathcal{F}}f\right)\left(x\right) & :=\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}e^{\ii px}f\left(p\right)\dd^{n}p
\end{align*}


%DATE: Fr 26.4.13


\subsection{Proposition \textmd{(Fourier Transform)}}

$\mathcal{F}$ and $\overline{\mathcal{F}}$ are well-defined linear
operators from $\mathcal{S}\left(\mathbb{R}^{n}\right)$ to $\mathcal{S}\left(\mathbb{R}^{n}\right)$.


\subsubsection*{Proof}

The linearity is clear. We still have to show, that all norms $\norm{\mathcal{F}f}_{r,s}$
are finite. First consider the norm $\norm ._{0,0}$:
\begin{align*}
\abs{\left(\mathcal{F}f\right)\left(p\right)} & \le\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\abs{f\left(x\right)}\cdot\frac{\left(1+\abs x\right)^{n+1}}{\left(1+\abs x\right)^{n+1}}\dd^{n}x\le\\
 & \le\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\norm f_{n+1,0}\underbrace{\int_{\mathbb{R}^{n}}\frac{\dd^{n}x}{\left(1+\abs x\right)^{n+1}}}_{<\infty}\le c\norm f_{n+1,0}
\end{align*}
Now we consider $\abs{p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right)}$.
\begin{align*}
\frac{\partial}{\partial p^{j}}\left(\mathcal{F}f\right)\left(p\right) & =\frac{\partial}{\partial p^{j}}\int e^{-\ii px}f\left(x\right)\dd^{n}x=\ldots=\int\left(\frac{\partial}{\partial p^{j}}e^{-\ii px}\right)f\left(x\right)\dd^{n}x=\\
 & =\int\left(-\ii x^{j}\right)e^{-\ii px}f\left(x\right)\dd^{n}x
\end{align*}
That the derivative and the integral can be interchanged is shown
as follows:
\begin{align*}
\frac{\partial}{\partial p^{j}}\int e^{-\ii px}f\left(x\right)\dd^{n}x & =\lim_{\varepsilon\searrow0}\int\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}f\left(x\right)\dd^{n}x\\
\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon} & =\frac{1}{\varepsilon}\int_{0}^{1}\frac{\dd}{\dd\tau}e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}\dd\tau=-\ii e_{j}x\int_{0}^{1}e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}\dd\tau\\
\Rightarrow\qquad\abs{\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}} & \le\norm x\cdot\int_{0}^{1}\underbrace{\abs{e^{-\ii\left(p+\varepsilon\tau e_{j}\right)x}}}_{=1}\dd\tau=\norm x\\
\abs{\frac{e^{-\ii\left(p+\varepsilon e_{j}\right)x}-e^{-\ii px}}{\varepsilon}f\left(x\right)} & \le\norm x\cdot\abs{f\left(x\right)}\le\frac{\norm x}{1+\norm x^{n+2}}\norm f_{n+2,0}=:h\left(x\right)\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
This allows us to apply the dominated convergence theorem to take
the limit $\varepsilon\to0$ inside the integral. Iteration of this
process gives:
\begin{align*}
\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}}\left(-\ii\right)^{\abs{\beta}}x^{\beta}f\left(x\right)e^{-\ii px}\dd^{n}x\\
p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}}\left(-\ii\right)^{\abs{\beta}}x^{\beta}f\left(x\right)p^{\alpha}e^{-\ii px}\dd^{n}x\\
p^{j}e^{-\ii px} & =\ii\frac{\partial}{\partial x^{j}}e^{-\ii px}\\
\Rightarrow\qquad p^{\alpha}e^{-\ii px} & =\ii^{\abs{\alpha}}\DD_{x}^{\alpha}e^{-\ii px}\\
p^{\alpha}\DD^{\beta}\left(\mathcal{F}f\right)\left(p\right) & =\frac{\left(-\ii\right)^{\abs{\beta}}\ii^{\abs{\alpha}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\underbrace{\left(x^{\beta}f\left(x\right)\right)}_{\text{rapid decay}}\left(\DD_{x}^{\alpha}e^{-\ii px}\right)\dd^{n}x=\\
 & \sr ={\text{integration}}{\text{by parts}}\frac{\left(-\ii\right)^{\abs{\beta}}\ii^{\abs{\alpha}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(-1\right)^{\abs{\alpha}}\DD_{x}^{\alpha}\left(x^{\beta}f\left(x\right)\right)e^{-\ii px}\dd^{n}x=\\
 & =\frac{\left(-\ii\right)^{\abs{\alpha}+\abs{\beta}}}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\DD_{x}^{\alpha}\left(x^{\beta}f\left(x\right)\right)e^{-\ii px}\dd^{n}x
\end{align*}
From the computation we did earlier in the proof we know:
\begin{align*}
\abs{\DD_{x}^{\alpha}\left(\mathcal{F}f\right)\left(p\right)} & \le C\norm{\DD_{x}^{\alpha}\left(x^{\beta}f\right)}_{n+1,0}\le\tilde{C}\left(\alpha,\beta\right)\norm f_{\abs{\beta}+n+1,\abs{\alpha}}
\end{align*}
\begin{align*}
\norm{\mathcal{F}f}_{r,s} & \le\tilde{c}\left(s,r,n\right)\norm f_{s+n+1,r}
\end{align*}
Therefore $\mathcal{F}:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathcal{S}\left(\mathbb{R}^{n}\right)$
is well-defined. The same follows analogously for $\overline{\mathcal{F}}$.\qqed

So we have the following correspondence:
\begin{align}
-\ii x^{j} & \leftrightarrow\frac{\partial}{\partial p^{j}}\\
-\ii\frac{\partial}{\partial x^{j}} & \leftrightarrow p^{j}
\end{align}
Here the derivatives always act on $f$ or $\mathcal{F}f$ and not
on $e^{-\ii px}$.
\begin{align*}
x^{\alpha}\DD^{\beta}f & \leftrightarrow\ii^{\abs{\alpha}+\abs{\beta}}\DD_{p}^{\alpha}p^{\beta}\left(\mathcal{F}f\right)\left(p\right)=\ii^{\abs{\alpha}+\abs{\beta}}p^{\beta}\DD^{\alpha}\left(\mathcal{F}f\right)\left(p\right)+\text{lower order terms}
\end{align*}
Suppose we had worked with $\norm f_{0,k}=\abs f_{C^{k}}$ as family
of norms. Then the norms of the Fourier transform of a function with
finite norms would not necessarily be finite.


\subsection{Theorem \textmd{(Plancherel, Convergence Generating Factor)\label{sub:Thm-Plancherel}}}

$\mathcal{F}$ and $\overline{\mathcal{F}}$ are inverse to each other:
\begin{align}
\overline{\mathcal{F}}\mathcal{F} & =\mathcal{F}\overline{\mathcal{F}}=\mathbbm{1}:\mathcal{S}\left(\mathbb{R}^{n}\right)\to\mathcal{S}\left(\mathbb{R}^{n}\right)
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}e^{-\ii px}\underbrace{\left(\int_{\mathbb{R}^{n}}e^{\ii qx}f\left(q\right)\dd^{n}q\right)}_{\left(\overline{\mathcal{F}}f\right)\left(x\right)}\dd^{n}x\stackrel{?}{=}f\left(p\right)\\
 & \stackrel{?}{=}\frac{1}{\left(2\pi\right)^{n}}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\int_{\mathbb{R}^{n}}e^{-\ii\left(p-q\right)x}\dd^{n}x\right)\dd^{n}q
\end{align*}
The problem here is, that $e^{-\ii\left(p-q\right)x}$ does not decay
at infinity, so the integral is not well-defined. Instead we have
to introduce a \emph{convergence generating factor} $e^{-\varepsilon x^{2}}$
and, after integrating, calculate the limes $\varepsilon\to0$.
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}e^{-\ii px}e^{-\varepsilon x^{2}}\left(\int_{\mathbb{R}^{n}}e^{\ii qx}f\left(q\right)\dd^{n}q\right)\dd^{n}x=\\
 & \stackrel{\text{Fubini}}{=}\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\int_{\mathbb{R}^{n}}e^{-\ii\left(p-q\right)x}e^{-\varepsilon x^{2}}\dd^{n}x\right)\dd^{n}q
\end{align*}
The resulting Gaussian integral can be computed in closed form. In
one dimension it is:
\begin{align*}
\int_{\mathbb{R}}e^{-\ii\lambda x}e^{-\varepsilon x^{2}}\dd x & =\int_{\mathbb{R}}e^{-\varepsilon\left(x+\frac{\ii\lambda}{2\varepsilon}\right)^{2}-\frac{\lambda^{2}}{4\varepsilon}}\dd x=e^{-\frac{\lambda^{2}}{4\varepsilon}}\int_{\mathbb{R}}e^{-\varepsilon\left(x+\frac{\ii\lambda}{2\varepsilon}\right)^{2}}\dd x=\\
 & \sr ={z=\sqrt{\varepsilon}\left(x+\frac{\ii\lambda}{2\varepsilon}\right)}{\dd z=\sqrt{\varepsilon}\dd x}e^{-\frac{\lambda^{2}}{4\varepsilon}}\int_{\mathbb{R}+\frac{\ii\lambda}{2\sqrt{\varepsilon}}}e^{-z^{2}}\frac{\dd z}{\sqrt{\varepsilon}}=\\
 & \sr ={\text{contour}}{\text{deformation}}\frac{e^{-\frac{\lambda^{2}}{4\varepsilon}}}{\sqrt{\varepsilon}}\underbrace{\int_{\mathbb{R}}e^{-z^{2}}\dd z}_{=\sqrt{\pi}}=\sqrt{\frac{\pi}{\varepsilon}}e^{-\frac{\lambda^{2}}{4\varepsilon}}
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\frac{1}{\left(2\pi\right)^{n}}\lim_{\varepsilon\searrow0}\int_{\mathbb{R}^{n}}f\left(q\right)\left(\frac{\pi}{\varepsilon}\right)^{\frac{n}{2}}e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q
\end{align*}


\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
 \begin{axis}[width=9cm, axis x line=middle, axis y line=middle, xtick={0}, ytick={0}, xlabel=$q$,domain=-6:6,samples=300, ymin=-0.5]
  \addplot[mark=none] {exp(-(1-x)^2/4)};
  \addlegendentry{$\varepsilon = 1$}
  \addplot[blue,dashed,mark=none] {exp(-(1-x)^2/0.4)/sqrt(0.5)};
  \addlegendentry{$\varepsilon = 0.5$}
  \addplot[red!50!black,dotted,mark=none] {exp(-(1-x)^2/0.03)/sqrt(0.1)};
  \addlegendentry{$\varepsilon = 0.1$}
  \draw (axis cs: 1,-0.05) -- (axis cs: 1,0.05) node[above]{$p$};
 \end{axis}
\end{tikzpicture} \hfill{}\begin{tikzpicture}
 \begin{axis}[width=9cm, axis equal image, axis x line=middle, axis y line=middle, xtick={0}, ytick={0}, xlabel=$q^i$, ylabel=$q^j$, xmin=-1, xmax=3, ymin=-0.45, ymax=3]
  \draw (axis cs: 2.05,0.95) -- (axis cs: 1.95,1.05) (axis cs: 2.05,1.05) -- (axis cs: 1.95,0.95) (axis cs:2,1) node[below]{$p$};
  \draw (axis cs: 2,1) circle (10.8mm);
  \draw (axis cs: 2,1) -- node[above]{$\varepsilon$} (axis cs: 1.4,1);
 \end{axis}
\end{tikzpicture} \caption{The Gaussian gets very narrow and very high as $\varepsilon$ decreases.}

\par\end{centering}

\end{figure}


Estimate the integral as follows:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\varepsilon\right)^{\frac{n}{2}}}\left(\int_{\mathbb{R}^{n}}f\left(p\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q+\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q\right)
\end{align*}
The first integral gives:
\begin{align*}
\int_{\mathbb{R}^{n}}e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q & \sr ={z=\frac{p-q}{2\sqrt{\varepsilon}}}{\dd^{n}z=\frac{\dd^{n}q}{\left(4\varepsilon\right)^{\frac{n}{2}}}}\left(4\varepsilon\right)^{\frac{n}{2}}\underbrace{\int_{\mathbb{R}^{n}}e^{-z^{2}}\dd^{n}q}_{=\pi^{\frac{n}{2}}}=\left(4\pi\varepsilon\right)^{\frac{n}{2}}
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =f\left(p\right)+\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\varepsilon\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{n}q
\end{align*}
It remains to show that the second summand goes to zero for $\varepsilon\to0$.
We use the following scaling argument:
\begin{align*}
\frac{1}{\varepsilon^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(q\right)-f\left(p\right)\right)e^{-\frac{\left(p-q\right)^{2}}{4\varepsilon}}\dd^{4}q & \sr ={u=\frac{p-q}{\sqrt{\varepsilon}}}{\dd^{n}q=\varepsilon^{\frac{n}{2}}\dd^{n}u}\frac{1}{\varepsilon^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)e^{-\frac{u^{2}}{4}}\varepsilon^{\frac{n}{2}}\dd^{n}u=\\
 & =\int_{\mathbb{R}^{n}}\underbrace{\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{\xrightarrow{\varepsilon\searrow0}0\ \text{pointwise}}e^{-\frac{u^{2}}{4}}\dd^{n}u
\end{align*}
For the integrand holds:
\begin{align*}
\underbrace{\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{\xrightarrow{\varepsilon\searrow0}0\ \text{pointwise}}e^{-\frac{u^{2}}{4}} & \le\norm f_{0,0}e^{-\frac{u^{2}}{4}}\in L^{1}\left(\mathbb{R}^{n}\right)
\end{align*}
So the dominated convergence theorem can be applied to get:
\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}f\right)\left(p\right) & =f\left(p\right)+\lim_{\varepsilon\searrow0}\frac{1}{\left(4\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\underbrace{\lim_{\varepsilon\searrow0}\left(f\left(p-\sqrt{\varepsilon}u\right)-f\left(p\right)\right)}_{=0}e^{-\frac{u^{2}}{4}}\dd^{n}u=f\left(p\right)
\end{align*}


$\overline{\mathcal{F}}\mathcal{F}=\mathbbm{1}$ follows analogously.\qqed

We want to generalize the Fourier transform to $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
We begin with the case $T_{g}$ with $g\in\mathcal{S}\left(\mathbb{R}^{n}\right)$.
We want:
\begin{align*}
\mathcal{F}\left(T_{g}\right) & =T_{\mathcal{F}g}
\end{align*}
\begin{align*}
T_{\mathcal{F}g}\left(f\right) & =\int_{\mathbb{R}^{n}}\left(\mathcal{F}g\right)\left(p\right)f\left(p\right)\dd^{n}p=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}\left(\int_{\mathbb{R}^{n}}e^{-\ii px}g\left(x\right)\dd^{n}x\right)f\left(p\right)\dd^{n}p
\end{align*}
Fubini's theorem allows us to interchange the order of integration:
\begin{align*}
T_{\mathcal{F}g}\left(f\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}g\left(x\right)\underbrace{\left(\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(p\right)\dd^{n}p\right)}_{=\mathcal{F}f\left(x\right)}\dd^{n}x=\int_{\mathbb{R}^{n}}g\left(x\right)\left(\mathcal{F}f\right)\left(x\right)\dd^{n}x=\TT_{g}\left(\mathcal{F}f\right)
\end{align*}
Since we want $\left(\mathcal{F}T_{g}\right)\left(f\right)=T_{\mathcal{F}g}=T_{g}\left(\mathcal{F}f\right)$,
this motivates the following general definition:


\subsection{Definition \textmd{(Fourier Transform of Distributions)\label{sub:Def-Fourier_distribution}}}

$\mathcal{F},\overline{\mathcal{F}}:\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\to\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
are defined by their action on a test function $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$:
\begin{align}
\left(\mathcal{F}T\right)\left(f\right) & :=T\left(\mathcal{F}f\right)\\
\left(\overline{\mathcal{F}}T\right)\left(f\right) & :=T\left(\overline{\mathcal{F}}f\right)
\end{align}
It holds:
\begin{align*}
\abs{\left(\mathcal{F}T\right)\left(f\right)} & =\abs{T\left(\mathcal{F}f\right)}\sr{\le}{T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}{\Rightarrow\exs r,s\in\mathbb{N},c\in\mathbb{R}_{>0}}c\norm{\mathcal{F}f}_{r,s}\le\tilde{c}\norm f_{s+n+1,r}
\end{align*}
Thus $\mathcal{F}T$ is indeed a tempered distribution.


\subsection{Theorem \textmd{(Plancherel for Distributions)}}

Plancherel's theorem holds on $\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$
as well:
\begin{align}
\mathcal{F}\overline{\mathcal{F}} & =\overline{\mathcal{F}}\mathcal{F}=\mathbbm{1}_{\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}
\end{align}



\subsubsection*{Proof}

\begin{align*}
\left(\mathcal{F}\overline{\mathcal{F}}T\right)\left(f\right) & \stackrel{\text{Definition }\ref{sub:Def-Fourier_distribution}}{=}\left(\overline{\mathcal{F}}T\right)\left(\mathcal{F}f\right)=T\left(\overline{\mathcal{F}}\mathcal{F}f\right)\stackrel{\text{Plancherel }\ref{sub:Thm-Plancherel}}{=}T\left(f\right)
\end{align*}
Since this holds for all $f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
and all $T\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$ it follows:
\begin{align*}
\mathcal{F}\overline{\mathcal{F}} & =\mathbbm{1}_{\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)}
\end{align*}
The same follows for $\overline{\mathcal{F}}\mathcal{F}$.\qqed


\subsection{Examples}
\begin{enumerate}
\item The Fourier transform of the $\delta$-Distribution can be calculated
as follows:
\begin{align*}
\left(\mathcal{F}\delta\right)\left(f\right) & =\delta\left(\mathcal{F}f\right)=\left(\mathcal{F}f\right)\left(0\right)=\\
 & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}f\left(x\right)\dd^{n}x\bigg|_{p=0}=\int_{\mathbb{R}^{n}}\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}f\left(x\right)\dd^{n}x=T_{\left(2\pi\right)^{-\frac{n}{2}}}\left(f\right)
\end{align*}
This means:
\begin{align*}
\mathcal{F}\delta & =T_{\left(2\pi\right)^{-\frac{n}{2}}}
\end{align*}
Or, in a more computational manner, one can write this as:
\begin{align*}
\mathcal{F}\delta & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}\delta\left(x\right)\dd^{n}x=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}
\end{align*}
This is not satisfying from a mathematical point of view, because
one does not know, that the usual formula for the Fourier transform
also works for distributions.
\item Consider $T_{f}$ with $f\left(p\right)=e^{\ii py}$ for a given $y\in\mathbb{R}^{n}$.
\begin{align*}
\left(\mathcal{F}T_{f}\right)\left(h\right) & =T_{f}\left(\mathcal{F}h\right)=T_{f}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int e^{-\ii px}h\left(x\right)\dd^{n}x\right)=\\
 & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int e^{\ii py}\left(\int e^{-\ii px}h\left(x\right)\dd^{n}x\right)\dd^{n}p=\\
 & =\left(2\pi\right)^{\frac{n}{2}}\left(\overline{\mathcal{F}}\mathcal{F}\right)h\left(y\right)=\left(2\pi\right)^{\frac{n}{2}}h\left(y\right)
\end{align*}
So we get:
\begin{align*}
\mathcal{F}T_{f}h & =\left(2\pi\right)^{\frac{n}{2}}h\left(y\right)\\
\left(\mathcal{F}T_{f}\right)\left(x\right) & =\left(2\pi\right)^{\frac{n}{2}}\delta^{\left(n\right)}\left(x-y\right)
\end{align*}
Formally one can write:
\begin{align*}
\left(\mathcal{F}f\right)\left(x\right) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii px}e^{\ii py}\dd^{n}p=\frac{1}{\left(2\pi\right)^{\frac{n}{2}}}\int_{\mathbb{R}^{n}}e^{-\ii p\left(x-y\right)}\dd^{n}p
\end{align*}
This is ill-defined, but physicists use the formal relation:
\begin{align*}
\int_{\mathbb{R}^{n}}e^{-\ii p\left(x-y\right)}\dd^{n}p & =\left(2\pi\right)^{n}\delta^{\left(n\right)}\left(x-y\right)
\end{align*}
%DATE: Fr 3.5.13
\item Consider $T=T_{g}$ with $g\left(p\right)=p^{2}e^{\ii py}$ for a
given $y\in\mathbb{R}$. 
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =T_{g}\left(\mathcal{F}f\right)=\int_{-\infty}^{\infty}g\left(p\right)\left(\mathcal{F}f\right)\left(p\right)\dd p=\\
 & =\int g\left(p\right)\left(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}f\left(x\right)e^{-\ii px}\dd x\right)\dd p
\end{align*}
One cannot interchange the integrals, because the integral
\begin{align*}
\int_{-\infty}^{\infty}\underbrace{g\left(p\right)e^{-\ii p\alpha}}_{\not\in L^{1}}\dd p
\end{align*}
does not exist. Therefore we work again with a convergence generating
factor, which we can due to the dominated convergence theorem:
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}g\left(p\right)e^{-\varepsilon\abs p}\left(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}f\left(x\right)e^{-\ii px}\dd x\right)\dd p=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}g\left(p\right)e^{-\varepsilon\abs p}e^{-\ii px}\dd p\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}p^{2}e^{\ii py}e^{-\varepsilon\abs p}e^{-\ii px}\dd p\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\int_{-\infty}^{\infty}\left(\ii\partial_{x}\right)^{2}e^{-\ii p\left(x-y\right)-\varepsilon\abs p}\dd p\right)\dd x=\\
 & \stackrel{\text{Lebesgue theorem}}{=}\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\ii\partial_{x}\right)^{2}\left(\int_{-\infty}^{\infty}e^{-\ii p\left(x-y\right)-\varepsilon\abs p}\dd p\right)\dd x
\end{align*}
Now one can decompose the integral into integrals from $-\infty$
to 0 and from $0$ to $\infty$ and calculate the result.
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(f\right) & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\left(\ii\partial_{x}\right)^{2}\left(\int_{-\infty}^{0}e^{-\ii p\left(x-y\right)+\varepsilon p}\dd p+\int_{0}^{\infty}e^{-\ii p\left(x-y\right)-\varepsilon p}\dd p\right)\dd x=\\
 & =\frac{-1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{1}{-\ii\left(x-y\right)+\varepsilon}-\frac{1}{-\ii\left(x-y\right)-\varepsilon}\right)\dd x=\\
 & =\frac{-1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{-\ii\left(x-y\right)-\varepsilon-\left(-\ii\left(x-y\right)+\varepsilon\right)}{-\left(x-y\right)^{2}-\varepsilon^{2}}\right)\dd x=\\
 & =\frac{1}{\sqrt{2\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f\left(x\right)\partial_{x}^{2}\left(\frac{2\varepsilon}{\left(x-y\right)^{2}+\varepsilon^{2}}\right)\dd x=\\
 & \sr ={\text{integration}}{\text{by parts}}\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(x\right)\cdot\frac{\varepsilon}{\left(x-y\right)^{2}+\varepsilon^{2}}\dd x=\\
 & \sr ={z:=\frac{x-y}{\varepsilon}}{\dd z=\frac{\dd x}{\varepsilon}}\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(\varepsilon z+y\right)\cdot\frac{\varepsilon}{\varepsilon^{2}z^{2}+\varepsilon^{2}}\varepsilon\dd z=\\
 & =\sqrt{\frac{2}{\pi}}\lim_{\varepsilon\searrow0}\int_{-\infty}^{\infty}f''\left(\varepsilon z+y\right)\cdot\frac{1}{z^{2}+1}\dd z=\\
 & =\sqrt{\frac{2}{\pi}}f''\left(y\right)\underbrace{\int_{-\infty}^{\infty}\frac{1}{z^{2}+1}\dd z}_{=\pi}=\sqrt{2\pi}f''\left(y\right)
\end{align*}
So we get:
\begin{align*}
\left(\mathcal{F}T_{g}\right)\left(x\right) & =\sqrt{2\pi}\delta''\left(x-y\right)
\end{align*}

\item Consider the following Hilbert space:
\begin{align*}
L^{2}\left(\mathbb{R}^{n}\right) & =\left\{ f:\mathbb{R}^{n}\to\mathbb{R}\bigg|f\text{ measurable with }\int\abs f^{2}\dd^{n}x<\infty\right\} 
\end{align*}
For $f\in L^{2}\left(\mathbb{R}^{n}\right)$ define:
\begin{align*}
T_{f}\left(g\right) & :=\int_{\mathbb{R}^{n}}f\left(x\right)g\left(x\right)\dd^{n}x\\
\abs{T_{f}\left(g\right)} & \stackrel{\text{Schwarz}}{\le}\norm f_{L^{2}\left(\mathbb{R}^{n}\right)}\norm g_{L^{2}\left(\mathbb{R}^{n}\right)}\le\norm f_{L^{2}\left(\mathbb{R}^{n}\right)}\cdot c\left(n\right)\norm g_{n+1,0}
\end{align*}
Here we used:
\begin{align*}
\abs{g\left(x\right)} & \le\tilde{c}\left(n\right)\frac{\norm g_{n+1,0}}{\left(1+\abs x\right)^{n+1}}
\end{align*}
So we have $T_{f}\in\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)$.
\begin{align*}
L^{2}\left(\mathbb{R}^{n}\right) & \hookrightarrow\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\xrightarrow{\mathcal{F}}\mathcal{S}^{*}\left(\mathbb{R}^{n}\right)\\
f & \mapsto\ \ \ T_{f}\quad\mapsto\mathcal{F}T_{f}
\end{align*}

\end{enumerate}

\subsection{Theorem \textmd{(Fourier Transform is isometry)}}

The mappings $\mathcal{F},\overline{\mathcal{F}}:L^{2}\left(\mathbb{R}^{n}\right)\to L^{2}\left(\mathbb{R}^{n}\right)$
are isometries, i.e.:
\begin{align}
\norm f_{L^{2}\left(\mathbb{R}^{n}\right)} & =\norm{\mathcal{F}f}_{L^{2}\left(\mathbb{R}^{n}\right)}
\end{align}
Due to $\mathcal{F}\overline{\mathcal{F}}=1$ they are even unitary
transformations.


\subsubsection*{Proof}

Consider first $f,g\in\mathcal{S}\left(\mathbb{R}^{n}\right)\subseteq L^{2}\left(\mathbb{R}^{n}\right)$.
\begin{align*}
\left\langle \mathcal{F}f,\mathcal{F}g\right\rangle _{L^{2}\left(\mathbb{R}^{n}\right)} & =\int_{\mathbb{R}^{n}}\overline{\left(\mathcal{F}f\right)\left(x\right)}\left(\mathcal{F}g\right)\left(x\right)\dd^{n}x\stackrel{?}{=}\int\overline{f}\left(x\right)g\left(x\right)\dd^{n}x\\
 & =T_{\overline{\mathcal{F}}\,\overline{f}}\left(\mathcal{F}g\right)=\left(\overline{\mathcal{F}}T_{\overline{f}}\right)\left(\mathcal{F}g\right)=T_{\overline{f}}\left(\overline{\mathcal{F}}\mathcal{F}g\right)=\\
 & \stackrel{\overline{\mathcal{F}}\mathcal{F}=1}{=}T_{\overline{f}}\left(g\right)=\int\overline{f}\left(x\right)g\left(x\right)\dd^{n}x
\end{align*}
$\mathcal{S}\left(\mathbb{R}^{n}\right)$ is dense in $L^{2}\left(\mathbb{R}^{n}\right)$.
Because $\mathcal{F}$ is continuous, $\mathcal{F}$ is also isometric
on $L^{2}\left(\mathbb{R}^{n}\right)$.\\
For $f\in L^{2}\left(\mathbb{R}^{n}\right)$ choose $f_{n}\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
with $f_{n}\to f$ converging in $L^{2}\left(\mathbb{R}^{n}\right)$.
Then holds for all $n\in\mathbb{N}$:
\begin{align*}
\norm{f_{n}}_{L^{2}} & =\norm{\mathcal{F}f_{n}}
\end{align*}
In the limes $n\to\infty$ we get, since $\mathcal{F}$ is continuous:
\begin{align*}
\norm f & =\norm{\mathcal{F}f}
\end{align*}
\qqed


\section{Applications to Partial Differential Equations with Constant Coefficients}

Consider as example the Poisson equation
\begin{align*}
\upDelta u & =f
\end{align*}
 in $\mathbb{R}^{n}$ with a given $f$ and assume for simplicity
$f\in\mathcal{S}\left(\mathbb{R}^{n}\right)$. After a Fourier transform
and defining $\hat{u}:=\mathcal{F}u$ and $\hat{f}=\mathcal{F}f$
we get:
\begin{align*}
\left(-\norm p^{2}\right)\hat{u}\left(p\right) & =\hat{f}\left(p\right)\\
\Rightarrow\qquad\hat{u}\left(p\right) & =-\frac{\hat{f}\left(p\right)}{\norm p^{2}}
\end{align*}
Then $\overline{\mathcal{F}}\hat{u}$ is a solution of the Poisson
equation.
\begin{itemize}
\item For $\norm p^{-2}\hat{f}\left(p\right)\in\mathcal{S}\left(\mathbb{R}^{n}\right)$
the method works directly and one gets a $u\in\mathcal{S}\left(\mathbb{R}^{n}\right)$.
\item In the case of $n\ge3$, $\hat{u}=-\norm p^{-2}\hat{f}\left(p\right)$
is a regular distribution. (If $n<3$ the integral does not necessarily
converge.)
\begin{align*}
\left(T_{\hat{u}}\right)\left(g\right) & :=\int\left(-\frac{\hat{f}\left(p\right)}{\norm p^{2}}\right)g\left(p\right)\dd^{n}p
\end{align*}
Therefore $u:=\overline{\mathcal{F}}T_{\hat{u}}$ is a distributional
solution of the Poisson equation, so we get $\upDelta u=T_{f}$.

\begin{description}
\item [{Problem:}] The distributional solution is not unique, because e.g.
\begin{align*}
\hat{u}\left(p\right) & =-\frac{\hat{f}\left(p\right)}{\norm p^{2}}+c\delta\left(p\right)
\end{align*}
is also a solution. Therefore we have to specify the behavior of $u\left(x\right)$
in the limit $\norm x\to\infty$.
\end{description}
\end{itemize}

\chapter{The Laplace Equation\texorpdfstring{ in $\Omega\subseteq\mathbb{R}^{n}$}{}}

In this chapter we always consider an open subset $\Omega\subseteq\mathbb{R}^{n}$
with boundary $\partial\Omega$. With the Laplacian
\begin{align}
\upDelta & =\frac{\partial^{2}}{\partial x_{1}^{2}}+\ldots+\frac{\partial^{2}}{\partial x_{n}^{2}}
\end{align}
the Laplace equation can be written as:
\begin{align*}
\upDelta u & =0
\end{align*}
The inhomogeneous Laplace equation is called Poisson equation:
\begin{align*}
\upDelta u & =f
\end{align*}
For both one needs to specify boundary conditions on $\partial\Omega$
to get a unique solution.

\setcounter{section}{-1}


\section{Reminder}


\subsection{Theorem \textmd{(Gauss's Theorem)}}

If $Y$ is a smooth vector field on the closure $\overline{\Omega}$
and $\partial\Omega$ is smooth with outer normal $\nu$, then holds:
\begin{align}
\int_{\Omega}\text{div}\left(Y\right)\underbrace{\dd^{n}x}_{=\dd\mu} & =\int_{\partial\Omega}\left\langle Y,\nu\right\rangle \dd\mu_{\partial\Omega}
\end{align}



\subsubsection*{(Proof omitted)}


\subsection{Theorem \textmd{(Green's Identities)}}

For $u,w\in C^{\infty}\left(\overline{\Omega}\right)$ holds:
\begin{align}
\int_{\Omega}w\upDelta u\dd\mu_{\Omega} & =\int_{\partial\Omega}w\left(\nabla_{\nu}u\right)\dd\mu_{\partial\Omega}-\int_{\Omega}\left\langle \nabla w,\nabla u\right\rangle \dd\mu_{\Omega}\\
\int_{\Omega}\left(w\left(\upDelta u\right)-\left(\upDelta w\right)u\right)\dd\mu_{\Omega} & =\int_{\partial\Omega}\left(w\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}w\right)u\right)\dd\mu_{\partial\Omega}
\end{align}



\subsubsection*{Proof}

We use $\upDelta=\text{div}\,\text{grad}$ and integrate by parts:
\begin{align*}
\int_{\Omega}w\upDelta u\dd\mu_{\Omega} & =\int_{\Omega}w\cdot\text{div}\left(\nabla u\right)\dd\mu_{\Omega}=\int_{\Omega}\text{div}\left(w\nabla u\right)-\left\langle \nabla w,\nabla u\right\rangle \dd\mu_{\Omega}
\end{align*}
Then one can use Gauss's theorem to get the first identity. Now one
subtracts the identity with $w$ and $u$ commuted:
\begin{align*}
w\upDelta u-u\upDelta w & =\text{div}\left(w\nabla u\right)-\left\langle \nabla w,\nabla u\right\rangle -\left(\text{div}\left(u\nabla w\right)-\left\langle \nabla u,\nabla w\right\rangle \right)=\\
 & \stackrel{\left\langle .,.\right\rangle \text{ symmetric}}{=}\text{div}\left(w\nabla u\right)-\text{div}\left(u\nabla w\right)
\end{align*}
Using Gauss's theorem the second identity follows.\qqed


\section{Representation Formulas for Harmonic Functions}


\subsection{Definition \textmd{(Harmonic Functions)}}

A function $u\in C^{2}\left(\overline{\Omega}\right)$ is called \emph{harmonic},
if the Laplacian vanishes:
\begin{align*}
\upDelta u & =0
\end{align*}
The harmonic functions form a vector space.


\subsubsection*{Examples}
\begin{itemize}
\item Constant or linear functions
\item $u\left(x_{1},x_{2}\right)=x_{1}^{2}-x_{2}^{2}$ is harmonic on $\mathbb{R}^{2}$.
\item Holomorphic functions on $\Omega\subseteq\mathbb{C}\stackrel{\sim}{=}\mathbb{R}^{2}$
\end{itemize}
Consider now \emph{spherically symmetric harmonic functions}. For
this we choose polar coordinates $\left(r,\vartheta,\varphi\right)$
in $\mathbb{R}^{3}$:
\begin{align*}
x & =r\cos\left(\vartheta\right)\\
y & =r\sin\left(\vartheta\right)\cos\left(\varphi\right)\\
z & =r\sin\left(\vartheta\right)\sin\left(\varphi\right)
\end{align*}
More general in $\mathbb{R}^{n}$ with $n\in\mathbb{N}_{\ge2}$ we
choose $r=\norm x$ and $\omega\in S^{n-1}$. Regard $\mathbb{R}^{n}$
with the Euclidian metric as a Riemannian manifold $\left(M,g\right)$.
Polar coordinates give a special chart on $\Omega\subseteq M$ with
$0\not\in\Omega$. The we can calculate $\upDelta=\LBO$ as Laplace-Beltrami
operator in polar coordinates. The metric is:
\begin{align*}
g & =\left(\begin{array}{cc}
1 & 0\\
0 & r^{2}g_{S^{n-1}}
\end{array}\right) & g^{-1} & =\left(\begin{array}{cc}
1 & 0\\
0 & r^{-2}g_{S^{n-1}}^{-1}
\end{array}\right)
\end{align*}
\begin{align*}
\det\left(g\right) & =r^{2\left(n-1\right)}g_{S^{n-1}}\\
\sqrt{\det\left(g\right)} & =r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}
\end{align*}
Now the Laplace-Beltrami operator can be calculated with the \emph{Koszul
formula}:
\begin{align}
\LBO u & =\nabla_{j}\nabla^{j}u=\frac{1}{\sqrt{\det\left(g\right)}}\frac{\partial}{\partial x^{j}}\left(\sqrt{\det\left(g\right)}g^{jk}\frac{\partial}{\partial x^{k}}u\right)=\\
 & =\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial x^{j}}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}g^{jk}\frac{\partial}{\partial x^{k}}u\right)=\nonumber \\
 & =\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial r}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}\frac{\partial}{\partial r}u\right)+\nonumber \\
 & \qquad+\sum_{j,k=2}^{n}\frac{1}{r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}}\frac{\partial}{\partial x^{j}}\left(r^{n-1}\sqrt{\det\left(g_{S^{n-1}}\right)}\frac{1}{r^{2}}\left(g_{S^{n-1}}\right)^{jk}\frac{\partial}{\partial x^{k}}u\right)=\nonumber \\
 & =\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}u\right)+\frac{1}{r^{2}}\LBO_{S^{n-1}}u\nonumber 
\end{align}
The important formula is:
\begin{align}
\LBO & =\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}\,.\,\right)+\frac{1}{r^{2}}\LBO_{S^{n-1}}
\end{align}
For spherically symmetric solutions $\Gamma\in C^{\infty}\left(\mathbb{R}^{n}\setminus\left\{ 0\right\} \right)$,
the Laplace equation reads:
\begin{align*}
\LB\Gamma=\frac{1}{r^{n-1}}\frac{\partial}{\partial r}\left(r^{n-1}\frac{\partial}{\partial r}\Gamma\left(r\right)\right) & =0
\end{align*}


%DATE: Mi 8.5.13

This gives:
\begin{align*}
r^{n-1}\frac{\partial}{\partial r}\Gamma\left(r\right) & =c\\
\frac{\partial}{\partial r}\Gamma\left(r\right) & =cr^{1-n}
\end{align*}
\begin{align*}
\Gamma\left(r\right) & =a+C\int^{r}\tau^{1-n}\dd\tau=\begin{cases}
a+\tilde{c}\ln\left(r\right) & \text{if }n=2\\
a+\frac{c}{r^{n-2}} & \text{if }n>2
\end{cases}
\end{align*}
Now we choose specific values for $a$ and $c$ or $\tilde{c}$.


\subsection{Definition \textmd{(Fundamental Solution of Laplace Equation)}}

The \emph{fundamental solution} $\Gamma$ of the Laplace equation
in $\mathbb{R}^{n}$ is defined by:
\begin{align}
\Gamma\left(x,y\right) & =\Gamma\left(\norm{x-y}\right):=\begin{cases}
\frac{1}{2\pi}\ln\left(\norm{x-y}\right) & \text{if }n=2\\
\frac{1}{n\left(2-n\right)\omega_{n}}\norm{x-y}^{2-n} & \text{if }n>2
\end{cases}
\end{align}
Here $\omega_{n}:=\mu\left(B_{1}\left(0\right)\right)$ is the Lebesgue
measure of the unit ball.

For example for $n=3$ we have $\omega_{3}=\frac{4\pi}{3}$ and thus:
\begin{align}
\Gamma\left(x,y\right) & =\frac{1}{3\left(-1\right)\frac{4\pi}{3}}\cdot\frac{1}{\norm{x-y}}=-\frac{1}{4\pi}\frac{1}{\norm{x-y}}
\end{align}



\subsection{Theorem \textmd{(Green's representation)}}

Let $\Omega\subseteq\mathbb{R}^{n}$ be open with smooth boundary
and $u\in C^{2}\left(\overline{\Omega}\right)$. Then for any $y\in\Omega$
holds:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align}
For harmonic functions with $\upDelta u=0$, this simplifies to:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align}
Thus $u$ has an explicit representation in terms of its boundary
values on $\partial\Omega$.


\subsubsection*{Proof}

Choose $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(y\right)\subseteq\Omega$.
\begin{align*}
\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}\underbrace{\Gamma\left(x,y\right)}_{\text{smooth}}\underbrace{\left(\upDelta u\right)\left(x\right)}_{\text{continuous}}\dd\mu\left(x\right)
\end{align*}


\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[scale=2]{>}};},postaction={decorate}},scale=0.8]
  \draw (-0.1,-0.1) -- (0.1,0.1);
  \draw (-0.1,0.1) -- (0.1,-0.1);
  \node[right=0pt] at (0,0) {$y$};
  \draw (0,0) circle(1);
  \draw[dashed] (0,0) -- node[above left=-2pt]{$\varepsilon$} ({cos(100)},{sin(100)});
  \draw plot[smooth cycle,tension=.7,scale=2] coordinates{(0,-2) (1,-0.95) (2,0.2) (1.5,1.4) (0,2) (-2,-0.5)};
  \node at (0.5,4.5) {$\Omega$};
  \foreach \x in {20,80,...,360} {
    \draw[arr, orange] ({cos(\x)},{sin(\x)}) -- ({1.5*cos(\x)},{1.5*sin(\x)});
    \draw[arr] ({cos(\x)},{sin(\x)}) -- ({0.5*cos(\x)},{0.5*sin(\x)});
	}
  \node[orange] at (1.5,0.3) {$\nu$};
  \draw[arr] (0,4) -- (-0.3,4.45);
  \draw[arr] (4.05,1) -- (4.55,1);
  \draw[arr] (2,-1.9) -- (2.3,-2.2);
  \draw[arr] (-2,-3.27) -- node[below right=2pt]{$\nu$} (-2.25,-3.74);
  \draw[arr] (-3,1.2) -- (-3.4,1.5);
\end{tikzpicture}
\par\end{centering}

\caption{Outer normal $\nu$ of $\Omega\setminus B_{\varepsilon}\left(y\right)$
(black) and of $B_{\varepsilon}\left(y\right)$ (orange) }
\end{figure}


We apply the second Green's identity to obtain with $v\left(x\right):=\Gamma\left(x,y\right)$:
\begin{align*}
\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}\big(v\cdot\upDelta u-\underbrace{\left(\upDelta v\right)}_{=0}u\big)\dd\mu & =\int_{\partial\left(\Omega\setminus B_{\varepsilon}\left(y\right)\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial\Omega}=\\
 & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}+\\
 & \qquad-\int_{\partial B_{\varepsilon}\left(y\right)}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\nabla_{\nu}\Gamma\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)}
\end{align*}
The minus in front of $\int_{\partial B_{\varepsilon}\left(y\right)}$
comes from the fact, that the outer normal of $\partial\left(\Omega\setminus B_{\varepsilon}\left(y\right)\right)$
shows in the opposite direction of the outer normal of $\partial B_{\varepsilon}\left(y\right)$.
The left side of the integral gives in the limit $\varepsilon\searrow0$:
\begin{align*}
\lim_{\varepsilon\searrow0}\int_{\Omega\setminus B_{\varepsilon}\left(y\right)}v\cdot\upDelta u\dd\mu & =\int_{\Omega}v\cdot\upDelta u\dd\mu=\int_{\Omega}\Gamma\left(x,y\right)\cdot\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
We estimate the integral over $\partial B_{\varepsilon}\left(y\right)$
in the limit $\varepsilon\searrow0$:
\begin{align*}
\abs{\int_{\partial B_{\varepsilon}\left(y\right)}\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)}} & \le\Gamma\left(\varepsilon\right)\sup_{B_{\varepsilon}\left(y\right)}\norm{\nabla u}\cdot\underbrace{n\omega_{n}}_{\sr{}{\text{surface area of}}{\text{the unit sphere}}}\varepsilon^{n-1}\sim\\
 & \sim\begin{cases}
\varepsilon & \text{if }n>2\\
\varepsilon\ln\left(\varepsilon\right) & \text{if }n=2
\end{cases}\xrightarrow{\varepsilon\searrow0}0
\end{align*}
Now we expand the second part around $\varepsilon=0$:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(y\right)}\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\dd\mu_{\partial B_{\varepsilon}\left(y\right)} & =\underbrace{\frac{\partial}{\partial\varepsilon}\Gamma\left(\varepsilon\right)}_{=\frac{1}{n\omega_{n}}\varepsilon^{1-n}}\underbrace{\int_{\partial B_{\varepsilon}\left(y\right)}u\left(x\right)\dd\mu_{B_{\varepsilon}\left(y\right)}}_{=u\left(y\right)n\omega_{n}\varepsilon^{n-1}+o_{0}\left(\varepsilon^{n-1}\right)}=\\
 & =u\left(y\right)+o_{0}\left(\varepsilon^{0}\right)\xrightarrow{\varepsilon\searrow0}u\left(y\right)
\end{align*}
This gives:
\begin{align*}
\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)-\left(\nabla_{\nu}\Gamma\right)\left(x,y\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}+u\left(y\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
\qqed


\subsection{Corollary \textmd{(Laplacian of Fundamental Solution is Delta Distribution)}}

For any $\varphi\in C_{0}^{\infty}\left(\Omega\right)$ holds:
\begin{align}
\varphi\left(y\right) & =\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)\label{eq:phi-as-integral}
\end{align}
This can also be expressed in terms of distributions as:
\begin{align}
\upDelta_{x}\Gamma\left(x,y\right) & =\delta^{\left(n\right)}\left(x-y\right)
\end{align}
More correctly, for fixed $y\in\mathbb{R}^{n}$, $T\left(x\right):=T_{\Gamma\left(x,y\right)}$
defines a regular distribution. Equation (\ref{eq:phi-as-integral})
means, that for all $\varphi\in C_{0}^{\infty}\left(\Omega\right)\subseteq\mathcal{S}\left(\mathbb{R}^{n}\right)$:
\begin{align*}
\left(\upDelta T\right)\left(\varphi\right) & =\varphi\left(y\right)\\
\Leftrightarrow\qquad\upDelta T & =\delta_{y}
\end{align*}



\subsubsection*{Proof}

Since the support of $\varphi$ lies inside of $\Omega$, the first
term in Green's representation vanishes:
\begin{align*}
\varphi\left(y\right) & =\int_{\partial\Omega}\left(\varphi\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}\varphi\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)=\\
 & =\int_{\Omega}\Gamma\left(x,y\right)\left(\upDelta\varphi\right)\left(x\right)\dd\mu\left(x\right)
\end{align*}
\qqed

Next we investigate the existence of solutions.
\begin{align}
\upDelta u & =0 & u\big|_{\partial\Omega} & =u_{0} &  & \text{Dirichlet problem}\\
\upDelta u & =0 & \nabla_{\nu}u\big|_{\partial\Omega} & =u_{1} &  & \text{Neumann problem}
\end{align}
The problem is, that the representation
\begin{align*}
u\left(y\right) & =\int_{\partial\Omega}\left(u\left(x\right)\nabla_{\nu}\Gamma\left(x,y\right)-\Gamma\left(x,y\right)\nabla_{\nu}u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align*}
needs booth $u$ and $\nabla_{\nu}u$ on the boundary. Suppose we
want to solve the Dirichlet problem. Then $u_{0}=u\big|_{\partial\Omega}$
is given, but $\nabla_{\nu}u\big|_{\partial\Omega}$ is unknown.


\section{The Green's Function}

Consider the Dirichlet problem for the Poisson equation:
\begin{align}
\upDelta u\left(x\right) & =f\left(x\right)\qquad\fall_{x\in\Omega} & u\big|_{\partial\Omega} & =\varphi
\end{align}
Assume $u\in C^{2}\left(\overline{\Omega}\right)$, $f\in C^{0}\left(\overline{\Omega}\right)$
and $\varphi\in C^{2}\left(\partial\Omega\right)$.


\subsection{Definition \textmd{(Green's function)}}

A function $G\left(x,y\right)$ defined for $x,y\in\overline{\Omega}$
with $x\not=y$ is called \emph{Green's function} for the domain $\Omega$
if the following conditions are satisfied:
\begin{enumerate}[label=\roman*)]
\item For all $x\in\partial\Omega$ and $y\not=x$ holds ${\displaystyle G\left(x,y\right)=0}$.
\item $h\left(x,y\right):=G\left(x,y\right)-\Gamma\left(x,y\right)$ is
in $C^{2}\left(\Omega\right)$, even for $x=y$, and harmonic in $x\in\Omega$.
\end{enumerate}

\subsection{Proposition \textmd{(Solution of Dirichlet Problem)}}

For a solution $u$ of the Dirichlet problem for the Poisson equation
holds:
\begin{align}
u\left(y\right) & =\int_{\partial\Omega}u\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}f\left(x\right)G\left(x,y\right)\dd\mu\left(x\right)
\end{align}



\subsubsection*{Proof}

\begin{align*}
\int_{\Omega}h\left(x,y\right)\left(\upDelta u\right)\left(x\right)\dd\mu\left(x\right) & =\int_{\Omega}h\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)=\\
 & \sr ={\text{2. Green's}}{\text{identity}}\int_{\partial\Omega}\left(h\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}h\left(x,y\right)\right)\cdot u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)
\end{align*}
Now we add the Green's representation
\begin{align*}
\int_{\Omega}\Gamma\left(x,y\right)f\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(\Gamma\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}\Gamma\left(x,y\right)\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+u\left(y\right)
\end{align*}
to get:
\begin{align*}
\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right) & =\int_{\partial\Omega}\left(G\left(x,y\right)\left(\nabla_{\nu}u\right)\left(x\right)-\left(\nabla_{\nu}G\left(x,y\right)\right)u\left(x\right)\right)\dd\mu_{\partial\Omega}\left(x\right)+u\left(y\right)
\end{align*}
Since $G\left(x,y\right)=0$ on $\partial\Omega$, the proposition
follows.\qqed


\subsection{Theorem \textmd{(Symmetry of the Green's Function)}}

For all $x,y\in\Omega$ with $x\not=y$ holds:
\begin{align}
G\left(x,y\right) & =G\left(y,x\right)
\end{align}



\subsubsection*{Proof}

\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[scale=0.7]
  \node at (0.5,4.5) {$\Omega$};
  \draw[clip] plot[smooth cycle,tension=.7,scale=2] coordinates{(0,-2) (1,-0.95) (2,0.2) (1.5,1.4) (0,2) (-2,-0.5)};
  \foreach \x in {-4.5,-3,...,2}     \draw (\x,-5) -- ({\x + 3},5);
  \draw[fill=white] (1,0) circle(1);
  \draw (1,0) +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \node[right=0pt] at (1,0) {$y$};
  \draw[dashed] (1,0) -- node[above left=-2pt]{$\varepsilon$} +({cos(90)},{sin(90)});
  \draw[fill=white] (-2.5,-1) circle(1);
  \draw (-2.5,-1) +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \node[right=0pt] at (-2.5,-1) {$x$};
  \draw[dashed] (-2.5,-1) -- node[above left=-2pt]{$\varepsilon$} +({cos(90)},{sin(90)});
\end{tikzpicture}
\par\end{centering}

\caption{$B_{\varepsilon}\left(x\right)\subseteq\Omega$, $B_{\varepsilon}\left(y\right)\subseteq\Omega$,
$B_{\varepsilon}\left(x\right)\cap B_{\varepsilon}\left(y\right)=\emptyset$}
\end{figure}


Choose $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(x\right)$
and $B_{\varepsilon}\left(y\right)$ are disjoint subsets of $\Omega$.
\begin{align*}
u\left(z\right) & :=G\left(z,x\right) & v\left(z\right) & :=G\left(z,y\right)
\end{align*}
It holds $u,v\in C^{2}\left(\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)\right)$
and $u,v$ are harmonic. Moreover for $z\in\partial\Omega$ holds:
\begin{align*}
u\left(z\right) & =G\left(z,x\right)=0 & v\left(z\right) & =G\left(z,y\right)=0
\end{align*}
Apply again the second Green's identity:
\begin{align*}
0 & =\int_{\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}\big(v\underbrace{\left(\upDelta u\right)}_{=0}-\underbrace{\left(\upDelta v\right)}_{=0}u\big)\dd\mu=\\
 & =\int_{\partial\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial\Omega\setminus\left(B_{\varepsilon}\left(x\right)\cup B_{\varepsilon}\left(y\right)\right)}
\end{align*}
Moreover, the boundary values on $\partial\Omega$ vanish. We conclude:
\begin{align*}
0 & =\int_{\partial B_{\varepsilon}\left(x\right)\cup\partial B_{\varepsilon}\left(y\right)}\left(v\left(\nabla_{\nu}u\right)-\left(\nabla_{\nu}v\right)u\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)\cup\partial B_{\varepsilon}\left(y\right)}
\end{align*}
Consider the integral over $\partial B_{\varepsilon}\left(x\right)$
first. Since $G=\Gamma+h$ and $h\in C^{2}$ is bounded, we know for
all $z\in\partial B_{\varepsilon}\left(x\right)$:
\begin{align*}
u\left(z\right) & =G\left(z,x\right)\sim\Gamma\left(z,x\right)\sim\begin{cases}
\ln\left(\varepsilon\right) & \text{if }n=2\\
\varepsilon^{2-n} & \text{if }n>2
\end{cases}
\end{align*}
Since $\nabla_{\nu}v$ is also bounded due to $v\in C^{2}\left(B_{\varepsilon}\left(x\right)\right)$,
we get:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}\left(\nabla_{\nu}v\right)u\dd_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}0
\end{align*}
The other term gives:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}v\left(\nabla_{\nu}u\right)\dd_{\partial B_{\varepsilon}\left(x\right)} & \sr ={\nabla_{\nu}u=\frac{\partial}{\partial\varepsilon}\Gamma\left(\varepsilon\right)+o_{0}\left(\varepsilon^{0}\right)=}{=\tilde{c}\varepsilon^{1-n}+o_{0}\left(\varepsilon^{0}\right)}cv\left(x\right)\varepsilon^{1-n}\underbrace{\int_{\partial B_{\varepsilon}\left(x\right)}1\dd\mu_{\partial B_{\varepsilon}\left(x\right)}}_{=n\omega_{n}\varepsilon^{n-1}}+o_{0}\left(\varepsilon\right)\xrightarrow{\varepsilon\searrow0}cv\left(x\right)
\end{align*}
Here the constant $c\not=0$ does not vanish. Now follows:
\begin{align*}
\int_{\partial B_{\varepsilon}\left(x\right)}\left(\left(\nabla_{\nu}v\right)u-v\left(\nabla_{\nu}u\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}cv\left(x\right)\\
\int_{\partial B_{\varepsilon}\left(y\right)}\left(\left(\nabla_{\nu}v\right)u-v\left(\nabla_{\nu}u\right)\right)\dd\mu_{\partial B_{\varepsilon}\left(x\right)} & \xrightarrow{\varepsilon\searrow0}cu\left(y\right)
\end{align*}
Adding these two integrals gives:
\begin{align*}
0 & =c\left(v\left(x\right)-u\left(y\right)\right)\\
\Rightarrow\qquad G\left(x,y\right) & =v\left(x\right)=u\left(y\right)=G\left(y,x\right)
\end{align*}
\qqed

Any solution $u$ of the Dirichlet problem
\begin{align*}
\upDelta u & =f & u\big|_{\partial\Omega} & =\varphi
\end{align*}
has the representation:
\begin{align*}
u\left(y\right) & =\int_{\partial\Omega}u\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
We define:
\begin{align*}
u\left(y\right) & :=\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}G\left(x,y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
Since $G$ is symmetric, $G\left(x,y\right)=G\left(y,x\right)$, the
equation $\upDelta_{x}G\left(x,y\right)=\delta^{\left(n\right)}\left(x-y\right)$
implies $\upDelta_{y}G\left(x,y\right)=\delta^{\left(n\right)}\left(x-y\right)$
as well. As a consequence, a formal computation gives:
\begin{align*}
\upDelta_{y}u\left(y\right) & =\int_{\partial\Omega}\varphi\left(x\right)\nabla_{\nu}\delta^{\left(n\right)}\left(x-y\right)\dd\mu_{\partial\Omega}\left(x\right)+\int_{\Omega}\delta^{\left(n\right)}\left(x-y\right)f\left(x\right)\dd\mu\left(x\right)
\end{align*}
For $y\in\Omega$ the first term vanishes, so we get:
\begin{align*}
\upDelta_{y}u\left(y\right) & =f\left(y\right)
\end{align*}
This formal calculation can be made rigorous, once an explicit Green's
function is given. Then one can also check, whether the boundary conditions
are satisfied.

%DATE: Fr 10.5.13


\subsection{Example \textmd{(Green's function for \texorpdfstring{$B_{R}\left(0\right)$}{Br(0)})}}

Now we want to construction the Green's function for $\Omega:=B_{R}\left(0\right)\subseteq\mathbb{R}^{n}$.
Consider an electric charge inside an earthed, electrically conducting
sphere, that screens the electric field, so that it vanishes outside
the sphere. The electric field inside the sphere can be calculated
using the concept of a mirror charge, which ensures, that the electric
field is perpendicular to the sphere.

\begin{figure}[H]
\noindent \begin{centering}
\hfill{}\subfloat[charge in earthed sphere]{\begin{tikzpicture}[scale=1]
  \draw (0,0) circle (2cm);
  \draw (1,0) node[above]{$y$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0,0) +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0,0) -- node[above]{$R$} (-2,0);
  \draw ({2cm*cos(-10)},{2cm*sin(-10)}) -- ++(0,-2) +(-0.7,0) -- +(0.7,0) ++(0,-0.2) +(-0.4,0) -- +(0.4,0) ++(0,-0.2) +(-0.2,0) -- +(0.2,0);
\end{tikzpicture}}\hfill{}\subfloat[equivalent mirror charge outside sphere]{\begin{tikzpicture}
  \draw[dashed] (0,0) circle (2cm);
  \draw (0,0) +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1,0) node[above]{$y$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (4,0) node[above]{$\tilde{y}$} node[below]{mirror charge} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dashed] ({2cm*cos(-10)},{2cm*sin(-10)}) -- ++(0,-2) +(-0.7,0) -- +(0.7,0) ++(0,-0.2) +(-0.4,0) -- +(0.4,0) ++(0,-0.2) +(-0.2,0) -- +(0.2,0);
\end{tikzpicture}}\hfill{}
\par\end{centering}

\caption{The mirror charge replicates the boundary conditions of the sphere.}
\end{figure}


The position of the mirror charge must be:
\begin{align*}
\tilde{y} & =\frac{R^{2}}{y^{2}}\cdot y\\
\Rightarrow\qquad\norm y\cdot\norm{\tilde{y}} & =R^{2}
\end{align*}
Compare this with the inversion with respect to the unit circle (\foreignlanguage{ngerman}{Spiegelung
am Einheitskreis}) in the complex plane:
\begin{align*}
z & \mapsto\frac{1}{\overline{z}}=\frac{z}{\abs z^{2}}
\end{align*}
This motivates the ansatz:
\begin{align*}
G\left(x,y\right) & =\begin{cases}
\Gamma\left(\norm{x-y}\right)-\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & \text{if }y\not=0\\
\Gamma\left(\norm x\right)-\Gamma\left(R\right) & \text{if }y=0
\end{cases}
\end{align*}
Let us verify that $G$ has all the required properties:
\begin{align*}
G\left(x,y\right)-\Gamma\left(x,y\right) & =\begin{cases}
-\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & \text{if }y\not=0\\
-\Gamma\left(R\right) & \text{if }y=0
\end{cases}
\end{align*}
For $x,y\in B_{R}\left(0\right)$ follows $\tilde{y}\not\in B_{R}\left(0\right)$
and thus $x\not=\tilde{y}$. So $\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)$
is smooth if $y\not=0$. To see smoothness in the case $y=0$, we
rewrite:
\begin{align}
\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & =\Gamma\left(\sqrt{\frac{y^{2}}{R^{2}}\left(x^{2}+\tilde{y}^{2}-2\left\langle x,\tilde{y}\right\rangle \right)}\,\right)=\nonumber \\
 & =\Gamma\left(\sqrt{\frac{y^{2}}{R^{2}}\left(x^{2}+\frac{R^{4}}{y^{2}}-2\frac{R^{2}}{y^{2}}\left\langle x,y\right\rangle \right)}\,\right)=\nonumber \\
 & =\Gamma\left(\sqrt{\frac{x^{2}y^{2}}{R^{2}}+R^{2}-2\left\langle x,y\right\rangle }\,\right)\label{eq:G-symmetric}
\end{align}
The argument is smooth at $y=0$ and it holds:
\begin{align*}
\lim_{y\to0}\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & =\Gamma\left(R\right)
\end{align*}
So $G\left(x,y\right)-\Gamma\left(x,y\right)$ is in $C^{2}$ for
$x,y\in\Omega$.

For $x\in\partial\Omega$, i.e. $\norm x=R$, holds:
\begin{align*}
G\left(x,y\right) & =\Gamma\left(\norm{x-y}\right)-\Gamma\left(\sqrt{\frac{\norm x^{2}\norm y^{2}}{R^{2}}+R^{2}-2\left\langle x,y\right\rangle }\,\right)=\\
 & \sr ={\norm x=R}{}\Gamma\left(\norm{x-y}\right)-\Gamma\left(\sqrt{\norm y^{2}+\norm x^{2}-2\left\langle x,y\right\rangle }\,\right)=\\
 & =\Gamma\left(\norm{x-y}\right)-\Gamma\left(\sqrt{\norm{x-y}^{2}}\:\right)=0
\end{align*}
Thus $G\left(x,y\right)$ satisfies the boundary condition $G\left(x,y\right)=0$
for $x\in\partial\Omega$.\\
Now we show that $G\left(x,y\right)-\Gamma\left(x,y\right)$ is harmonic:
\begin{align*}
G\left(x,y\right)-\Gamma\left(x,y\right) & =-\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\\
\nabla\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & =\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\frac{\norm y}{R}\nabla\norm{x-\tilde{y}}\\
\upDelta\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & =\Gamma''\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\left(\frac{\norm y}{R}\right)^{2}\left(\nabla\norm{x-\tilde{y}}\right)^{2}+\\
 & \qquad+\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\frac{\norm y}{R}\upDelta\norm{x-\tilde{y}}
\end{align*}
We know:
\begin{align*}
0 & =\upDelta\Gamma=\frac{1}{r^{n-1}}\partial_{r}\left(r^{n-1}\partial_{r}\Gamma\right)\\
\Rightarrow\qquad0 & =\Gamma''\left(r\right)+\frac{n-1}{r}\Gamma'\left(r\right)
\end{align*}
With this follows:
\begin{align*}
\upDelta\Gamma\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right) & =-\left(n-1\right)\frac{R}{\norm y\norm{x-\tilde{y}}}\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\left(\frac{\norm y}{R}\right)^{2}\left(\nabla\norm{x-\tilde{y}}\right)^{2}+\\
 & \qquad+\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\frac{\norm y}{R}\upDelta\norm{x-\tilde{y}}=\\
 & =\frac{\norm y}{R}\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\left(\frac{-\left(n-1\right)}{\norm{x-\tilde{y}}}\left(\nabla\norm{x-\tilde{y}}\right)^{2}+\upDelta\norm{x-\tilde{y}}\right)=\\
 & =\frac{\norm y}{R}\Gamma'\left(\frac{\norm y}{R}\norm{x-\tilde{y}}\right)\left(\frac{-\left(n-1\right)}{\norm{x-\tilde{y}}}\left(\frac{x-\tilde{y}}{\norm{x-\tilde{y}}}\right)^{2}+\frac{n-1}{\norm{x-\tilde{y}}}\right)=0
\end{align*}
Thus $G\left(x,y\right)$ is the desired Green's function. From (\ref{eq:G-symmetric})
one sees explicitly:
\begin{align*}
G\left(x,y\right) & =G\left(y,x\right)
\end{align*}
We hope that the solution of the Dirichlet problem
\begin{align*}
\upDelta u & =f & u\big|_{\partial B_{R}\left(0\right)} & =\varphi
\end{align*}
is given by the Green's representation:
\begin{align*}
u\left(y\right) & =\int_{B_{R}\left(0\right)}G\left(x,y\right)f\left(x\right)\dd\mu\left(x\right)+\int_{B_{R}\left(0\right)}\nabla_{\nu}G\left(x,y\right)\varphi\left(x\right)\dd\mu_{\partial B_{R}\left(0\right)}\left(x\right)
\end{align*}
Computing $\nabla_{\nu}G\left(x,y\right)$ for $x\in\partial B_{R}\left(0\right)$
gives:
\begin{align*}
\nabla_{\nu}G\left(x,y\right) & =\frac{R^{2}-y^{2}}{n\omega_{n}R}\cdot\frac{1}{\norm{x-y}^{n}}
\end{align*}



\subsection{Theorem \textmd{(Poisson representation)}}

The function
\begin{align}
u\left(y\right) & :=\begin{cases}
\frac{R^{2}-y^{2}}{n\omega_{n}R}\int_{\partial B_{R}\left(0\right)}\frac{\varphi\left(x\right)}{\norm{x-y}^{n}}\dd\mu_{\partial B_{R}\left(0\right)} & \text{if }y\in B_{R}\left(0\right)\\
\varphi\left(y\right) & \text{if }y\in\partial B_{R}\left(0\right)
\end{cases}
\end{align}
with $\varphi\in C^{0}\left(\partial B_{R}\left(0\right)\right)$
has the following properties:
\begin{itemize}
\item $u\in C^{0}\left(\overline{B_{R}\left(0\right)}\right)$
\item $u\in C^{2}\left(B_{R}\left(0\right)\right)$
\item $u$ is harmonic in $B_{R}\left(0\right)$.
\end{itemize}

\subsubsection*{Proof}

This can be shown using Green's representation, computing the boundary
values and justifying that the $y$-derivative may be taken inside
the integral.\qqed


\section{The Mean Value Theorem and the Maximum Principle for Harmonic Functions}


\subsection{Theorem \textmd{(Mean Value Formulas)}}

A continuous function $u:\Omega\to\mathbb{R}$ with $\Omega\subseteq\mathbb{R}^{n}$
is harmonic, i.e. $u\in C^{2}\left(\Omega\right)$ and $\upDelta u=0$,
if and only if for all $x_{0}\in\Omega$ and all balls $B_{r}\left(x_{0}\right)\subseteq\Omega$
one of the following mean value formulas holds:
\begin{align}
u\left(x_{0}\right) & =\frac{1}{n\omega_{n}r^{n-1}}\int_{\partial B_{r}\left(x_{0}\right)}u\left(x\right)\dd\mu_{\partial B_{R}}\left(x\right) &  & \text{(spherical mean)}\\
u\left(x_{0}\right) & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(x_{0}\right)}u\left(x\right)\dd\mu\left(x\right) &  & \text{(mean over ball)}
\end{align}
In this case, the other formula holds as well.


\subsubsection*{Proof}

``$\Rightarrow$'': Let $u\in C^{2}\left(\Omega\right)$ be harmonic
and $B_{r}\left(x_{0}\right)\subseteq\Omega$. Then $B_{r}\left(y\right)\subseteq\Omega$
holds also for all $y$ in a neighborhood of $x_{0}$. The function
\begin{align*}
H\left(x,y\right) & =\Gamma\left(x,y\right)-\Gamma\left(r\right)
\end{align*}
coincides up to a constant with the fundamental solution and it holds
$H\left(x,y\right)=0$ for $x\in\partial B_{r}\left(y\right)$. Using
Green's representation gives: 
\begin{align*}
u\left(y\right) & =\int_{B_{r}\left(y\right)}\underbrace{\left(\upDelta u\right)\left(x\right)}_{=0}\cdot H\left(x,y\right)\dd\mu\left(x\right)+\\
 & \qquad+\int_{\partial B_{r}\left(y\right)}\bigg(u\left(x\right)\nabla_{\nu}H\left(x,y\right)-\underbrace{H\left(x,y\right)}_{=0}\nabla_{\nu}u\left(x\right)\bigg)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)=\\
 & =\int_{\partial B_{r}\left(y\right)}u\left(x\right)\nabla_{\nu}H\left(x,y\right)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)
\end{align*}
\begin{align*}
\nabla_{\nu}H\left(x,y\right) & =\nabla_{\nu,x}\Gamma\left(\norm{x-y}\right)\sr ={r:=\norm{x-y}}{}\frac{\partial}{\partial r}\Gamma\left(r\right)=\frac{1}{n\omega_{n}r^{n-1}}
\end{align*}
For $y:=x_{0}$ follows the spherical mean formula:
\begin{align*}
u\left(x_{0}\right) & =\frac{1}{n\omega_{n}r^{n-1}}\int_{\partial B_{r}\left(x_{0}\right)}u\left(x\right)\dd\mu_{\partial B_{R}}\left(x\right)
\end{align*}
Now follows:
\begin{align}
\int_{B_{r}\left(y\right)}u\left(x\right)\dd\mu\left(x\right) & \stackrel{\text{Fubini}}{=}\int_{0}^{r}\dd\rho\int_{\partial B_{\rho}\left(y\right)}u\left(x\right)\dd\mu_{\partial B_{\rho}\left(y\right)}\left(x\right)=\int_{0}^{r}u\left(y\right)n\omega_{n}\rho^{n-1}\dd\rho=\nonumber \\
 & =u\left(y\right)n\omega_{n}\cdot\frac{1}{n}r^{n}=\omega_{n}r^{n}u\left(y\right)\label{eq:comp-spherical-mean}
\end{align}
``$\Leftarrow$'': Let $u\in C^{0}\left(\Omega\right)$ be continuous.
If the formula for the spherical mean holds, the computation (\ref{eq:comp-spherical-mean})
gives the formula for means over balls. Let us show that the formula
for means over balls implies the formula for spherical means. So assume
for fixed $y$ and all $r<r_{0}$:
\begin{align*}
u\left(y\right) & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y\right)}u\left(x\right)\dd\mu\left(x\right)
\end{align*}
Thus using Fubini's theorem follows:
\begin{align*}
r^{n}u\left(y\right) & =\frac{1}{\omega_{n}}\overbrace{\int_{0}^{r}\dd\rho\underbrace{\int_{\partial B_{\rho}\left(y\right)}u\left(x\right)\dd\mu_{\partial B_{\rho}\left(y\right)}\left(x\right)}_{\text{continuous in }\rho}}^{C^{1}\text{ in }r}
\end{align*}
Differentiation on both sides with respect to $r$ gives the formula
for spherical means:
\begin{align*}
nr^{n-1}u\left(y\right) & =\frac{1}{\omega_{n}}\int_{\partial B_{r}\left(y\right)}u\left(x\right)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)
\end{align*}
Next we show, that $u$ is smooth in $\Omega$. The idea is to mollify
by convolution. Choose:
\begin{align*}
\varrho\left(t\right) & :=\begin{cases}
c_{n}e^{\frac{1}{t^{2}-1}} & \text{if }-1<t<1\\
0 & \text{otherwise}
\end{cases}\in C_{0}^{\infty}\left(\mathbb{R}\right)
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=9cm, axis x line=middle, axis y line=middle, ytick={0}, xlabel=$t$, ylabel=$\varrho$,xmin=-1.5, xmax=1.5, ymax=0.4 ,samples=300]
  \addplot[mark=none,domain=-0.9999:0.9999] {exp(1/(x^2-1))};
 \end{axis}
\end{tikzpicture} \caption{$\varrho\left(t\right)$ is smooth and has compact support $\left[-1,1\right]$.}
\end{figure}


Then holds $\varrho\left(\norm x\right)\in C_{0}^{\infty}\left(\mathbb{R}^{n}\right)$.
Choose $c_{n}$ such that holds:
\begin{align*}
1 & =\int_{\mathbb{R}^{n}}\varrho\left(\norm x\right)\dd^{n}x
\end{align*}
Now for $\varepsilon\in\mathbb{R}_{>0}$ set:
\begin{align*}
\varrho_{\varepsilon}\left(x,y\right) & :=\frac{1}{\varepsilon^{n}}\varrho\left(\frac{\norm{x-y}}{\varepsilon}\right)
\end{align*}
Then still holds:
\begin{align*}
1 & =\int_{\mathbb{R}^{n}}\varrho_{\varepsilon}\left(x,y\right)\dd^{n}x
\end{align*}
Also we know $\varrho_{\varepsilon}\left(x,.\right)\in C_{0}^{\infty}\left(B_{2\varepsilon}\left(x\right)\right)$.
Choose $\varepsilon$ so small that $B_{2\varepsilon}\left(y\right)\subseteq\Omega$
and use $\varrho_{\varepsilon}$ as our convolution kernel to define:
\begin{align*}
u_{\varepsilon}\left(y\right) & :=\int_{\Omega}\varrho_{\varepsilon}\left(x,y\right)u\left(x\right)\dd\mu\left(x\right)
\end{align*}
Now $u_{\varepsilon}$ is a smooth function, because $\varrho_{\varepsilon}\left(x,.\right)$
is smooth and any derivative with respect to $y$ can be exchanged
with the integral, since the integration volume is compact.
\begin{align*}
u_{\varepsilon}\left(y\right) & =\frac{1}{\varepsilon^{n}}\int_{\Omega}\varrho\left(\frac{\norm{x-y}}{\varepsilon}\right)u\left(x\right)\dd\mu\left(x\right)
\end{align*}
Choose polar coordinates around $y$ and use Fubini to get:
\begin{align*}
u_{\varepsilon}\left(y\right) & =\frac{1}{\varepsilon^{n}}\int_{0}^{2\varepsilon}\dd r\int_{\partial B_{r}\left(y\right)}\varrho\left(\frac{r}{\varepsilon}\right)u\left(x\right)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)=\\
 & \stackrel{\text{spherical mean}}{=}\frac{1}{\varepsilon^{n}}\int_{0}^{2\varepsilon}\dd r\varrho\left(\frac{r}{\varepsilon}\right)u\left(y\right)n\omega_{n}r^{n-1}=\\
 & =u\left(y\right)\frac{1}{\varepsilon^{n}}\int_{0}^{2\varepsilon}\dd r\int_{\partial B_{r}\left(y\right)}1\cdot\varrho\left(\frac{r}{\varepsilon}\right)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)=\\
 & =u\left(y\right)\int_{\mathbb{R}^{n}}\varrho_{\varepsilon}\left(x,y\right)\dd^{n}x=u\left(y\right)
\end{align*}
Thus $u$ is smooth.

Compute $\upDelta u$ using the theorem of Gauss:
\begin{align*}
\int_{B_{r}\left(y\right)}\left(\upDelta u\left(x\right)\right)\dd\mu\left(x\right) & =\int_{\partial B_{r}\left(y\right)}\nabla_{\nu}u\dd\mu_{\partial B_{r}\left(y\right)}
\end{align*}
With
\begin{align*}
\omega & :=\frac{x-y}{\norm{x-y}}\in S^{n-1}
\end{align*}
we get:
\begin{align*}
\int_{B_{r}\left(y\right)}\left(\upDelta u\left(x\right)\right)\dd\mu\left(x\right) & =r^{n-1}\int_{\partial B_{1}\left(0\right)}\frac{\partial}{\partial r}u\left(y+r\omega\right)\dd\mu_{\partial B_{1}\left(0\right)}\left(\omega\right)=\\
 & =r^{n-1}\frac{\partial}{\partial r}\left(\frac{1}{r^{n-1}}\int_{\partial B_{r}\left(y\right)}u\left(x\right)\dd\mu_{\partial B_{r}\left(y\right)}\left(x\right)\right)=\\
 & \sr ={\text{mean value}}{\text{property}}r^{n-1}\frac{\partial}{\partial r}\left(\frac{1}{r^{n-1}}u\left(y\right)n\omega_{n}r^{n-1}\right)=0
\end{align*}
In the limes $r\to0$ follows $\upDelta u\left(y\right)=0$ since
$u$ is smooth. Thus $u$ is harmonic.\qqed

%DATE: Mi 15.5.13


\subsection{Theorem \textmd{(Strong Maximum Principle)}}

Let $u\in C^{2}\left(\Omega\right)$ be a harmonic function on an
open and connected subset $\Omega\subseteq\mathbb{R}^{n}$. If a point
$x_{0}\in\Omega$ with
\begin{align*}
u\left(x_{0}\right) & =\sup_{x\in\Omega}\left(u\right)
\end{align*}
or
\begin{align*}
u\left(x_{0}\right) & =\inf_{x\in\Omega}\left(u\right)
\end{align*}
exists, then $u$ is constant.


\subsubsection*{Proof}

Since $-u$ is also harmonic, it suffices to consider the case $u\left(x_{0}\right)=\sup_{\Omega}\left(u\right)$,
so assume
\begin{align*}
u\left(x_{0}\right) & =\sup_{\Omega}\left(u\right)=:M
\end{align*}
and define:
\begin{align*}
\Omega_{M} & :=\left\{ x\in\Omega\big|u\left(x\right)=M\right\} 
\end{align*}
Clearly, $\Omega_{M}$ is not empty, because $x_{0}\in\Omega_{M}$.
By continuity, $\Omega_{M}$ is closed in $\Omega$ with respect to
the relative topology. Thus it suffices to show that $\Omega_{M}$
is open. Consider $y\in\Omega_{M}$, i.e. $u\left(y\right)=M$, and
choose $r\in\mathbb{R}_{>0}$ with $B_{r}\left(y\right)\subseteq\Omega$.
\begin{align*}
0 & =u\left(y\right)-M\sr ={\text{mean value}}{\text{property}}\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y\right)}\underbrace{\left(u\left(x\right)-M\right)}_{\le0}\dd\mu\left(x\right)
\end{align*}
Since $u\left(x\right)\le M$, the integrand is non-positive and continuous.
So $u\left(x\right)=M$ for all $x\in B_{r}\left(y\right)$ and thus
follows $B_{r}\left(y\right)\subseteq\Omega_{M}$. This means that
$\Omega_{M}$ is open. Since it is also non-empty, closed and connected,
the only possibility is $\Omega_{M}=\Omega$.\qqed


\subsection{Theorem \textmd{(Weak Maximum Principle)\label{sub:Thm-Weak-Maximum-Principle}}}

Let $\Omega\subseteq\mathbb{R}^{n}$ be open and bounded and $u\in C^{0}\left(\overline{\Omega}\right)$
be harmonic. Then holds for all $x\in\Omega$:
\begin{align*}
\min_{y\in\partial\Omega}\left(u\left(y\right)\right) & \le u\left(x\right)\le\max_{y\in\partial\Omega}\left(u\left(y\right)\right)
\end{align*}



\subsubsection*{Proof}

If the statement were false, there would be an interior maximum or
minimum at point $x_{0}\in\Omega$, since $\overline{\Omega}$ is
compact, which ensures that the maximum and minimum of $u$ are attained
in $\overline{\Omega}$.\\
Let $\tilde{\Omega}\subseteq\Omega$ be the connected component of
$\Omega$ which contains $x_{0}$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw plot[smooth cycle,tension=1] coordinates{(0,0) (1,0) (0,1) (-1,0)};
  \draw (0.3,0.5) node[left]{$x_0$} +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \node at (0,1.3) {$\tilde{\Omega}$};
  \draw plot[smooth cycle,tension=1] coordinates{(2,-0.5) (4,0) (3,2)};
  \node (a) at (1.5,1) {$\Omega$};
  \draw (a.-130) -- (0.9,0.5) (a.-70) -- (2,0.5);
\end{tikzpicture}\caption{$\tilde{\Omega}$ is the connected component of $\Omega$ that contains
$x_{0}$.}
\end{figure}


The strong maximum principle implies $u=u\left(x_{0}\right)$ on $\tilde{\Omega}$.
Thus follows:
\begin{align*}
\min_{\partial\tilde{\Omega}}\left(u\right) & =u\left(x_{0}\right)=\max_{\partial\tilde{\Omega}}\left(u\right)\\
\Rightarrow\qquad\min_{\partial\Omega}\left(u\right)\le\min_{\partial\tilde{\Omega}}\left(u\right) & =u\left(x_{0}\right)=\max_{\partial\tilde{\Omega}}\left(u\right)\le\max_{\partial\Omega}\left(u\right)
\end{align*}
Therefore $x_{0}$ cannot be an interior maximum or minimum in contradiction
to our assumption.\qqed


\subsection{Corollary \textmd{(Uniqueness of Solutions of the Poisson Equation)}}

Let $u,v\in C^{0}\left(\overline{\Omega}\right)\cap C^{2}\left(\Omega\right)$
be solutions of the Poisson equation:
\begin{align*}
\upDelta u & =f=\upDelta v
\end{align*}
If moreover holds $u\le v$ on $\partial\Omega$, then follows $u\le v$
in $\Omega$.\\
In particular, $u=v$ on $\partial\Omega$ implies $u=v$ in $\Omega$.


\subsubsection*{Proof}

The function $h:=u-v$ is harmonic
\begin{align*}
\upDelta h & =\upDelta u-\upDelta v=f-f=0
\end{align*}
and on $\partial\Omega$ holds $h\le0$. The weak maximum principle
gives $h\le0$ in $\Omega$.\qqed


\subsection{Corollary \textmd{(Liouville's Theorem)}}

If $u:\mathbb{R}^{n}\to\mathbb{R}$ is harmonic and bounded, then
$u$ is constant.


\subsubsection*{Proof}

Choose $y_{1},y_{2}\in\mathbb{R}^{n}$. Then for any $r\in\mathbb{R}_{>0}$
holds for $i\in\left\{ 1,2\right\} $.
\begin{align*}
u\left(y_{i}\right) & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y_{i}\right)}u\left(x\right)\dd\mu\left(x\right)
\end{align*}
The difference is:
\begin{align*}
u\left(y_{1}\right)-u\left(y_{2}\right) & =\frac{1}{\omega_{n}r^{n}}\left(\int_{B_{r}\left(y_{1}\right)}u\left(x\right)\dd\mu\left(x\right)-\int_{B_{r}\left(y_{2}\right)}u\left(x\right)\dd\mu\left(x\right)\right)
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw (0,0) node[left]{$y_1$} +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \draw (0.5,0) node[right]{$y_2$} +(-0.1,-0.1) -- +(0.1,0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \draw[dashed] (0,0) -- node[above]{$r$} +({2*cos(150)},{2*sin(150)});
  \draw[dashed] (0.5,0) -- node[below right=-3pt]{$r$} +({2*cos(60)},{2*sin(60)});
  \draw[red,dashed] (0,0) -- node[right]{$r_-$} +({1.5*cos(100)},{1.5*sin(100)});
  \draw[red,dashed] (0,0) -- node[right]{$r_+$} +({2.5*cos(260)},{2.5*sin(260)});
\begin{scope}
  \draw[clip] (2,0) arc (0:360:2)  (2.5,0) arc (0:-360:2);
  \foreach \x in {-4.9,-3.8,...,3}     \draw (-4,\x) -- (4,{\x +4});
\end{scope}
  \draw[red,thick] (0,0) circle(1.5) circle (2.5);
\end{tikzpicture}\caption{$r_{-}:=r-\norm{y_{1}-y_{2}}$, $r_{+}:=r+\norm{y_{1}-y_{2}}$}
\end{figure}


So we get:
\begin{align*}
u\left(y_{1}\right)-u\left(y_{2}\right) & \le\frac{1}{\omega_{n}r^{n}}\underbrace{\sup_{\mathbb{R}^{n}}\left(\abs u\right)}_{<\infty}\mu\left(B_{r}\left(y_{1}\right)\setminus B_{r}\left(y_{2}\right)\cup B_{r}\left(y_{2}\right)\setminus B_{r}\left(y_{1}\right)\right)\le\\
 & \le\frac{1}{\omega_{n}r^{n}}\sup_{\mathbb{R}^{n}}\left(\abs u\right)\left(\mu\left(B_{r+\norm{y_{2}-y_{1}}}\left(y_{1}\right)\right)-\mu\left(B_{r-\norm{y_{2}-y_{1}}}\left(y_{1}\right)\right)\right)\le\\
 & \le\frac{1}{\omega_{n}r^{n}}\sup_{\mathbb{R}^{n}}\left(\abs u\right)\left(\omega_{n}\left(r+\norm{y_{2}-y_{1}}^{n}\right)-\omega_{n}\left(r-\norm{y_{2}-y_{1}}^{n}\right)\right)=\\
 & =\sup_{\mathbb{R}^{n}}\left(\abs u\right)\frac{1}{r^{n}}\left(2n\norm{y_{2}-y_{1}}r^{n-1}+\ldots\right)\xrightarrow{r\to\infty}0
\end{align*}
This gives $u\left(y_{1}\right)=u\left(y_{2}\right)$ and thus $u$
is constant.\qqed


\section{The Harnack Inequality for Harmonic Functions}


\subsection{Theorem \textmd{(Harnack inequality)}}

Let $\Omega\subseteq\mathbb{R}^{n}$ be open and $u:\Omega\to\mathbb{R}$
harmonic and non-negative. Then for every compact, (for simplicity)
connected subset $\Omega'\subseteq\Omega$ there is a constant $c=c\left(\Omega,\Omega'\right)\in\mathbb{R}$,
which is independent of $u$, such that holds:
\begin{align*}
\sup_{\Omega'}\left(u\right) & \le c\cdot\inf_{\Omega'}\left(u\right)
\end{align*}



\subsubsection{Proof}

We begin with the case $\Omega'=B_{r}\left(x_{0}\right)$ and $B_{4r}\left(x_{0}\right)\subseteq\overline{\Omega}$.
Choose $y_{1},y_{2}\in\Omega'$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=0.8]
  \draw plot[smooth cycle] coordinates {(-4,-4) (4,-3) (5,4) (-5,4)};
  \node at (-4,4) {$\overline{\Omega}$};
  \node at (1.3,0) {$\Omega '$};
  \node (x0) at (0,0){};
  \node (y1) at (-0.3,0.5){};
  \node (y2) at (0,-0.7){};
  \draw (x0) node[left] {$x_0$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (y1) node[right] {$y_1$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (y2) node[right] {$y_2$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (x0) circle(1) circle(4);
  \draw[red] (y1) circle(1);
  \draw[blue] (x0) circle(2);
  \draw[green] (y2) circle(3);
\end{tikzpicture}\caption{${\color{red}B_{r}\left(y_{1}\right)}\subseteq{\color{blue}B_{2r}\left(x_{0}\right)}\subseteq{\color{green}B_{3r}\left(y_{2}\right)}\subseteq B_{4r}\left(x_{0}\right)\subseteq\overline{\Omega}$}
\end{figure}


It holds:
\begin{align*}
u\left(y_{1}\right) & =\frac{1}{\omega_{n}r^{n}}\int_{{\color{red}B_{r}\left(y_{1}\right)}}u\left(x\right)\dd\mu\left(x\right)\sr{\le}{u\ge0}{}\frac{1}{\omega_{n}r^{n}}\int_{{\color{blue}B_{2r}\left(x_{0}\right)}}u\left(x\right)\dd\mu\left(x\right)\le\\
 & \le\frac{1}{\omega_{n}r^{n}}\int_{{\color{green}B_{3r}\left(y_{2}\right)}}u\left(x\right)\dd\mu\left(x\right)\le\frac{3^{n}}{\omega_{n}\left(3r\right)^{n}}\int_{{\color{green}B_{3r}\left(y_{2}\right)}}u\left(x\right)\dd\mu\left(x\right)=3^{n}u\left(y_{2}\right)
\end{align*}
Taking the supremum over $y_{1}$ and the infimum over $y_{2}$ we
get:
\begin{align*}
\sup_{B_{r}\left(x_{0}\right)}\left(u\right) & \le3^{n}\inf_{B_{r}\left(x_{0}\right)}\left(u\right)
\end{align*}
Now consider a general compact subset $\Omega'\subseteq\Omega$. If
$\Omega'$ is empty, we have nothing to show, so consider a non-empty
$\Omega'$. We want to find a $r\in\mathbb{R}_{>0}$ such that for
every $x\in\Omega'$ holds $B_{4r}\left(x\right)\subseteq\Omega$.
For $\Omega=\mathbb{R}^{n}$ we can choose any $r$. Otherwise $\partial\Omega\subseteq\mathbb{R}^{n}$
is non-empty and closed. Since $\Omega'$ is also non-empty and even
compact, the distance $\text{dist}\left(\Omega',\partial\Omega\right)$
is attained. This must be larger than zero, because from $\partial\Omega\cap\Omega=\emptyset$
and $\Omega'\subseteq\Omega$ follows $\partial\Omega\cap\Omega'=\emptyset$.
So we can choose any $r\in\mathbb{R}_{>0}$ with:
\begin{align*}
r & <\frac{1}{4}\text{dist}\left(\Omega',\partial\Omega\right)
\end{align*}
We cover $\Omega'$ by a finite number $\Omega_{1},\ldots,\Omega_{N}$
of balls of radius $r.$ On each of the sets $\Omega_{l}$ holds:
\begin{align*}
\sup\left(u\right) & \le3^{n}\text{inf}\left(u\right)
\end{align*}
One can proceed inductively as follows: Without loss of generality
holds $\sup_{\Omega'}\left(u\right)\le\sup_{\Omega_{1}}\left(u\right)$,
otherwise change the numbering of the $\Omega_{i}$. Since $\Omega'$
is connected, one can choose a finite number $\Omega_{2},\ldots,\Omega_{k}$
from the balls of the covering such that for $i\in\left\{ 1,\ldots,k-1\right\} $
holds
\begin{align*}
\Omega_{i}\cap\Omega_{i+1} & \not=\emptyset
\end{align*}
and $\inf_{\Omega_{k}}\left(u\right)\le\inf_{\Omega'}\left(u\right)$.
If $\inf_{\Omega_{1}}\left(u\right)\le\inf_{\Omega'}\left(u\right)$,
we can choose $k=1$. It holds:
\begin{align*}
\sup_{\Omega_{i}}\left(u\right) & \le3^{n}\inf_{\Omega_{i}}\left(u\right)\sr{\le}{z_{i}\in\Omega_{i}\cap\Omega_{i+1}}{}3^{n}u\left(z_{i}\right)\le3^{n}\sup_{\Omega_{i+1}}\left(u\right)
\end{align*}
Inductively one gets after $k-1$ steps:
\begin{align*}
\sup_{\Omega'}\left(u\right)\le\sup_{\Omega_{1}}\left(u\right) & \le3^{\left(k-1\right)n}\sup_{\Omega_{k}}\left(u\right)\le3^{kn}\inf_{\Omega_{k}}\left(u\right)\le3^{kn}\inf_{\Omega'}\left(u\right)
\end{align*}
In the worst case of $u$, we have $k=N$ and therefore for any $u$
holds:
\begin{align*}
\sup_{\Omega'}\left(u\right) & \le3^{Nn}\inf_{\Omega'}\left(u\right)
\end{align*}
Thus the theorem is proven.\qqed


\subsection{Corollary \textmd{(Harnack's Convergence Theorem)}}

Let $u_{n}:\Omega\to\mathbb{R}^{n}$ be a monotonically increasing
sequence of harmonic functions. Assume that there is a $y\in\Omega$,
where $u_{n}\left(y\right)$ is a bounded sequence.\\
Then the functions $u_{n}$ converge locally uniformly, i.e. uniformly
in a small neighborhood of $y$, to a harmonic function $u$.


\subsubsection*{Proof}

Since the sequence $u_{n}\left(y\right)$ is bounded and monotonically
increasing, it is convergent, i.e. for all $\varepsilon\in\mathbb{R}_{>0}$
there exists a $N\in\mathbb{N}$ such that for all $k>m>N$ holds:
\begin{align*}
u_{k}\left(y\right)-u_{m}\left(y\right) & <\varepsilon
\end{align*}
The function $u_{k}-u_{m}$ is non-negative and harmonic. Now choose
a bounded and connected neighborhood $\Omega'$ of $y$ with $\overline{\Omega'}\subseteq\Omega$.
According to the Harnack inequality holds:
\begin{align*}
\sup_{\overline{\Omega'}}\left(u_{k}-u_{m}\right) & \le c\left(\Omega,\overline{\Omega'}\right)\cdot\inf_{\overline{\Omega'}}\left(u_{k}-u_{m}\right)\le c\left(u_{k}\left(y\right)-u_{m}\left(y\right)\right)\xrightarrow{k,m\to\infty}0
\end{align*}
Hence $u_{k}$ converges \emph{uniformly} in $\Omega'$ to a function
$u\in C^{0}\left(\Omega'\right)$. The function $u$ is harmonic,
because for all $x_{0}\in\Omega'$ and $r\in\mathbb{R}_{>0}$ such
that $B_{r}\left(x_{0}\right)\subseteq\Omega'$ holds:
\begin{align*}
u_{k}\left(x_{0}\right) & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(x_{0}\right)}u_{k}\left(x\right)\dd\mu\left(x\right)
\end{align*}
From $u_{k}\left(x_{0}\right)\to u\left(x_{0}\right)$ and $u_{k}\left(x\right)\rightrightarrows u\left(x\right)$
follows:
\begin{align*}
u\left(x_{0}\right) & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(x_{0}\right)}u\left(x\right)\dd\mu\left(x\right)
\end{align*}
So $u$ has the mean-value property and is thus harmonic.\qqed


\chapter{Perron Method of Sub- and Supersolutions}

Consider the Dirichlet problem on a bounded $\Omega\subseteq\mathbb{R}^{n}$
with $\varphi\in C^{2}\left(\partial\Omega\right)$:
\begin{align*}
\upDelta u & =0 & u\big|_{\partial\Omega} & =\varphi
\end{align*}
The Perron method, named after Oskar Perron (1880-1972), yields the
existence of a solution if $\partial\Omega$ is sufficiently smooth.
This is a classical method, in the sense that it works always with
continuous functions and no weak solutions, but only classical solutions.
The idea is to find the solution as a supremum of subsolutions:
\begin{align*}
u\left(x\right) & :=\sup_{v\text{ subsolution}}\left(v\left(x\right)\right)
\end{align*}
For any domain this gives a harmonic function, but $\partial\Omega$
has to be sufficiently smooth, for the boundary condition to be satisfied.

%DATE: Fr 17.5.13


\section{Definition \textmd{(Sub- and Superharmonic Functions, Compactly Contained)}}

A function $u\in C^{0}\left(\Omega\right)$ is called \emph{subharmonic}
(\emph{superharmonic}) in $\Omega$, if for every ball $B\Subset\Omega$
(\emph{compactly contained} in $\Omega$, i.e. $\overline{B}\subseteq\Omega$)
and every harmonic function $h\in C^{0}\left(\overline{B}\right)$
with $u\le h$ (respectively $u\ge h$) in $\partial B$ follows $u\le h$
(respectively $u\ge h$) in all of $B$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw plot [smooth cycle] coordinates {(-2,0) (-1,2) (1,1) (2,-1)};
  \draw (0,0) node{$h$} circle (0.5);
  \node at (0,0.7) {$B$};
  \node at (-1,0.5) {$u$};
  \node at (0.3,1.9) {$\Omega$};
\end{tikzpicture}\caption{$h\in C^{0}\left(\overline{B}\right)$}
\end{figure}


Note that every harmonic function is subharmonic and superharmonic
by the weak maximum principle.

For $\varphi\in C^{2}\left(\partial\Omega\right)$ we consider the
family $S_{\varphi}$ of functions defined as:
\begin{align*}
S_{\varphi} & :=\left\{ v\in C^{0}\left(\overline{\Omega}\right)\big|v\text{ subharmonic},v\big|_{\partial\Omega}\le\varphi\big|_{\partial\Omega}\right\} 
\end{align*}
Because the constant $v:=\min_{\partial\Omega}\varphi$ is subharmonic
and satisfies $v\big|_{\partial\Omega}\le\varphi\big|_{\partial\Omega}$,
we know $S_{\varphi}\not=\emptyset$. The constant is bigger than
minus infinity, because $\Omega$ is bounded and thus $\partial\Omega$
is compact. A function $v\in S_{\varphi}$ is called \emph{subsolution}.
Now define the function $u$ by:
\begin{align*}
u\left(x\right) & :=\sup_{v\in S_{\varphi}}\left(v\left(x\right)\right)\in\mathbb{R}\cup\left\{ \infty\right\} 
\end{align*}
We hope, that $u$ is the solution of the Dirichlet problem.


\section{Theorem \textmd{(Supremum of Subsolutions is Harmonic)}\label{sec:Thm-u-harmonic}}

The function
\begin{align*}
u\left(x\right) & :=\sup_{v\in S_{\varphi}}\left(v\left(x\right)\right)\in\mathbb{R}\cup\left\{ \infty\right\} 
\end{align*}
is a harmonic function in $\Omega$.

After proving this theorem, we still need to verify that $u$ satisfies
the boundary condition.


\section{Definition \textmd{(Harmonic Lift)}}

Let $u\in C^{0}\left(\Omega\right)$ be subharmonic in $\Omega$ and
$B\Subset\Omega$ a ball. The function $\overline{v}\in C^{0}\left(\Omega\right)$
defined by
\begin{align*}
\overline{v}\big|_{\Omega\setminus B} & =v\big|_{\Omega\setminus B} & \upDelta\overline{v}\big|_{B} & =0
\end{align*}
is referred to as the \emph{harmonic lift} of $v$ in $B$.


\section{Lemma \textmd{(Harmonic Lift Exists)}}

The harmonic lift exists.


\subsubsection*{Proof}

Consider the Dirichlet problem on the ball $B$:
\begin{align*}
\upDelta u\big|_{B} & =0 & u\big|_{\partial B} & =v\big|_{\partial B}
\end{align*}
This Dirichlet problem has an explicit solution $u$ given by the
Poisson representation. Set:
\begin{align*}
\overline{v}\left(x\right) & =\begin{cases}
v\left(x\right) & \text{if }x\in\Omega\setminus B\\
u\left(x\right) & \text{if }x\in B
\end{cases}
\end{align*}
\qqed

Note that $\overline{v}\ge v$ follows by the definition of subharmonic,
because $u\ge v$ holds in $B$ and thus $\overline{v}\ge v$ holds
in $\Omega$.


\section{Lemma \textmd{(Harmonic Lift is Subharmonic)}}

The harmonic lift is again subharmonic.


\subsubsection*{Proof}

Let $\overline{v}$ be the harmonic lift of $v$ in $B$.

We want to prove, that for all balls $B'\Subset\Omega$ and for all
harmonic functions $u$ with $u\ge\overline{v}$ on $\partial B'$
holds $u\ge\overline{v}$ in $B'$.

If $B'\cap B=\emptyset$ this follows, because $\overline{v}\big|_{\Omega\setminus B}=v$
and $v$ is subharmonic.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=1.5]
  \draw plot [smooth cycle] coordinates {(-2,0) (-1,2) (2,1) (2,-1)};
  \draw(0,0.5) circle (0.5) (0.8,0.3) circle (1);
\begin{scope}
  \clip (0,0.5) circle (0.5);
  \clip (0.8,0.3) circle (1);
  \draw[thick, orange] (0,0.5) circle (0.485);
  \draw[thick, orange] (0.8,0.3) circle (0.985);
  \foreach \x in {-0.45,-0.25,...,0.35}     \draw[orange] (-1,\x) -- (1,{\x+1});
\end{scope}
  \node[orange] at (0,1.4) {$B\cap B'$};
  \node at (1.15,0.56) {$v=\overline{v}$};
\begin{scope}
  \clip (0.8,0.3) +(1,0) arc (0:360:1) (0,0.5) +(0.5,0) arc (0:-360:0.5);
  \foreach \x in {-1,-0.25,...,0.5}     \draw (2,\x) -- (0.1,{\x+1});
\end{scope}
  \node at (-0.6,0.9) {$B$};
  \node at (1.6,-0.7) {$B'$};
  \node at (0.3,2.2) {$\Omega$};
\end{tikzpicture}\caption{$B'\cap B\not=\emptyset$}
\end{figure}


Otherwise let $u\in C^{2}\left(B'\right)$ be harmonic and $u\ge\overline{v}$
on $\partial B'$. We know $v\le\overline{v}$ in $\Omega$ thus follows:
\begin{align*}
v\big|_{\partial B'} & \le\overline{v}\big|_{\partial B'}\le u\big|_{\partial B'}\\
\sr{\Rightarrow}{\text{subharmonic}}{}v\big|_{B'} & \le u\big|_{B'}
\end{align*}
Therefore we have $\overline{v}=v\le u$ in $B'\setminus B$ and thus
$\overline{v}\le u$ on $\partial\left(B\cap B'\right)$. Since the
functions $\overline{v}$ and $u$ are both harmonic in $B\cap B'$,
the weak maximum principle implies $\overline{v}\le u$ in $B\cap B'$.\qqed


\section{Proposition \textmd{(Maximum Principle for Subharmonic Functions)}}

Let $\Omega\subseteq\mathbb{R}^{n}$ be open and connected and $u\in C^{0}\left(\overline{\Omega}\right)$
subharmonic.
\begin{enumerate}[label=\alph*)]
\item Strong maximum principle: If there is a $x_{0}\in\Omega$ with $u\left(x_{0}\right)=\sup_{\Omega}\left(u\right)$,
then $u$ is constant.
\item Weak maximum principle: ${\displaystyle u\left(x\right)\le\sup_{\partial\Omega}\left(u\right)}$
\end{enumerate}

\subsubsection*{Proof}

b) follows from a) just as in the proof of Theorem \ref{sub:Thm-Weak-Maximum-Principle}.

To prove a), suppose that $u\left(x_{0}\right)=\sup_{\Omega}\left(u\right)$
holds, but $u$ is \emph{not} constant. Then there is a $y\in\Omega$
and a $r\in\mathbb{R}_{>0}$ such that $u\left(y\right)=\sup_{x\in\Omega}u\left(x\right)$,
but $u\big|_{\partial B_{r}\left(y\right)}$ is not constant.

Let $c\left(\tau\right)$ be a curve joining $c\left(0\right)=x_{0}$
with $c\left(1\right)=z$.
\begin{align*}
\tilde{\tau} & :=\sup\left\{ \tau\big|u\left(c\left(\tau\right)\right)=u\left(x_{0}\right)\right\} <1
\end{align*}
Choose $y:=c\left(\tilde{\tau}\right)$ and $r$ small enough, so
that $B_{r}\left(y\right)\subseteq\Omega$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=1.5]
  \draw plot [smooth cycle] coordinates {(-2,0) (-1,2) (2,1) (2,-1)};
  \node at (0.3,2) {$\Omega$};
  \draw (-1,1) node[left]{$x_0$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1.5,0) node[right]{$z$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw plot [smooth] coordinates {(-1,1) (-0.5,0) (0.5,0.5) (1.5,0)};
  \draw[red] (0.5,0.5) node[above]{$y$} +(0.1,0.1) -- +(-0.1,-0.1) +(0.1,-0.1) -- +(-0.1,0.1) +(0,0) circle (0.5) node[above right=10pt]{$B_r(y)$};
\end{tikzpicture}\caption{$u\left(z\right)<u\left(x_{0}\right)=u\left(y\right)$; $u\big|_{\partial B_{r}\left(y\right)}$
is not constant.}
\end{figure}


Let $\overline{u}$ be the harmonic lift of $u$ in $B_{r}$. Then
holds:
\begin{align*}
\overline{u}\left(y\right) & \ge u\left(y\right)\ge\sup_{\partial B_{r}\left(y\right)}\left(u\right)=\sup_{\partial B_{r}\left(y\right)}\left(\overline{u}\right)
\end{align*}
By the weak maximum principle, which states $\overline{u}\left(y\right)\le\sup_{\partial B_{r}\left(y\right)}\left(\overline{u}\right)$,
follows that $\overline{u}$ is constant in $B_{r}\left(y\right)$.
This implies that $\overline{u}\big|_{\partial B_{r}}=u\big|_{\partial B_{r}}$
is constant, which is a contradiction to $u$ not being constant on
$\partial B_{r}$.\qqed


\section{Proposition\label{sec:Prop-sub-super-equals}}

If $v$ is subharmonic and $u$ superharmonic in $\Omega$ and $v\le u$
holds on $\partial\Omega$, then in $\Omega$ holds either $v<u$
or $v=u$, in which case $u$ and $v$ are harmonic.


\subsubsection*{Proof}

This is proven in the exercises.\qqed


\subsubsection*{Proof of Theorem \ref{sec:Thm-u-harmonic}}

Define $u\left(x\right):=\sup_{v\in S_{\varphi}}\left(v\left(x\right)\right)$.
According to Proposition \ref{sec:Prop-sub-super-equals} we know,
since the constant function $\sup_{\partial\Omega}\left(\varphi\right)$
is superharmonic:
\begin{align*}
v\left(x\right) & \le\sup_{\partial\Omega}\left(\varphi\right)\qquad\fall_{v\in S_{\varphi}}\\
\Rightarrow\qquad u\left(x\right) & \le\sup_{\partial\Omega}\left(\varphi\right)
\end{align*}
From $\inf_{\partial\Omega}\left(\varphi\right)\in S_{\varphi}$ and
because $u$ is the supremum of the functions in $S_{\varphi}$, we
also know:
\begin{align*}
\inf_{\partial\Omega}\left(\varphi\right) & \le u\left(x\right)
\end{align*}
Hence $u$ is a bounded function on $\Omega$. Consider $y\in\Omega$.
By definition of the supremum, there is a sequence $v_{n}\in S_{\varphi}$
such that $v_{n}\left(y\right)\to u\left(y\right)$ converges. We
can assume that the functions $v_{n}$ are bounded, because $v_{n}\le u$
bounds from above and if $v_{n}$ is not bounded from below, we can
replace it by $\max\left(v_{n},\inf_{\partial\Omega}\left(\varphi\right)\right)$.
This is again a subsolution.

Choose $r\in\mathbb{R}_{>0}$ such that $B_{r}\left(y\right)\Subset\Omega$
and let $\overline{v}_{n}$ be the harmonic lift of $v_{n}$ in $B_{r}\left(y\right)$.
Then $v_{n}\le\overline{v}_{n}$ holds in $\Omega$ and $\overline{v}_{n}\left(y\right)\le u\left(y\right)$,
since $\overline{v}_{n}$ is again a subsolution. Hence follows:
\begin{align*}
\underbrace{v_{n}\left(y\right)}_{\to u\left(y\right)} & \le\overline{v}_{n}\left(y\right)\le u\left(y\right)
\end{align*}
Thus we have $\overline{v}_{n}\left(y\right)\to u\left(y\right)$.
Possibly after choosing a subsequence, the sequence $\overline{v}_{n}\left(y\right)$
is monotonically increasing. Moreover, we can assume that the sequence
$v_{n}$ is monotonically increasing in $\Omega$. Namely, we can
replace $v_{n}$ by $\tilde{v}_{n}$ defined by:
\begin{align*}
\tilde{v}_{1} & =v_{1}\\
\tilde{v}_{2} & :=\max\left(v_{1},v_{2}\right)\\
\vdots\ \\
\tilde{v}_{n} & :=\max\left(v_{1},\ldots,v_{n}\right)
\end{align*}
These are again subharmonic and they are monotonically increasing.
Then the $\overline{v}_{n}$ are also monotonically increasing in
$B_{r}\left(y\right)$ using the maximum principle:
\begin{align*}
\left(\overline{v}_{n+1}-\overline{v}_{n}\right)\big|_{\partial B_{r}\left(y\right)} & =\left(v_{n+1}-v_{n}\right)\big|_{\partial B_{r}\left(y\right)}\ge0
\end{align*}
The weak maximum principle implies $\overline{v}_{n+1}-\overline{v}_{n}\ge0$
in $B_{r}\left(y\right)$.

Applying Harnack's convergence theorem, we conclude
\begin{align*}
\overline{v}_{n} & \rightrightarrows\overline{v}\text{ in }B_{r}\left(y\right)
\end{align*}
and $\overline{v}$ is harmonic.

Now we show $u=\overline{v}$ in $B_{r}\left(y\right)$. Obviously
holds $\overline{v}\le u,$ because $\overline{v}_{n}\le u$ holds
for all $n\in\mathbb{N}$.\\
Thus assume that there is a point $x\in B_{r}\left(y\right)$ with
$\overline{v}\left(x\right)<u\left(x\right)$. Then there exists a
subsolution $s\in S_{\varphi}$ with $\overline{v}\left(x\right)<s\left(x\right)<u\left(x\right)$,
because $u\left(x\right)=\sup_{v\in S_{\varphi}}\left(v\left(x\right)\right)$.
Thus we also have $v_{n}\left(x\right)\le\overline{v}\left(x\right)<s\left(x\right)$.
Now form the sequence:
\begin{align*}
w_{n} & :=\max\left(s,v_{n}\right)
\end{align*}
These are again subharmonic, from $v_{n}\left(x\right)<s\left(x\right)$
follows $w_{n}\left(x\right)=s\left(x\right)$, and for the harmonic
lifts holds $\overline{w}_{n}\ge\overline{v}_{n}$. Then repeating
the above construction for $v_{n}$ replaced by $w_{n}$, we find
$\overline{w}_{n}\rightrightarrows\overline{w}$ converges uniformly
to a harmonic $\overline{w}$. Then follows $\overline{v}\le\overline{w}\le u$
just as before and:
\begin{align*}
\overline{v}\left(y\right) & =\overline{w}\left(y\right)=u\left(y\right)\\
\overline{v}\left(x\right) & <\overline{w}\left(x\right)=s\left(x\right)<u\left(x\right)
\end{align*}
The mean value property gives:
\begin{align*}
\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y\right)}\overline{w}\left(z\right)\dd\mu\left(z\right) & \ge\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y\right)}\overline{v}\left(z\right)\dd\mu\left(z\right)=\overline{v}\left(y\right)=\overline{w}\left(y\right)=\\
 & =\frac{1}{\omega_{n}r^{n}}\int_{B_{r}\left(y\right)}\overline{w}\left(z\right)\dd\mu\left(z\right)
\end{align*}
Thus follows $\overline{w}=\overline{v}$ in $B_{r}\left(y\right)$
in contradiction to $\overline{v}\left(x\right)<\overline{w}\left(x\right)$.\qqed

Question: Is $u$ also a solution of the Dirichlet problem?


\section{Proposition \textmd{(Existing Solution is Perron Solution)}}

If the Dirichlet problem has a solution, then
\begin{align*}
u\left(x\right) & =\sup_{v\in S_{\varphi}}\left(v\left(x\right)\right)
\end{align*}
equals this solution.


\subsubsection*{Proof}

Let $\tilde{u}$ be a solution of the Dirichlet problem. Then $\tilde{u}$
is also a subsolution, i.e. $\tilde{u}\in S_{\varphi}$. Therefore
holds $u\left(x\right)\ge\tilde{u}\left(x\right)$ for all $x\in\Omega$.
Hence $u-\tilde{u}$ is harmonic and $\left(u-\tilde{u}\right)\big|_{\partial\Omega}=0$.
By the weak maximum principle follows $u=\tilde{u}$ in $\Omega$.\qqed


\part*{Appendix\thispagestyle{empty}}

\addcontentsline{toc}{part}{Appendix}

\fancyhead[R]{}
\fancyhead[C]{Appendix}


\chapter*{Acknowledgements}

\addcontentsline{toc}{section}{\hspace*{2.7em}Acknowledgements}

\fancyhead[R]{Acknowledgements}

My special thanks goes to Professor Finster, who gave this lecture
and allowed me to publish this script of the lecture.

I would also like to thank all those, who found errors by careful
reading and told me of them.

\vspace{1cm}


\hfill{}Andreas Völklein

\label{END}
\end{document}
